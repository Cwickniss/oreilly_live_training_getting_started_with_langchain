{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydantic==2.7.0\n",
    "!pip install langchain\n",
    "!pip install langchain-openai\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# # Set OPENAI API Key\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your openai key\"\n",
    "\n",
    "# OR (load from .env file)\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "# make sure you have python-dotenv installed\n",
    "# load_dotenv(\"./.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we want to convert openai functions to pydantic objects (for a more structured approach for defining tools for LLMs) we can leverage the following ideas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the goal here?\n",
    "To go from openai functions to a Pydantic object that is an easier way to interact with structured information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.utils.function_calling import convert_to_openai_function\n",
    "# this function will convert an openai function to a pydantic object\n",
    "\n",
    "\n",
    "# this is a Pydantic object that inherits from the BaseModel class from pydantic and contains the fields that will be used in the openai function\n",
    "class WeatherSearch(BaseModel):\n",
    "    \"\"\"Call this function to get the weather of a specific airport.\"\"\"\n",
    "    airport_code: str = Field(description=\"The airport code of the airport you want to know the weather of.\")\n",
    "    \n",
    "\n",
    "openai_function_weather_search = convert_to_openai_function(WeatherSearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SO the airport_code is something that the LLM will figure out on how to input to the function, therefore making the call with the correct input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"LIS\"}', 'name': 'WeatherSearch'}}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 60, 'total_tokens': 77}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-b58e4db3-4026-4dfa-b980-6b4525e279e2-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_chat = ChatOpenAI()\n",
    "\n",
    "llm_chat.invoke(\"What's the weather like in Lisbon today?\",functions=[openai_function_weather_search])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from below that the LLM figured out that the airport_code for Lisbon is `LIS`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also bind the function to the model to avoid having to pass the `functions` keyword argument everytime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"LIS\"}', 'name': 'WeatherSearch'}}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 60, 'total_tokens': 77}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-2e4ed22d-4d7c-4b08-bf5d-d8915611ce56-0', usage_metadata={'input_tokens': 60, 'output_tokens': 17, 'total_tokens': 77})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_function = llm_chat.bind(functions=[openai_function_weather_search])\n",
    "model_with_function.invoke(\"What's the weather like in Lisbon today?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOu can also force the model to use the function by binding it with it and adding the `function_call` keyword argument to a dictionary containing the key `name` and the name of that function `WeatherSearch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_forced_function = llm_chat.bind(functions=[openai_function_weather_search],function_call={\"name\": \"WeatherSearch\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's connect to the stuff we already know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"LIS\"}', 'name': 'WeatherSearch'}}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 80, 'total_tokens': 87}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-9c4a1b57-c55b-4be4-a74f-17e544e76e2a-0', usage_metadata={'input_tokens': 80, 'output_tokens': 7, 'total_tokens': 87})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that tells the weather\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "llm_chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "llm_chat_with_forced_function = llm_chat.bind(functions=[openai_function_weather_search], function_call={\"name\": \"WeatherSearch\"})\n",
    "\n",
    "chain = prompt | llm_chat_with_forced_function\n",
    "\n",
    "chain.invoke({\"input\": \"What's the weather like in Lisbon today?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multiple functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class SearchExamples(BaseModel):\n",
    "    \"\"\"Call this function to search for examples of a concept.\"\"\"\n",
    "    concept: str = Field(description=\"The concept you want to search for.\")\n",
    "    \n",
    "class AnalogySearch(BaseModel):\n",
    "    \"\"\"Call this function to search for analogies of a concept.\"\"\"\n",
    "    concept: str = Field(description=\"The concept you want to search for.\")\n",
    "\n",
    "\n",
    "openai_function_analogy_search = convert_to_openai_function(AnalogySearch)\n",
    "openai_function_example_search = convert_to_openai_function(SearchExamples) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    openai_function_analogy_search,\n",
    "    openai_function_example_search\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chat_with_functions = llm_chat.bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"concept\":\"SDK\"}', 'name': 'SearchExamples'}}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 85, 'total_tokens': 99}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-24cb4d9c-8a41-4887-bbfe-0d46ea67396f-0', usage_metadata={'input_tokens': 85, 'output_tokens': 14, 'total_tokens': 99})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here the model calls the example function\n",
    "llm_chat_with_functions.invoke(\"List examples for what and SDK is.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"concept\":\"SDK\"}', 'name': 'AnalogySearch'}}, response_metadata={'token_usage': {'completion_tokens': 15, 'prompt_tokens': 86, 'total_tokens': 101}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-b8506fb4-8e35-4a39-a61e-62ea90698376-0', usage_metadata={'input_tokens': 86, 'output_tokens': 15, 'total_tokens': 101})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chat_with_functions.invoke(\"List analogies for what and SDK is.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-langchain",
   "language": "python",
   "name": "oreilly-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
