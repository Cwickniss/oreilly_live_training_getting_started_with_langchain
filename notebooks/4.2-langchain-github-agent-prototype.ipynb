{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain==0.2.14\n",
    "!pip install langchain-openai==0.1.8\n",
    "!pip install langchainhub==0.1.20\n",
    "!pip install tiktoken==0.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# # Set OPENAI API Key\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "\n",
    "# OR (load from .env file)\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(\"./.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more complex version of this would use this pygithub package as shown in here:\n",
    "- https://python.langchain.com/docs/integrations/toolkits/github\n",
    "\n",
    "But let's try a simpler version that just sets up a bunch of python functions to automate different github actions like add, commit and pull requests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with a simple commit to a branch of some repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I'll create a github repository using some simple commands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# git init -b main\n",
    "\n",
    "# git add . && git commit -m \"Some commit\"\n",
    "\n",
    "# gh repo create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL='gpt-4o-mini'\n",
    "TEMP=0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try asking an agent to write come code and commit the resulting code to the current branch of this repository.\n",
    "\n",
    "To do that, let's give the agent the necessary tools it will need which in this case will be python functions that perform different github actions using the `subprocess` package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll follow the basic steps for building a langchain agent:\n",
    "\n",
    "# Steps for building a simple agent:\n",
    "- Set up the LLM\n",
    "- Define the tool or toolkit (list of tools)\n",
    "- Set up a prompt template\n",
    "- Connect llm with your tools\n",
    "- Define your agent as a dict with keys: input, and agent scratchpad \n",
    "- Use the Langchain LCEL language to pipe agent, prompt the llm_with_tools variable and the output parser (which can use OpenAI function calling parser)\n",
    "- Create the agent loop\n",
    "- Wrap everything into the AgentExecutor\n",
    "- Invoke the agent with some query input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the llm\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=MODEL, temperature=TEMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a tool for the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def github_commit_tool(commit_message=\"Some commit\"):\n",
    "    subprocess.run([\"git\", \"add\", \".\"])\n",
    "    subprocess.run([\"git\", \"commit\", \"-m\", commit_message])\n",
    "    subprocess.run([\"git\", \"push\", \"-u\", \"origin\", \"main\"])\n",
    "    \n",
    "    return \"Committed to Github\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now! Before we use it with langchain, let's test it by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main ae43492] Some testing commit\n",
      " 2 files changed, 86 insertions(+), 71 deletions(-)\n",
      "branch 'main' set up to track 'origin/main'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/EnkrateiaLucca/oreilly_live_training_getting_started_with_langchain.git\n",
      "   b572795..ae43492  main -> main\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Committed to Github'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "github_commit_tool(\"Some testing commit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at out github repository from the terminal.\n",
    "\n",
    "![](2023-10-29-20-47-54.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! It looks like we are good to go with this first simple tool!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now make it a tool for our langchain agent by adding the @tool. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def github_commit_tool(commit_message=\"Some commit\"):\n",
    "    \"\"\"This function uses the subprocess package to make commits to a github repo pre-defined.\"\"\"\n",
    "    subprocess.run([\"git\", \"add\", \".\"])\n",
    "    subprocess.run([\"git\", \"commit\", \"-m\", commit_message])\n",
    "    subprocess.run([\"git\", \"push\", \"-u\", \"origin\", \"main\"])\n",
    "    \n",
    "    return \"Committed to Github\"\n",
    "\n",
    "tools = [github_commit_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We added some documentation to our function to abide by the requirements of the tool decorator from langchain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test if a simple agent can use that tool!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by setting up our prompt template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.agents import AgentExecutor\n",
    "# from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# template = \"\"\"\n",
    "# You are a helpful programming assistant. The user will ask you to perform commits to a github repo and you will perform the needed actions and call the necessary\n",
    "# functions when needed.\n",
    "# Your current task:\n",
    "# {input}\n",
    "# \"\"\"\n",
    "# prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_openai_tools_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_chat = ChatOpenAI(temperature=0)\n",
    "agent = create_openai_tools_agent(llm_chat, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(agent=agent,tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `github_commit_tool` with `{'commit_message': 'Testing openai tools agent!'}`\n",
      "\n",
      "\n",
      "\u001b[0m[main 45844f5] Testing openai tools agent!\n",
      " 7 files changed, 340 insertions(+), 321 deletions(-)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/EnkrateiaLucca/oreilly_live_training_getting_started_with_langchain.git\n",
      "   28bc4f4..45844f5  main -> main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch 'main' set up to track 'origin/main'.\n",
      "\u001b[36;1m\u001b[1;3mCommitted to Github\u001b[0m\u001b[32;1m\u001b[1;3mI have successfully created a GitHub commit with the message 'Testing openai tools agent!'.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"Create a github commit with the message 'Testing openai tools agent!'\",\n",
       " 'output': \"I have successfully created a GitHub commit with the message 'Testing openai tools agent!'.\"}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"Create a github commit with the message 'Testing openai tools agent!'\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And voila, the agent calls the right function and creates the commit!\n",
    "\n",
    "(ignore the github related error, let's focus on the agent capabilities)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And voila! We made a commit!\n",
    "\n",
    "![](2023-10-30-13-04-20.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is cool but, we can go beyond that, and add the ability to create a file and then commit that file to our desired repository. Let's do that!\n",
    "\n",
    "To do it all we have to do is amplify the Agent's toolkit with another tool that can create files in the current folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfect! Now, let's add this to our github agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def create_file_tool(file_contents):\n",
    "    \"\"\"This function creates a file with the contents and file path provided as inputs.\"\"\"\n",
    "    with open(\"file.py\", \"w\") as f:\n",
    "        f.write(file_contents)\n",
    "    \n",
    "    return \"File created\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add that functionality to our agent by just updating the tools list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [github_commit_tool, create_file_tool]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's modify our agent with its new toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_tools_agent(llm_chat, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try using both tools in a call to see if the agent can do something slightly more complex now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `create_file_tool` with `{'file_contents': \"# Python code\\n\\ntruths = ['Pancakes are better than waffles.', 'Waffles are better than pancakes.']\\n\\nfor truth in truths:\\n    print(truth)\\n\", 'file_path': 'pancakes_vs_waffles.py'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3mFile created\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `github_commit_tool` with `{'commit_message': 'Add Python code comparing pancakes and waffles'}`\n",
      "\n",
      "\n",
      "\u001b[0m[main fdd3f5b] Add Python code comparing pancakes and waffles\n",
      " 2 files changed, 49 insertions(+), 48 deletions(-)\n",
      " create mode 100644 notebooks/file.py\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/EnkrateiaLucca/oreilly_live_training_getting_started_with_langchain.git\n",
      "   45844f5..fdd3f5b  main -> main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch 'main' set up to track 'origin/main'.\n",
      "\u001b[36;1m\u001b[1;3mCommitted to Github\u001b[0m\u001b[32;1m\u001b[1;3mI have written the Python code comparing pancakes and waffles, saved it to a file, and committed it to our GitHub repository.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Write Python code with a for loop stating the truth about what is better: pancakes or waffles.    Output ONLY THE CODE and save that to a file then commit it to our github repository.',\n",
       " 'output': 'I have written the Python code comparing pancakes and waffles, saved it to a file, and committed it to our GitHub repository.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"Write Python code with a for loop stating the truth about what is better: pancakes or waffles.\\\n",
    "    Output ONLY THE CODE and save that to a file then commit it to our github repository.\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And voila again!\n",
    "![](2023-10-30-13-15-38.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And again we succeed!\n",
    "\n",
    "![](2023-10-30-13-26-32.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, before we finish with this example, let's add a last tool to read files from a repo, for situations where we might write some Python code and we want our agent to integrate that Python code into our repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we follow the same procedure:\n",
    "\n",
    "- Create the tool\n",
    "- Update our tookit\n",
    "- Update our agent\n",
    "- Run a test task to check if it works "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2023-10-30-13-42-25.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think this is a great usecase for agents like these even if sometimes the performance and reliability is a bit off, because now, its a matter of optimizing the edges to get it to work for complex use cases."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-langchain",
   "language": "python",
   "name": "oreilly-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
