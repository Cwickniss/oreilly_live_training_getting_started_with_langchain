{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Trying Out Different Learning Acronyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADEPT\n",
    "\n",
    "- A:= analogy\n",
    "- D:= diagram\n",
    "- E:= example\n",
    "- P:= plain english\n",
    "- T:= technical definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This still needs a bridge into what the person cares about. So teachiing some formalization technique or trick to bring that person's interests into the problem/concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "def chain_analogy(llm):\n",
    "    return ChatPromptTemplate.from_template(\"Write a simple analogy for this concept: '''{concept}''', which should perfectly encapsulate\\\n",
    "        what it is.\") | llm\n",
    "\n",
    "def chain_diagram(llm):\n",
    "    return ChatPromptTemplate.from_template(\"Write a knowledge graph with the necessary concepts and elements to understand the following concept: '''{concept}''', this diagram should perfectly encapsulate\\\n",
    "        what it is and what it relates to.\") | llm\n",
    "\n",
    "\n",
    "def chain_example(llm):\n",
    "    return ChatPromptTemplate.from_template(\"Write down five examples that perfectly demonstrate this concept: '''{concept}'''. \") | llm\n",
    "\n",
    "\n",
    "def chain_plain_english(llm):\n",
    "    return ChatPromptTemplate.from_template(\"Write a plain english definition for this concept: '''{concept}'''\") | llm\n",
    "\n",
    "\n",
    "def chain_technical_definition(llm):\n",
    "    return ChatPromptTemplate.from_template(\"Write a short and precise technical definition for this concept: '''{concept}'''\") | llm\n",
    "\n",
    "\n",
    "llm_chat = ChatOpenAI()\n",
    "\n",
    "analogy_chain = chain_analogy(llm_chat)\n",
    "diagram_chain = chain_diagram(llm_chat)\n",
    "example_chain = chain_example(llm_chat)\n",
    "plain_english_chain = chain_plain_english(llm_chat)\n",
    "technical_definition_chain = chain_technical_definition(llm_chat)\n",
    "\n",
    "\n",
    "concept = \"joint probability mass function\"\n",
    "map_chain = RunnableParallel(analogy=analogy_chain, diagram=diagram_chain, example=example_chain, \n",
    "                             plain_english=plain_english_chain, technical_def=technical_definition_chain)\n",
    "output_explanation = map_chain.invoke({\"concept\": concept})\n",
    "output_explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**analogy**\n",
       "\n",
       "A joint probability mass function is like a recipe book that tells you the chances of getting a specific combination of ingredients in a dish.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**diagram**\n",
       "\n",
       "Here is a knowledge graph explaining the concept of a \"joint probability mass function\":\n",
       "\n",
       "[Joint Probability Mass Function]\n",
       "- Definition: A joint probability mass function (joint PMF) is a function that assigns probabilities to the possible outcomes of multiple random variables.\n",
       "- Purpose: It describes the probability distribution of a set of random variables by assigning probabilities to each combination of their possible values.\n",
       "- Related Concepts:\n",
       "  - Probability: The likelihood of an event occurring.\n",
       "  - Random Variables: Variables that can take on different values based on the outcome of a random phenomenon.\n",
       "  - Probability Distribution: A function that describes the probabilities of different outcomes in a sample space.\n",
       "  - Discrete Random Variables: Random variables that take on a countable number of distinct values.\n",
       "  - Marginal Probability: The probability distribution of an individual random variable, ignoring the other variables.\n",
       "  - Conditional Probability: The probability of an event occurring given that another event has already occurred.\n",
       "- Example:\n",
       "  - Consider two discrete random variables X and Y.\n",
       "  - The joint PMF P(X, Y) assigns probabilities to all possible combinations of values for X and Y.\n",
       "  - The values in the joint PMF must be non-negative and sum up to 1.\n",
       "- Notation:\n",
       "  - P(X, Y) or P(X=x, Y=y): Denotes the joint probability that X takes on value x and Y takes on value y.\n",
       "- Properties:\n",
       "  - Non-Negativity: P(X, Y) ≥ 0 for all possible combinations of X and Y.\n",
       "  - Summation: ∑∑P(X, Y) = 1, where the summation is taken over all possible combinations of X and Y.\n",
       "- Relationships:\n",
       "  - Marginal PMF: By summing or integrating the joint PMF over one variable, we can obtain the marginal PMF for the other variable.\n",
       "  - Conditional PMF: Dividing the joint PMF by the marginal PMF of a variable yields the conditional PMF for the other variable.\n",
       "- Applications:\n",
       "  - Used in statistics, probability theory, and data analysis to model and analyze the relationships between multiple random variables.\n",
       "  - Enables the calculation of probabilities for various events and helps understand the dependencies between different variables.\n",
       "  - Important in areas such as machine learning, econometrics, and genetics for modeling complex systems and making predictions.\n",
       "\n",
       "Note: This knowledge graph provides a concise representation of the concept, but additional details and examples can be added based on specific requirements.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**example**\n",
       "\n",
       "1) Consider a fair six-sided die. The joint probability mass function can be represented as a table with the probabilities of each possible outcome when rolling two dice simultaneously. For instance, P(X=1, Y=1) = 1/36, P(X=2, Y=3) = 1/36, etc.\n",
       "\n",
       "2) In a card game, suppose you draw two cards from a standard deck without replacement. The joint probability mass function would describe the probabilities of each possible combination of cards being drawn. For example, P(X=King of Hearts, Y=Queen of Diamonds) = 1/221, P(X=4 of Clubs, Y=4 of Diamonds) = 1/221, etc.\n",
       "\n",
       "3) Imagine a manufacturing process that produces light bulbs, where some bulbs are defective and others are not. The joint probability mass function can be used to describe the probabilities of different combinations of defects in a sample of bulbs. For instance, P(X=3 defective bulbs, Y=2 non-defective bulbs) = 0.05, P(X=0 defective bulbs, Y=5 non-defective bulbs) = 0.15, etc.\n",
       "\n",
       "4) In a survey, respondents are asked to rate a product on a scale of 1 to 5 for quality and a scale of 1 to 5 for satisfaction. The joint probability mass function would show the probabilities of different combinations of responses. For example, P(X=3 quality rating, Y=5 satisfaction rating) = 0.08, P(X=2 quality rating, Y=2 satisfaction rating) = 0.12, etc.\n",
       "\n",
       "5) Let's say you have two coins, one fair and the other biased. The joint probability mass function can describe the probabilities of different combinations of outcomes when flipping both coins simultaneously. For instance, P(X=Heads on fair coin, Y=Tails on biased coin) = 1/4, P(X=Tails on fair coin, Y=Tails on biased coin) = 1/4, etc.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**plain_english**\n",
       "\n",
       "A joint probability mass function is a way of describing the probability of two or more random variables occurring together. It tells us the likelihood of specific combinations of values for these variables happening at the same time.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**technical_def**\n",
       "\n",
       "A joint probability mass function refers to a function that assigns probabilities to multiple discrete random variables. It calculates the probability of a particular combination of outcomes occurring simultaneously for these variables.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "for key in output_explanation.keys():\n",
    "    display(Markdown(f\"**{key}**\\n\\n{output_explanation[key].content}\\n\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is nice but can we make it better? Like the knowledge graph is not visual, how can we improve upon that? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydantic import BaseModel, Field\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "from graphviz import Digraph\n",
    "import argparse\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "import graphviz\n",
    "from IPython.display import display\n",
    "\n",
    "class Node(BaseModel):\n",
    "    id: int\n",
    "    label: str\n",
    "    color: str\n",
    "\n",
    "class Edge(BaseModel):\n",
    "    source: int\n",
    "    target: int\n",
    "    label: str\n",
    "    color: str = \"black\"\n",
    "\n",
    "class KnowledgeGraph(BaseModel):\n",
    "    \"\"\"A knowledge graph is a graph that represents knowledge as a set of entities and relations between them.\"\"\"\n",
    "    nodes: List[Node] = Field(..., description=\"A list of nodes in the knowledge graph\")\n",
    "    edges: List[Edge] = Field(..., description=\"A list of edges in the knowledge graph\")\n",
    "\n",
    "\n",
    "def visualize_knowledge_graph(kg: KnowledgeGraph):\n",
    "    dot = Digraph(comment=\"Knowledge Graph\")\n",
    "\n",
    "    # Add nodes\n",
    "    for node in kg.nodes:\n",
    "        dot.node(str(node.id), node.label, color=node.color)\n",
    "\n",
    "    # Add edges\n",
    "    for edge in kg.edges:\n",
    "        dot.edge(str(edge.source), str(edge.target), label=edge.label, color=edge.color)\n",
    "\n",
    "    # Render the graph\n",
    "    display(graphviz.Source(dot.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's modify the `chain_diagram()` function to output a schema that's appropriate for generating a knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"nodes\": [\\n    {\"id\": 1, \"label\": \"Random Variable\", \"color\": \"lightblue\"},\\n    {\"id\": 2, \"label\": \"Probability Distribution\", \"color\": \"lightblue\"},\\n    {\"id\": 3, \"label\": \"Joint Probability Mass Function\", \"color\": \"lightgreen\"},\\n    {\"id\": 4, \"label\": \"Discrete Random Variables\", \"color\": \"lightblue\"},\\n    {\"id\": 5, \"label\": \"Probability Mass Function\", \"color\": \"lightgreen\"}\\n  ],\\n  \"edges\": [\\n    {\"source\": 1, \"target\": 2, \"label\": \"has\", \"color\": \"black\"},\\n    {\"source\": 2, \"target\": 3, \"label\": \"has\", \"color\": \"black\"},\\n    {\"source\": 1, \"target\": 4, \"label\": \"is a\", \"color\": \"black\"},\\n    {\"source\": 4, \"target\": 5, \"label\": \"has\", \"color\": \"black\"}\\n  ]\\n}', 'name': 'KnowledgeGraph'}})"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "openai_function_knowledge_graph = convert_pydantic_to_openai_function(KnowledgeGraph)\n",
    "\n",
    "llm_chat = ChatOpenAI()    \n",
    "llm_with_tools = llm_chat.bind(functions=[openai_function_knowledge_graph])\n",
    "\n",
    "chain = chain_diagram(llm_with_tools)\n",
    "concept = \"joint probability mass function\"\n",
    "\n",
    "output_graph = chain.invoke({\"concept\": concept})\n",
    "output_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we are getting the right output, which we can access like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"nodes\": [\\n    {\"id\": 1, \"label\": \"Random Variable\", \"color\": \"lightblue\"},\\n    {\"id\": 2, \"label\": \"Probability Distribution\", \"color\": \"lightblue\"},\\n    {\"id\": 3, \"label\": \"Joint Probability Mass Function\", \"color\": \"lightgreen\"},\\n    {\"id\": 4, \"label\": \"Discrete Random Variables\", \"color\": \"lightblue\"},\\n    {\"id\": 5, \"label\": \"Probability Mass Function\", \"color\": \"lightgreen\"}\\n  ],\\n  \"edges\": [\\n    {\"source\": 1, \"target\": 2, \"label\": \"has\", \"color\": \"black\"},\\n    {\"source\": 2, \"target\": 3, \"label\": \"has\", \"color\": \"black\"},\\n    {\"source\": 1, \"target\": 4, \"label\": \"is a\", \"color\": \"black\"},\\n    {\"source\": 4, \"target\": 5, \"label\": \"has\", \"color\": \"black\"}\\n  ]\\n}'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_graph.additional_kwargs[\"function_call\"][\"arguments\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want this output to be perfectly tailored for a function that visualizes the graph, so let's do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"nodes\": [\\n    {\"id\": 1, \"label\": \"Random Variable\", \"color\": \"lightblue\"},\\n    {\"id\": 2, \"label\": \"Probability Distribution\", \"color\": \"lightblue\"},\\n    {\"id\": 3, \"label\": \"Joint Probability Mass Function\", \"color\": \"lightgreen\"},\\n    {\"id\": 4, \"label\": \"Discrete Random Variables\", \"color\": \"lightblue\"},\\n    {\"id\": 5, \"label\": \"Probability Mass Function\", \"color\": \"lightgreen\"}\\n  ],\\n  \"edges\": [\\n    {\"source\": 1, \"target\": 2, \"label\": \"has\", \"color\": \"black\"},\\n    {\"source\": 2, \"target\": 3, \"label\": \"has\", \"color\": \"black\"},\\n    {\"source\": 1, \"target\": 4, \"label\": \"is a\", \"color\": \"black\"},\\n    {\"source\": 4, \"target\": 5, \"label\": \"has\", \"color\": \"black\"}\\n  ]\\n}'"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "pydantic_output_parser = PydanticOutputParser(pydantic_object=KnowledgeGraph)\n",
    "\n",
    "output_graph_json_dict = output_graph.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "output_graph_json_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes=[Node(id=1, label='Random Variable', color='lightblue'), Node(id=2, label='Probability Distribution', color='lightblue'), Node(id=3, label='Joint Probability Mass Function', color='lightgreen'), Node(id=4, label='Discrete Random Variables', color='lightblue'), Node(id=5, label='Probability Mass Function', color='lightgreen')], edges=[Edge(source=1, target=2, label='has', color='black'), Edge(source=2, target=3, label='has', color='black'), Edge(source=1, target=4, label='is a', color='black'), Edge(source=4, target=5, label='has', color='black')])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pydantic_output_parser.parse(output_graph_json_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! As you can see above, the output of parsing with the pydantic_output_parser is the `KnowledgeGraph` object, which we can feed into the \n",
    "`visualize_graph` function to get the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"506pt\" height=\"221pt\"\n",
       " viewBox=\"0.00 0.00 505.87 221.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 217)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-217 501.87,-217 501.87,4 -4,4\"/>\n",
       "<!-- 1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"lightblue\" cx=\"252.17\" cy=\"-195\" rx=\"75.41\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"252.17\" y=\"-189.95\" font-family=\"Times,serif\" font-size=\"14.00\">Random Variable</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"lightblue\" cx=\"138.17\" cy=\"-106.5\" rx=\"98.95\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"138.17\" y=\"-101.45\" font-family=\"Times,serif\" font-size=\"14.00\">Probability Distribution</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M230.19,-177.32C212.95,-164.24 188.74,-145.87 169.48,-131.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"171.76,-128.59 161.68,-125.34 167.53,-134.17 171.76,-128.59\"/>\n",
       "<text text-anchor=\"middle\" x=\"215.17\" y=\"-145.7\" font-family=\"Times,serif\" font-size=\"14.00\">has</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"lightblue\" cx=\"381.17\" cy=\"-106.5\" rx=\"112.26\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"381.17\" y=\"-101.45\" font-family=\"Times,serif\" font-size=\"14.00\">Discrete Random Variables</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;4 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M276.74,-177.53C296.48,-164.29 324.45,-145.54 346.47,-130.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"348.2,-133.82 354.56,-125.35 344.3,-128.01 348.2,-133.82\"/>\n",
       "<text text-anchor=\"middle\" x=\"338.54\" y=\"-145.7\" font-family=\"Times,serif\" font-size=\"14.00\">is a</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"lightgreen\" cx=\"130.17\" cy=\"-18\" rx=\"130.17\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.17\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Joint Probability Mass Function</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M136.59,-88.41C135.51,-76.76 134.06,-61.05 132.81,-47.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"136.32,-47.49 131.91,-37.86 129.35,-48.14 136.32,-47.49\"/>\n",
       "<text text-anchor=\"middle\" x=\"144.17\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">has</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"lightgreen\" cx=\"388.17\" cy=\"-18\" rx=\"109.7\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"388.17\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Probability Mass Function</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M382.55,-88.41C383.5,-76.76 384.77,-61.05 385.86,-47.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"389.33,-48.11 386.64,-37.86 382.35,-47.54 389.33,-48.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"395.17\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">has</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x162535fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kg = pydantic_output_parser.parse(output_graph_json_dict)\n",
    "\n",
    "visualize_knowledge_graph(kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yaaay victory!!! Now, let's wrap this into a modified version of the original chain by using the RunnableLambda Object to do the \n",
    "intermediary step we were doing before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"452pt\" height=\"221pt\"\n",
       " viewBox=\"0.00 0.00 452.05 221.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 217)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-217 448.05,-217 448.05,4 -4,4\"/>\n",
       "<!-- 1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#ff7f0e\" cx=\"262.06\" cy=\"-195\" rx=\"130.17\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"262.06\" y=\"-189.95\" font-family=\"Times,serif\" font-size=\"14.00\">Joint Probability Mass Function</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#1f77b4\" cx=\"158.06\" cy=\"-106.5\" rx=\"109.7\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"158.06\" y=\"-101.45\" font-family=\"Times,serif\" font-size=\"14.00\">Probability Mass Function</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#1f77b4\" d=\"M241.51,-176.91C225.99,-164 204.47,-146.1 187.17,-131.71\"/>\n",
       "<polygon fill=\"#1f77b4\" stroke=\"#1f77b4\" points=\"189.65,-129.23 179.73,-125.52 185.18,-134.61 189.65,-129.23\"/>\n",
       "<text text-anchor=\"middle\" x=\"229.43\" y=\"-145.7\" font-family=\"Times,serif\" font-size=\"14.00\">is a</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"#1f77b4\" cx=\"365.06\" cy=\"-106.5\" rx=\"78.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"365.06\" y=\"-101.45\" font-family=\"Times,serif\" font-size=\"14.00\">Random Variables</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#1f77b4\" d=\"M282.41,-176.91C297.89,-163.91 319.38,-145.87 336.56,-131.43\"/>\n",
       "<polygon fill=\"#1f77b4\" stroke=\"#1f77b4\" points=\"338.54,-134.34 343.94,-125.23 334.04,-128.98 338.54,-134.34\"/>\n",
       "<text text-anchor=\"middle\" x=\"347.81\" y=\"-145.7\" font-family=\"Times,serif\" font-size=\"14.00\">relates to</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"#1f77b4\" cx=\"82.06\" cy=\"-18\" rx=\"82.06\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"82.06\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Discrete Outcomes</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#1f77b4\" d=\"M143.04,-88.41C132.01,-75.85 116.84,-58.58 104.38,-44.41\"/>\n",
       "<polygon fill=\"#1f77b4\" stroke=\"#1f77b4\" points=\"107.27,-42.39 98.04,-37.19 102.01,-47.01 107.27,-42.39\"/>\n",
       "<text text-anchor=\"middle\" x=\"136.43\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">is a</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"#1f77b4\" cx=\"234.06\" cy=\"-18\" rx=\"51.86\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.06\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Probability</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;5 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#1f77b4\" d=\"M173.08,-88.41C184.25,-75.69 199.68,-58.13 212.22,-43.86\"/>\n",
       "<polygon fill=\"#1f77b4\" stroke=\"#1f77b4\" points=\"214.62,-46.43 218.59,-36.6 209.36,-41.81 214.62,-46.43\"/>\n",
       "<text text-anchor=\"middle\" x=\"229.31\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">computes</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x161e78290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "chain = chain_diagram(llm_with_tools)\n",
    "\n",
    "\n",
    "def chain_diagram_viz(llm):\n",
    "    \"\"\"Full chain to generate the formatted knowledge graph\"\"\"\n",
    "    openai_function_knowledge_graph = convert_pydantic_to_openai_function(KnowledgeGraph)\n",
    "    llm_chat = ChatOpenAI()    \n",
    "    llm_with_tools = llm_chat.bind(functions=[openai_function_knowledge_graph])\n",
    "    pydantic_output_parser = PydanticOutputParser(pydantic_object=KnowledgeGraph)\n",
    "    return ChatPromptTemplate.from_template(\"Write a knowledge graph with the necessary concepts and elements to understand the following concept: '''{concept}''', this diagram should perfectly encapsulate\\\n",
    "        what it is and what it relates to.\") | llm_with_tools | RunnableLambda(lambda x: x.additional_kwargs[\"function_call\"][\"arguments\"]) | pydantic_output_parser\n",
    "    \n",
    "concept = \"joint probability mass function\" \n",
    "\n",
    "output_graph = chain_diagram_viz(llm_with_tools).invoke({\"concept\": concept})\n",
    "visualize_knowledge_graph(output_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! How about we put everything together under a class that represents this LangChain implementation of the ADEPT method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "@dataclass\n",
    "class ADEPT:\n",
    "    concept: str\n",
    "    llm_chat = ChatOpenAI()\n",
    "    \n",
    "    def chain_analogy(self):\n",
    "        return ChatPromptTemplate.from_template(\"Write a simple analogy for this concept: '''{concept}''', which should perfectly encapsulate\\\n",
    "            what it is.\") | llm_chat\n",
    "\n",
    "    \n",
    "    def chain_diagram_viz(self):\n",
    "        \"\"\"Full chain to generate the formatted knowledge graph\"\"\"\n",
    "        openai_function_knowledge_graph = convert_pydantic_to_openai_function(KnowledgeGraph) \n",
    "        llm_with_tools = llm_chat.bind(functions=[openai_function_knowledge_graph])\n",
    "        pydantic_output_parser = PydanticOutputParser(pydantic_object=KnowledgeGraph)\n",
    "        return ChatPromptTemplate.from_template(\"Write a knowledge graph with the necessary concepts and elements to understand the following concept: '''{concept}''', this diagram should perfectly encapsulate\\\n",
    "            what it is and what it relates to.\") | llm_with_tools | RunnableLambda(lambda x: x.additional_kwargs[\"function_call\"][\"arguments\"]) | pydantic_output_parser\n",
    "        \n",
    "\n",
    "    def chain_example(self):\n",
    "        return ChatPromptTemplate.from_template(\"Write down five examples that perfectly demonstrate this concept: '''{concept}'''. \") | llm_chat\n",
    "\n",
    "\n",
    "    def chain_plain_english(self):\n",
    "        return ChatPromptTemplate.from_template(\"Write a plain english definition for this concept: '''{concept}'''\") | llm_chat\n",
    "\n",
    "\n",
    "    def chain_technical_definition(self):\n",
    "        return ChatPromptTemplate.from_template(\"Write a short and precise technical definition for this concept: '''{concept}'''\") | llm_chat\n",
    "    \n",
    "    def visualize_knowledge_graph(self, kg: KnowledgeGraph):\n",
    "        dot = Digraph(comment=\"Knowledge Graph\")\n",
    "\n",
    "        # Add nodes\n",
    "        for node in kg.nodes:\n",
    "            dot.node(str(node.id), node.label, color=node.color)\n",
    "\n",
    "        # Add edges\n",
    "        for edge in kg.edges:\n",
    "            dot.edge(str(edge.source), str(edge.target), label=edge.label, color=edge.color)\n",
    "\n",
    "        # Render the graph\n",
    "        display(graphviz.Source(dot.source))\n",
    "        \n",
    "    # now let's write a __call__ method that runs all of the chains and generates a nice output just from the concept input.\n",
    "    def __call__(self):\n",
    "        analogy_chain = self.chain_analogy()\n",
    "        diagram_chain = self.chain_diagram_viz()\n",
    "        example_chain = self.chain_example()\n",
    "        plain_english_chain = self.chain_plain_english()\n",
    "        technical_definition_chain = self.chain_technical_definition()\n",
    "        map_chain = RunnableParallel(analogy=analogy_chain, diagram=diagram_chain, example=example_chain, \n",
    "                             plain_english=plain_english_chain, technical_def=technical_definition_chain)\n",
    "        output_explanation = map_chain.invoke({\"concept\": self.concept})\n",
    "        return output_explanation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADEPT(concept='joint probability mass function')"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept = \"joint probability mass function\"\n",
    "\n",
    "adept = ADEPT(concept)\n",
    "adept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_explanation = adept()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"268pt\" height=\"221pt\"\n",
       " viewBox=\"0.00 0.00 268.34 221.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 217)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-217 264.34,-217 264.34,4 -4,4\"/>\n",
       "<!-- 1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"blue\" cx=\"130.17\" cy=\"-195\" rx=\"75.41\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.17\" y=\"-189.95\" font-family=\"Times,serif\" font-size=\"14.00\">Random Variable</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"orange\" cx=\"130.17\" cy=\"-106.5\" rx=\"109.7\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.17\" y=\"-101.45\" font-family=\"Times,serif\" font-size=\"14.00\">Probability Mass Function</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130.17,-176.91C130.17,-165.26 130.17,-149.55 130.17,-136.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"133.67,-136.36 130.17,-126.36 126.67,-136.36 133.67,-136.36\"/>\n",
       "<text text-anchor=\"middle\" x=\"151.17\" y=\"-145.7\" font-family=\"Times,serif\" font-size=\"14.00\">Defines</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"green\" cx=\"130.17\" cy=\"-18\" rx=\"130.17\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.17\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Joint Probability Mass Function</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130.17,-88.41C130.17,-76.76 130.17,-61.05 130.17,-47.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"133.67,-47.86 130.17,-37.86 126.67,-47.86 133.67,-47.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"151.17\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">Defines</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x163034750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diagram = output_explanation[\"diagram\"]\n",
    "\n",
    "adept.visualize_knowledge_graph(diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A joint probability mass function is like a recipe book for a potluck party. Just as the recipe book tells you the likelihood of different dishes being prepared by different people, the joint probability mass function tells you the likelihood of different combinations of events occurring together.'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_explanation[\"analogy\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1) Suppose we have two dice, one fair and the other biased. The joint probability mass function can be used to calculate the probability of obtaining a sum of 7 when rolling both dice simultaneously. \\n\\n2) In a card game, the joint probability mass function can be used to determine the probability of drawing two cards of the same suit from a standard deck of cards. \\n\\n3) When conducting a survey, the joint probability mass function can be used to calculate the probability of two participants giving the same response to a particular question. \\n\\n4) In a sports tournament, the joint probability mass function can be used to calculate the probability of two teams facing each other in the final match, given their performance in earlier rounds. \\n\\n5) In a genetics experiment, the joint probability mass function can be used to determine the probability of obtaining a certain combination of genes in an offspring, based on the genetic makeup of the parents.'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_explanation[\"example\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A joint probability mass function is a way to calculate the probability of two or more random variables occurring at the same time. It helps us understand the likelihood of different combinations of outcomes happening together.'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_explanation[\"plain_english\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A joint probability mass function refers to a mathematical function that assigns probabilities to all possible combinations of values in multiple discrete random variables. It provides a measure of the likelihood of simultaneous occurrences of specific outcomes in the variables under consideration.'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_explanation[\"technical_def\"].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-langchain",
   "language": "python",
   "name": "oreilly-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
