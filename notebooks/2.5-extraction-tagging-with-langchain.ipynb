{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heavily inspired by this course: https://learn.deeplearning.ai/functions-tools-agents-langchain/lesson/5/tagging-and-extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging and Extraction Using OpenAI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import openai\n",
    "\n",
    "# from dotenv import load_dotenv, find_dotenv\n",
    "# _ = load_dotenv(find_dotenv()) # read local .env file\n",
    "# openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class TaggingRefsUrls(BaseModel):\n",
    "    \"\"\"Extracting URLs from a paper references section.\"\"\"\n",
    "    urls: List[str] = Field(description=\"A list of urls from the references section of a paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'TaggingRefsUrls',\n",
       " 'description': 'Extracting URLs from a paper references section.',\n",
       " 'parameters': {'description': 'Extracting URLs from a paper references section.',\n",
       "  'properties': {'urls': {'description': 'A list of urls from the references section of a paper',\n",
       "    'items': {'type': 'string'},\n",
       "    'title': 'Urls',\n",
       "    'type': 'array'}},\n",
       "  'required': ['urls'],\n",
       "  'title': 'TaggingRefsUrls',\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "\n",
    "convert_pydantic_to_openai_function(TaggingRefsUrls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(temperature=0)\n",
    "\n",
    "tagging_functions = [convert_pydantic_to_openai_function(TaggingRefsUrls)]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Think carefully, and then tag the text as instructed\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "model_with_functions = model.bind(\n",
    "    functions=tagging_functions,\n",
    "    function_call={\"name\": \"TaggingRefsUrls\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Think carefully, and then tag the text as instructed')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "| RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x1170f0d10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x11740ca50>, temperature=0.0, openai_api_key='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', openai_proxy=''), kwargs={'functions': [{'name': 'TaggingRefsUrls', 'description': 'Extracting URLs from a paper references section.', 'parameters': {'description': 'Extracting URLs from a paper references section.', 'properties': {'urls': {'description': 'A list of urls from the references section of a paper', 'items': {'type': 'string'}, 'title': 'Urls', 'type': 'array'}}, 'required': ['urls'], 'title': 'TaggingRefsUrls', 'type': 'object'}}], 'function_call': {'name': 'TaggingRefsUrls'}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_urls_chain = prompt | model_with_functions\n",
    "\n",
    "tagging_urls_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"urls\": [\\n    \"arXiv:2212.10466\",\\n    \"arXiv:2304.05128\",\\n    \"arXiv:2110.14168\",\\n    \"https://aclanthology.org/2022.emnlp-main.222\",\\n    \"arXiv:2309.16797\",\\n    \"https://noahgoodman.substack.com/p/meta-prompt-a-simple-self-improving\",\\n    \"https://aclanthology.org/2023.acl-long.108\"\\n  ]\\n}', 'name': 'TaggingRefsUrls'}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refs_string = \"\"\"REFERENCES\n",
    "Howard Chen, Huihan Li, Danqi Chen, and Karthik Narasimhan. Controllable text generation with\n",
    "language constraints. arXiv preprint arXiv:2212.10466, 2022.\n",
    "Xinyun Chen, Maxwell Lin, Nathanael Scharli, and Denny Zhou. Teaching large language models ¨\n",
    "to self-debug. arXiv preprint arXiv:2304.05128, 2023.\n",
    "Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,\n",
    "Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to\n",
    "solve math word problems. arXiv preprint arXiv:2110.14168, 2021.\n",
    "Mingkai Deng, Jianyu Wang, Cheng-Ping Hsieh, Yihan Wang, Han Guo, Tianmin Shu, Meng Song,\n",
    "Eric Xing, and Zhiting Hu. RLPrompt: Optimizing discrete text prompts with reinforcement\n",
    "learning. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language\n",
    "Processing, pp. 3369–3391, Abu Dhabi, United Arab Emirates, December 2022. Association for\n",
    "Computational Linguistics. doi: 10.18653/v1/2022.emnlp-main.222. URL https://aclanthology.\n",
    "org/2022.emnlp-main.222.\n",
    "Chrisantha Fernando, Dylan Banarse, Henryk Michalewski, Simon Osindero, and Tim Rocktaschel. ¨\n",
    "Promptbreeder: Self-referential self-improvement via prompt evolution. arXiv preprint\n",
    "arXiv:2309.16797, 2023.\n",
    "Noah Goodman. Meta-prompt: A simple self-improving language agent, 2023. URL https:\n",
    "//noahgoodman.substack.com/p/meta-prompt-a-simple-self-improving.\n",
    "Or Honovich, Uri Shaham, Samuel R. Bowman, and Omer Levy. Instruction induction: From few\n",
    "examples to natural language task descriptions. In Proceedings of the 61st Annual Meeting of the\n",
    "Association for Computational Linguistics (Volume 1: Long Papers), pp. 1935–1952, Toronto,\n",
    "Canada, July 2023. Association for Computational Linguistics. doi: 10.18653/v1/2023.acl-long.\n",
    "108. URL https://aclanthology.org/2023.acl-long.108.\n",
    "1\"\"\"\n",
    "tagging_urls_chain.invoke({\"input\": refs_string})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'urls': ['arXiv:2212.10466',\n",
       "  'arXiv:2304.05128',\n",
       "  'arXiv:2110.14168',\n",
       "  'https://aclanthology.org/2022.emnlp-main.222',\n",
       "  'arXiv:2309.16797',\n",
       "  'https://noahgoodman.substack.com/p/meta-prompt-a-simple-self-improving',\n",
       "  'https://aclanthology.org/2023.acl-long.108']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "\n",
    "tagging_urls_chain = prompt | model_with_functions | JsonOutputFunctionsParser()\n",
    "\n",
    "tagging_urls_chain.invoke({\"input\": refs_string})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction\n",
    "\n",
    "Extraction is used for extracting multiple pieces of information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(description=\"person's name\")\n",
    "    age: Optional[int] = Field(description=\"person's age\")\n",
    "\n",
    "class Information(BaseModel):\n",
    "    \"\"\"Information to extract.\"\"\"\n",
    "    people: List[Person] = Field(description=\"List of info about people\")\n",
    "\n",
    "convert_pydantic_to_openai_function(Information)\n",
    "\n",
    "extraction_functions = [convert_pydantic_to_openai_function(Information)]\n",
    "extraction_model = model.bind(functions=extraction_functions, function_call={\"name\": \"Information\"})\n",
    "\n",
    "extraction_model.invoke(\"Joe is 30, his mom is Martha\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "extraction_chain = prompt | extraction_model\n",
    "\n",
    "extraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})\n",
    "\n",
    "extraction_chain = prompt | extraction_model | JsonOutputFunctionsParser()\n",
    "\n",
    "extraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})\n",
    "\n",
    "from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser\n",
    "\n",
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"people\")\n",
    "\n",
    "extraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-langchain",
   "language": "python",
   "name": "oreilly-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
