{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./assets-resources/pydantic.png\" width=400> </img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Functions \n",
    "\n",
    "Allow you to format the output of an llm to input to a function. Meaning allows you to call functions from outputs of LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a traditional [openai function for function calling](https://platform.openai.com/docs/guides/function-calling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"weather_search\",\n",
    "      \"description\": \"Search for weather given an airport code\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"airport_code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The airport code to get the weather for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"airport_code\"]\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can bind this function to a model using the `.bind` method from the ChatOpenAI object (or any `ChatModel` object in langchain for that matter.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "     (\"human\", \"{input}\")   \n",
    "    ]\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(temperature=0).bind(functions=functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we can create our runnable with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is the same as saying chain = prompt | model\n",
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and we can call it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"airport_code\": \"LIS\"\\n}', 'name': 'weather_search'}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"input\": \"What's the weather like in Lisbon?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's update the `functions` variable and add another function.\n",
    "\n",
    "Let's say search for relevant resources given a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"weather_search\",\n",
    "      \"description\": \"Search for weather given an airport code\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"airport_code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The airport code to get the weather for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"airport_code\"]\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"resources_search\",\n",
    "      \"description\": \"Search for relevant resources given a query\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The query describing the subject of the resources\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"query\"]\n",
    "      }\n",
    "    }\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take that same model and bind these functions to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"query\": \"langchain Python library\"\\n}', 'name': 'resources_search'}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"input\": \"What are the most useful resources of the langchain Python library?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted the model to put a json object rather than some string or some object?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'names': ['Biscuit', 'Coco', 'Max', 'Lola', 'Charlie']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "import json\n",
    "\n",
    "llm_chat = ChatOpenAI(temperature=0)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "simple_chain = llm_chat | output_parser | json.loads\n",
    "\n",
    "simple_chain.invoke(\"What are fun five names for dogs?The output should be a json object.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we add a list of other runnables. \n",
    "\n",
    "If there is an error it will go through the list of fallback chains (meaning, other ways of processing the input in a useful way.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = simple_chain.with_fallbacks([simple_chain])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's add a prompt template to this, and explore the `.batch` option of a runnable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. Power Rule Drill: Choose a variety of functions and have students practice finding the derivative using the power rule. For example, give them functions like f(x) = x^3, g(x) = 2x^5, and h(x) = 4x^2. Have them find the derivative of each function and explain their steps.\\n\\n2. Chain Rule Drill: Provide students with composite functions and ask them to find the derivative using the chain rule. For instance, give them functions like f(x) = (2x^3 + 5x)^4 or g(x) = sin(3x^2). Have them break down the functions into their individual components and apply the chain rule to find the derivative.\\n\\n3. Product and Quotient Rule Drill: Give students functions that require the product or quotient rule to find the derivative. For example, provide them with functions like f(x) = (x^2 + 3x)(2x - 1) or g(x) = (3x^2 + 2x)/(x - 1). Have them apply the appropriate rule and simplify their answers.',\n",
       " \"1. Simple Linear Regression Exercise:\\n- Choose a dataset with two variables, such as height and weight.\\n- Use the linear regression formula to calculate the slope and intercept of the best-fit line.\\n- Plot the data points and the best-fit line on a graph.\\n- Calculate the coefficient of determination (R-squared) to evaluate the goodness of fit.\\n\\n2. Multiple Linear Regression Exercise:\\n- Select a dataset with multiple independent variables, such as age, income, and education level, and a dependent variable like house price.\\n- Use multiple linear regression to determine the coefficients for each independent variable.\\n- Interpret the coefficients to understand the impact of each variable on the dependent variable.\\n- Evaluate the model's performance by calculating the R-squared and adjusted R-squared values.\\n\\n3. Residual Analysis Exercise:\\n- Choose a dataset with a dependent variable and multiple independent variables.\\n- Perform linear regression and obtain the predicted values.\\n- Calculate the residuals by subtracting the predicted values from the actual values.\\n- Plot the residuals against the predicted values to check for any patterns or trends.\\n- Conduct tests for heteroscedasticity and autocorrelation to assess the model's assumptions.\"]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"Create a list of 3 exercises to drill this concept: {concept}\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "llm_chat = ChatOpenAI(temperature=0)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | llm_chat | output_parser\n",
    "\n",
    "chain.batch([{\"concept\": \"derivatives\"}, {\"concept\": \"linear regression\"}])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can stream results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1\n",
      ".\n",
      " Power\n",
      " Rule\n",
      " Drill\n",
      ":\n",
      " Choose\n",
      " a\n",
      " variety\n",
      " of\n",
      " functions\n",
      " and\n",
      " have\n",
      " students\n",
      " practice\n",
      " finding\n",
      " the\n",
      " derivative\n",
      " using\n",
      " the\n",
      " power\n",
      " rule\n",
      ".\n",
      " For\n",
      " example\n",
      ",\n",
      " give\n",
      " them\n",
      " functions\n",
      " like\n",
      " f\n",
      "(x\n",
      ")\n",
      " =\n",
      " x\n",
      "^\n",
      "3\n",
      ",\n",
      " g\n",
      "(x\n",
      ")\n",
      " =\n",
      " \n",
      "2\n",
      "x\n",
      "^\n",
      "5\n",
      ",\n",
      " and\n",
      " h\n",
      "(x\n",
      ")\n",
      " =\n",
      " \n",
      "4\n",
      "x\n",
      "^\n",
      "2\n",
      ".\n",
      " Have\n",
      " them\n",
      " find\n",
      " the\n",
      " derivative\n",
      " of\n",
      " each\n",
      " function\n",
      " and\n",
      " explain\n",
      " the\n",
      " steps\n",
      " they\n",
      " took\n",
      " to\n",
      " arrive\n",
      " at\n",
      " the\n",
      " answer\n",
      ".\n",
      "\n",
      "\n",
      "2\n",
      ".\n",
      " Chain\n",
      " Rule\n",
      " Drill\n",
      ":\n",
      " Provide\n",
      " students\n",
      " with\n",
      " composite\n",
      " functions\n",
      " and\n",
      " ask\n",
      " them\n",
      " to\n",
      " find\n",
      " the\n",
      " derivative\n",
      " using\n",
      " the\n",
      " chain\n",
      " rule\n",
      ".\n",
      " For\n",
      " instance\n",
      ",\n",
      " give\n",
      " them\n",
      " functions\n",
      " like\n",
      " f\n",
      "(x\n",
      ")\n",
      " =\n",
      " (\n",
      "2\n",
      "x\n",
      "^\n",
      "2\n",
      " +\n",
      " \n",
      "3\n",
      "x\n",
      ")^\n",
      "4\n",
      " or\n",
      " g\n",
      "(x\n",
      ")\n",
      " =\n",
      " sin\n",
      "(\n",
      "3\n",
      "x\n",
      "^\n",
      "2\n",
      ").\n",
      " Have\n",
      " them\n",
      " break\n",
      " down\n",
      " the\n",
      " functions\n",
      " into\n",
      " their\n",
      " individual\n",
      " components\n",
      " and\n",
      " apply\n",
      " the\n",
      " chain\n",
      " rule\n",
      " to\n",
      " find\n",
      " the\n",
      " derivative\n",
      ".\n",
      "\n",
      "\n",
      "3\n",
      ".\n",
      " Product\n",
      " Rule\n",
      " Drill\n",
      ":\n",
      " Give\n",
      " students\n",
      " functions\n",
      " that\n",
      " require\n",
      " the\n",
      " product\n",
      " rule\n",
      " to\n",
      " find\n",
      " the\n",
      " derivative\n",
      ".\n",
      " For\n",
      " example\n",
      ",\n",
      " provide\n",
      " them\n",
      " with\n",
      " functions\n",
      " like\n",
      " f\n",
      "(x\n",
      ")\n",
      " =\n",
      " x\n",
      "^\n",
      "2\n",
      " *\n",
      " sin\n",
      "(x\n",
      ")\n",
      " or\n",
      " g\n",
      "(x\n",
      ")\n",
      " =\n",
      " (\n",
      "2\n",
      "x\n",
      " +\n",
      " \n",
      "1\n",
      ")(\n",
      "3\n",
      "x\n",
      " -\n",
      " \n",
      "2\n",
      ").\n",
      " Have\n",
      " them\n",
      " apply\n",
      " the\n",
      " product\n",
      " rule\n",
      " to\n",
      " find\n",
      " the\n",
      " derivative\n",
      " and\n",
      " simplify\n",
      " the\n",
      " expression\n",
      " as\n",
      " much\n",
      " as\n",
      " possible\n",
      ".\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# /Users/greatmaster/Desktop/projects/oreilly-live-trainings/oreilly_live_training_getting_started_with_langchain/notebooks/2.1-LCEL-interface.ipynb\n",
    "outputs = []\n",
    "streaming_output = \"\"\n",
    "for t in chain.stream({\"concept\": \"derivatives\"}):\n",
    "    print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-langchain",
   "language": "python",
   "name": "oreilly-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
