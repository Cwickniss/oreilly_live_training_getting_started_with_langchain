{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain\n",
    "%pip install pydantic\n",
    "%pip install langchain-openai\n",
    "%pip install tiktoken\n",
    "%pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# Set OPENAI API Key\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key:\")\n",
    "\n",
    "# OR (load from .env file)\n",
    "# make sure you have python-dotenv installed\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(\"./.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Trying Out Different Learning Acronyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADEPT\n",
    "\n",
    "- A:= analogy\n",
    "- D:= diagram\n",
    "- E:= example\n",
    "- P:= plain english\n",
    "- T:= technical definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This still needs a bridge into what the person cares about. So teachiing some formalization technique or trick to bring that person's interests into the problem/concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analogy': AIMessage(content='A joint probability mass function is like a recipe that shows the likelihood of two ingredients being used together in a dish.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 32, 'total_tokens': 55, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-98fd3b8d-213b-4210-a2c6-39de8133b647-0', usage_metadata={'input_tokens': 32, 'output_tokens': 23, 'total_tokens': 55, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       " 'diagram': AIMessage(content='A joint probability mass function is a function that gives the probability that two or more discrete random variables X and Y take on specific values x and y. It is denoted as P(X=x, Y=y) or P(x, y).\\n\\nKey Concepts:\\n1. Random Variables: Variables that can take on different values as outcomes of a random phenomenon.\\n2. Discrete Random Variables: Random variables that can only take on a countable number of distinct values.\\n3. Probability Mass Function (PMF): A function that gives the probability of a discrete random variable taking on a specific value.\\n4. Joint Probability Mass Function: A function that gives the probability of two or more discrete random variables taking on specific values simultaneously.\\n5. Marginal Probability: The probability of a single event occurring without consideration of any other events.\\n6. Conditional Probability: The probability of an event occurring given that another event has already occurred.\\n\\nElements:\\n- X and Y: Discrete random variables that are being considered.\\n- P(X=x, Y=y): The joint probability mass function for variables X and Y.\\n- Marginal Probability: P(X=x) and P(Y=y) representing the probabilities of individual events.\\n- Conditional Probability: P(X=x | Y=y) and P(Y=y | X=x) representing the probability of one event given another event.\\n\\nRelations:\\n- Joint Probability Mass Function relates the probabilities of multiple random variables occurring together.\\n- Marginal probabilities can be calculated from the joint probability mass function by summing or averaging over the other variable.\\n- Conditional probabilities can be calculated from the joint probability mass function by considering the events of one variable given the occurrence of another variable.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 334, 'prompt_tokens': 46, 'total_tokens': 380, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-23ede133-b59a-4c83-83fc-06c264bb53b8-0', usage_metadata={'input_tokens': 46, 'output_tokens': 334, 'total_tokens': 380, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       " 'example': AIMessage(content='1. The joint probability mass function of rolling a fair six-sided die twice and getting a 1 on the first roll and a 2 on the second roll is 1/36.\\n2. The joint probability mass function of flipping two fair coins and getting heads on both flips is 1/4.\\n3. The joint probability mass function of drawing two cards from a standard deck of 52 cards without replacement and getting a red card followed by a black card is 26/51 * 26/50.\\n4. The joint probability mass function of selecting two balls from an urn containing 3 red balls and 2 blue balls without replacement and getting a red ball followed by a blue ball is 3/5 * 2/4.\\n5. The joint probability mass function of selecting two marbles from a bag containing 5 red marbles and 3 blue marbles with replacement and getting a red marble followed by a blue marble is (5/8) * (3/8).', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 202, 'prompt_tokens': 25, 'total_tokens': 227, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-04c7618b-de26-4a38-bbbb-33c5987be194-0', usage_metadata={'input_tokens': 25, 'output_tokens': 202, 'total_tokens': 227, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       " 'plain_english': AIMessage(content='A joint probability mass function is a mathematical function that assigns probabilities to different combinations of outcomes from two or more random variables in a discrete probability distribution.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 22, 'total_tokens': 51, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-ecb42b64-cbaa-4262-91dd-97a61ce407b7-0', usage_metadata={'input_tokens': 22, 'output_tokens': 29, 'total_tokens': 51, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}}),\n",
       " 'technical_def': AIMessage(content='A joint probability mass function is a function that assigns probabilities to the various combinations of outcomes for multiple random variables in a discrete probability distribution.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 24, 'total_tokens': 51, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-eed5cefd-dab2-41eb-a509-7bf23786f44f-0', usage_metadata={'input_tokens': 24, 'output_tokens': 27, 'total_tokens': 51, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def chain_analogy(llm): \n",
    "    return ChatPromptTemplate.from_template(\"Write a simple analogy for this concept: '''{concept}''', which should perfectly encapsulate\\\n",
    "        what it is.\") | llm\n",
    "\n",
    "def chain_diagram(llm):\n",
    "    return ChatPromptTemplate.from_template(\"Write a knowledge graph with the necessary concepts and elements to understand the following concept: '''{concept}''', this diagram should perfectly encapsulate\\\n",
    "        what it is and what it relates to.\") | llm\n",
    "\n",
    "def chain_example(llm):\n",
    "    return ChatPromptTemplate.from_template(\"Write down five examples that perfectly demonstrate this concept: '''{concept}'''. \") | llm\n",
    "\n",
    "\n",
    "def chain_plain_english(llm):\n",
    "    return ChatPromptTemplate.from_template(\"Write a plain english definition for this concept: '''{concept}'''\") | llm\n",
    "\n",
    "\n",
    "def chain_technical_definition(llm):\n",
    "    return ChatPromptTemplate.from_template(\"Write a short and precise technical definition for this concept: '''{concept}'''\") | llm\n",
    "\n",
    "\n",
    "llm_chat = ChatOpenAI()\n",
    "\n",
    "analogy_chain = chain_analogy(llm_chat)\n",
    "diagram_chain = chain_diagram(llm_chat)\n",
    "example_chain = chain_example(llm_chat)\n",
    "plain_english_chain = chain_plain_english(llm_chat)\n",
    "technical_definition_chain = chain_technical_definition(llm_chat)\n",
    "\n",
    "\n",
    "concept = \"joint probability mass function\"\n",
    "map_chain = RunnableParallel(analogy=analogy_chain, diagram=diagram_chain, example=example_chain, \n",
    "                             plain_english=plain_english_chain, technical_def=technical_definition_chain)\n",
    "output_explanation = map_chain.invoke({\"concept\": concept})\n",
    "output_explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**analogy**\n",
       "\n",
       "A joint probability mass function is like a recipe that shows the likelihood of two ingredients being used together in a dish.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**diagram**\n",
       "\n",
       "A joint probability mass function is a function that gives the probability that two or more discrete random variables X and Y take on specific values x and y. It is denoted as P(X=x, Y=y) or P(x, y).\n",
       "\n",
       "Key Concepts:\n",
       "1. Random Variables: Variables that can take on different values as outcomes of a random phenomenon.\n",
       "2. Discrete Random Variables: Random variables that can only take on a countable number of distinct values.\n",
       "3. Probability Mass Function (PMF): A function that gives the probability of a discrete random variable taking on a specific value.\n",
       "4. Joint Probability Mass Function: A function that gives the probability of two or more discrete random variables taking on specific values simultaneously.\n",
       "5. Marginal Probability: The probability of a single event occurring without consideration of any other events.\n",
       "6. Conditional Probability: The probability of an event occurring given that another event has already occurred.\n",
       "\n",
       "Elements:\n",
       "- X and Y: Discrete random variables that are being considered.\n",
       "- P(X=x, Y=y): The joint probability mass function for variables X and Y.\n",
       "- Marginal Probability: P(X=x) and P(Y=y) representing the probabilities of individual events.\n",
       "- Conditional Probability: P(X=x | Y=y) and P(Y=y | X=x) representing the probability of one event given another event.\n",
       "\n",
       "Relations:\n",
       "- Joint Probability Mass Function relates the probabilities of multiple random variables occurring together.\n",
       "- Marginal probabilities can be calculated from the joint probability mass function by summing or averaging over the other variable.\n",
       "- Conditional probabilities can be calculated from the joint probability mass function by considering the events of one variable given the occurrence of another variable.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**example**\n",
       "\n",
       "1. The joint probability mass function of rolling a fair six-sided die twice and getting a 1 on the first roll and a 2 on the second roll is 1/36.\n",
       "2. The joint probability mass function of flipping two fair coins and getting heads on both flips is 1/4.\n",
       "3. The joint probability mass function of drawing two cards from a standard deck of 52 cards without replacement and getting a red card followed by a black card is 26/51 * 26/50.\n",
       "4. The joint probability mass function of selecting two balls from an urn containing 3 red balls and 2 blue balls without replacement and getting a red ball followed by a blue ball is 3/5 * 2/4.\n",
       "5. The joint probability mass function of selecting two marbles from a bag containing 5 red marbles and 3 blue marbles with replacement and getting a red marble followed by a blue marble is (5/8) * (3/8).\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**plain_english**\n",
       "\n",
       "A joint probability mass function is a mathematical function that assigns probabilities to different combinations of outcomes from two or more random variables in a discrete probability distribution.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**technical_def**\n",
       "\n",
       "A joint probability mass function is a function that assigns probabilities to the various combinations of outcomes for multiple random variables in a discrete probability distribution.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "for key in output_explanation.keys():\n",
    "    display(Markdown(f\"**{key}**\\n\\n{output_explanation[key].content}\\n\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is nice but can we make it better? Like the knowledge graph is not visual, how can we improve upon that? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# from pydantic import BaseModel, Field\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "from graphviz import Digraph\n",
    "import argparse\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "import graphviz\n",
    "from IPython.display import display\n",
    "\n",
    "class Node(BaseModel):\n",
    "    id: int\n",
    "    label: str\n",
    "    color: str\n",
    "\n",
    "class Edge(BaseModel):\n",
    "    source: int\n",
    "    target: int\n",
    "    label: str\n",
    "    color: str = \"black\"\n",
    "\n",
    "class KnowledgeGraph(BaseModel):\n",
    "    \"\"\"A knowledge graph is a graph that represents knowledge as a set of entities and relations between them.\"\"\"\n",
    "    nodes: List[Node] = Field(..., description=\"A list of nodes in the knowledge graph\")\n",
    "    edges: List[Edge] = Field(..., description=\"A list of edges in the knowledge graph\")\n",
    "\n",
    "\n",
    "def visualize_knowledge_graph(kg: KnowledgeGraph):\n",
    "    dot = Digraph(comment=\"Knowledge Graph\")\n",
    "\n",
    "    # Add nodes\n",
    "    for node in kg.nodes:\n",
    "        dot.node(str(node.id), node.label, color=node.color)\n",
    "\n",
    "    # Add edges\n",
    "    for edge in kg.edges:\n",
    "        dot.edge(str(edge.source), str(edge.target), label=edge.label, color=edge.color)\n",
    "\n",
    "    # Render the graph\n",
    "    display(graphviz.Source(dot.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's modify the `chain_diagram()` function to output a schema that's appropriate for generating a knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5l/y8s3fc655417629rqwgxkhx80000gn/T/ipykernel_32042/3605930416.py:2: LangChainDeprecationWarning: The function `convert_pydantic_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 1.0. Use :meth:`~langchain_core.utils.function_calling.convert_to_openai_function()` instead.\n",
      "  openai_function_knowledge_graph = convert_pydantic_to_openai_function(KnowledgeGraph)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"nodes\":[{\"id\":1,\"label\":\"Large Language Models\",\"color\":\"#ffcc00\"},{\"id\":2,\"label\":\"Natural Language Processing\",\"color\":\"#33cc33\"},{\"id\":3,\"label\":\"Machine Learning\",\"color\":\"#3366cc\"}],\"edges\":[{\"source\":1,\"target\":2,\"label\":\"is a part of\"},{\"source\":2,\"target\":3,\"label\":\"relies on\"}]}', 'name': 'KnowledgeGraph'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 96, 'prompt_tokens': 157, 'total_tokens': 253, 'completion_tokens_details': {'audio_tokens': None, 'reasoning_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run-3d13854b-95e8-46be-bfc3-601b759cd0e0-0', usage_metadata={'input_tokens': 157, 'output_tokens': 96, 'total_tokens': 253, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "openai_function_knowledge_graph = convert_pydantic_to_openai_function(KnowledgeGraph)\n",
    "\n",
    "llm_chat = ChatOpenAI()    \n",
    "llm_with_tools = llm_chat.bind(functions=[openai_function_knowledge_graph])\n",
    "\n",
    "chain = chain_diagram(llm_with_tools)\n",
    "concept = \"large language models\"\n",
    "\n",
    "output_graph = chain.invoke({\"concept\": concept})\n",
    "output_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we are getting the right output, which we can access like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"nodes\":[{\"id\":1,\"label\":\"Large Language Models\",\"color\":\"#ffcc00\"},{\"id\":2,\"label\":\"Natural Language Processing\",\"color\":\"#33cc33\"},{\"id\":3,\"label\":\"Machine Learning\",\"color\":\"#3366cc\"}],\"edges\":[{\"source\":1,\"target\":2,\"label\":\"is a part of\"},{\"source\":2,\"target\":3,\"label\":\"relies on\"}]}'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_graph.additional_kwargs[\"function_call\"][\"arguments\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want this output to be perfectly tailored for a function that visualizes the graph, so let's do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"nodes\":[{\"id\":1,\"label\":\"Large Language Models\",\"color\":\"#ffcc00\"},{\"id\":2,\"label\":\"Natural Language Processing\",\"color\":\"#33cc33\"},{\"id\":3,\"label\":\"Machine Learning\",\"color\":\"#3366cc\"}],\"edges\":[{\"source\":1,\"target\":2,\"label\":\"is a part of\"},{\"source\":2,\"target\":3,\"label\":\"relies on\"}]}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "pydantic_output_parser = PydanticOutputParser(pydantic_object=KnowledgeGraph)\n",
    "\n",
    "output_graph_json_dict = output_graph.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "output_graph_json_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes=[Node(id=1, label='Large Language Models', color='#ffcc00'), Node(id=2, label='Natural Language Processing', color='#33cc33'), Node(id=3, label='Machine Learning', color='#3366cc')], edges=[Edge(source=1, target=2, label='is a part of', color='black'), Edge(source=2, target=3, label='relies on', color='black')])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pydantic_output_parser.parse(output_graph_json_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! As you can see above, the output of parsing with the pydantic_output_parser is the `KnowledgeGraph` object, which we can feed into the \n",
    "`visualize_graph` function to get the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.0.0 (20240704.0754)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"248pt\" height=\"221pt\"\n",
       " viewBox=\"0.00 0.00 247.87 221.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 217)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-217 243.87,-217 243.87,4 -4,4\"/>\n",
       "<!-- 1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#ffcc00\" cx=\"119.93\" cy=\"-195\" rx=\"102.02\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"119.93\" y=\"-189.95\" font-family=\"Times,serif\" font-size=\"14.00\">Large Language Models</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#33cc33\" cx=\"119.93\" cy=\"-106.5\" rx=\"119.93\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"119.93\" y=\"-101.45\" font-family=\"Times,serif\" font-size=\"14.00\">Natural Language Processing</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M119.93,-176.91C119.93,-165.26 119.93,-149.55 119.93,-136.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"123.43,-136.36 119.93,-126.36 116.43,-136.36 123.43,-136.36\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.18\" y=\"-145.7\" font-family=\"Times,serif\" font-size=\"14.00\">is a part of</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"#3366cc\" cx=\"119.93\" cy=\"-18\" rx=\"79.5\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"119.93\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Machine Learning</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M119.93,-88.41C119.93,-76.76 119.93,-61.05 119.93,-47.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"123.43,-47.86 119.93,-37.86 116.43,-47.86 123.43,-47.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"143.18\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">relies on</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x11112d490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kg = pydantic_output_parser.parse(output_graph_json_dict)\n",
    "\n",
    "visualize_knowledge_graph(kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yaaay victory!!! Now, let's wrap this into a modified version of the original chain by using the RunnableLambda Object to do the \n",
    "intermediary step we were doing before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! How about we put everything together under a class that represents this LangChain implementation of the ADEPT method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "@dataclass\n",
    "class ADEPT:\n",
    "    concept: str\n",
    "    llm_chat = ChatOpenAI()\n",
    "    \n",
    "    def chain_analogy(self):\n",
    "        return ChatPromptTemplate.from_template(\"Write a simple analogy for this concept: '''{concept}''', which should perfectly encapsulate\\\n",
    "            what it is.\") | llm_chat\n",
    "\n",
    "    \n",
    "    def chain_diagram_viz(self):\n",
    "        \"\"\"Full chain to generate the formatted knowledge graph\"\"\"\n",
    "        openai_function_knowledge_graph = convert_pydantic_to_openai_function(KnowledgeGraph) \n",
    "        llm_with_tools = llm_chat.bind(functions=[openai_function_knowledge_graph])\n",
    "        pydantic_output_parser = PydanticOutputParser(pydantic_object=KnowledgeGraph)\n",
    "        return ChatPromptTemplate.from_template(\"Write a knowledge graph with the necessary concepts and elements to understand the following concept: '''{concept}''', this diagram should perfectly encapsulate\\\n",
    "            what it is and what it relates to.\") | llm_with_tools | RunnableLambda(lambda x: x.additional_kwargs[\"function_call\"][\"arguments\"]) | pydantic_output_parser\n",
    "        \n",
    "\n",
    "    def chain_example(self):\n",
    "        return ChatPromptTemplate.from_template(\"Write down five examples that perfectly demonstrate this concept: '''{concept}'''. \") | llm_chat\n",
    "\n",
    "\n",
    "    def chain_plain_english(self):\n",
    "        return ChatPromptTemplate.from_template(\"Write a plain english definition for this concept: '''{concept}'''\") | llm_chat\n",
    "\n",
    "\n",
    "    def chain_technical_definition(self):\n",
    "        return ChatPromptTemplate.from_template(\"Write a short and precise technical definition for this concept: '''{concept}'''\") | llm_chat\n",
    "    \n",
    "    def visualize_knowledge_graph(self, kg: KnowledgeGraph):\n",
    "        dot = Digraph(comment=\"Knowledge Graph\")\n",
    "\n",
    "        # Add nodes\n",
    "        for node in kg.nodes:\n",
    "            dot.node(str(node.id), node.label, color=node.color)\n",
    "\n",
    "        # Add edges\n",
    "        for edge in kg.edges:\n",
    "            dot.edge(str(edge.source), str(edge.target), label=edge.label, color=edge.color)\n",
    "\n",
    "        # Render the graph\n",
    "        display(graphviz.Source(dot.source))\n",
    "        \n",
    "    # now let's write a __call__ method that runs all of the chains and generates a nice output just from the concept input.\n",
    "    def __call__(self):\n",
    "        analogy_chain = self.chain_analogy()\n",
    "        diagram_chain = self.chain_diagram_viz()\n",
    "        example_chain = self.chain_example()\n",
    "        plain_english_chain = self.chain_plain_english()\n",
    "        technical_definition_chain = self.chain_technical_definition()\n",
    "        map_chain = RunnableParallel(analogy=analogy_chain, diagram=diagram_chain, example=example_chain, \n",
    "                             plain_english=plain_english_chain, technical_def=technical_definition_chain)\n",
    "        output_explanation = map_chain.invoke({\"concept\": self.concept})\n",
    "        return output_explanation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADEPT(concept='artificial neural networks')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept = \"artificial neural networks\"\n",
    "\n",
    "adept = ADEPT(concept)\n",
    "adept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_explanation = adept()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 12.0.0 (20240704.0754)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"428pt\" height=\"310pt\"\n",
       " viewBox=\"0.00 0.00 428.38 309.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 305.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-305.5 424.38,-305.5 424.38,4 -4,4\"/>\n",
       "<!-- 1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"blue\" cx=\"215.13\" cy=\"-283.5\" rx=\"110.72\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"215.13\" y=\"-278.45\" font-family=\"Times,serif\" font-size=\"14.00\">Artificial Neural Networks</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"orange\" cx=\"165.13\" cy=\"-106.5\" rx=\"42.14\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"165.13\" y=\"-101.45\" font-family=\"Times,serif\" font-size=\"14.00\">Neurons</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M179.01,-266.17C158.11,-254.59 133.62,-236.85 121.63,-213 108.14,-186.17 125.88,-154.13 142.59,-132.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"145.27,-134.69 148.88,-124.73 139.85,-130.27 145.27,-134.69\"/>\n",
       "<text text-anchor=\"middle\" x=\"157.88\" y=\"-189.95\" font-family=\"Times,serif\" font-size=\"14.00\">Composed of</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"orange\" cx=\"318.13\" cy=\"-195\" rx=\"36\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"318.13\" y=\"-189.95\" font-family=\"Times,serif\" font-size=\"14.00\">Layers</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M235.48,-265.41C251.56,-251.91 274.12,-232.96 291.61,-218.27\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"293.67,-221.12 299.07,-212.01 289.16,-215.76 293.67,-221.12\"/>\n",
       "<text text-anchor=\"middle\" x=\"302.88\" y=\"-234.2\" font-family=\"Times,serif\" font-size=\"14.00\">Consist of</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"orange\" cx=\"361.13\" cy=\"-106.5\" rx=\"41.63\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"361.13\" y=\"-101.45\" font-family=\"Times,serif\" font-size=\"14.00\">Weights</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;6 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M286.48,-269.34C303.31,-264.22 320.58,-257.17 335.13,-247.5 371.24,-223.51 371.02,-202.05 376.13,-159 376.99,-151.72 377.61,-149.68 376.13,-142.5 375.62,-140.03 374.93,-137.51 374.13,-135.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"377.47,-133.97 370.59,-125.91 370.94,-136.5 377.47,-133.97\"/>\n",
       "<text text-anchor=\"middle\" x=\"387.38\" y=\"-189.95\" font-family=\"Times,serif\" font-size=\"14.00\">Have</text>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"orange\" cx=\"85.13\" cy=\"-18\" rx=\"85.13\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"85.13\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Activation Function</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;7 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>1&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M162.32,-267.44C150.8,-262.42 139.32,-255.9 130.13,-247.5 73.85,-196.09 76.06,-96.48 81.13,-47.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"84.59,-48.09 82.27,-37.75 77.64,-47.28 84.59,-48.09\"/>\n",
       "<text text-anchor=\"middle\" x=\"95.63\" y=\"-145.7\" font-family=\"Times,serif\" font-size=\"14.00\">Use</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;7 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>2&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M150.08,-89.23C138.35,-76.55 121.86,-58.71 108.43,-44.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"111.32,-42.16 101.96,-37.2 106.18,-46.91 111.32,-42.16\"/>\n",
       "<text text-anchor=\"middle\" x=\"149.01\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">Apply</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>3&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M299.31,-179.4C284.73,-168.47 263.77,-153.55 244.13,-142.5 231.98,-135.66 218.23,-129.17 205.65,-123.68\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"207.39,-120.62 196.82,-119.92 204.64,-127.06 207.39,-120.62\"/>\n",
       "<text text-anchor=\"middle\" x=\"290.51\" y=\"-145.7\" font-family=\"Times,serif\" font-size=\"14.00\">Contain</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>3&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M321.52,-176.67C323.95,-166.37 327.79,-153.26 333.38,-142.5 335.1,-139.2 337.14,-135.9 339.34,-132.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"342.03,-134.98 345.27,-124.89 336.44,-130.75 342.03,-134.98\"/>\n",
       "<text text-anchor=\"middle\" x=\"354.51\" y=\"-145.7\" font-family=\"Times,serif\" font-size=\"14.00\">Contain</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"orange\" cx=\"234.13\" cy=\"-195\" rx=\"30.37\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"234.13\" y=\"-189.95\" font-family=\"Times,serif\" font-size=\"14.00\">Input</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;2 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>4&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M212.25,-182.36C202.78,-176.42 192.21,-168.45 184.88,-159 179.47,-152.03 175.4,-143.41 172.4,-135.22\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"175.82,-134.41 169.42,-125.97 169.16,-136.56 175.82,-134.41\"/>\n",
       "<text text-anchor=\"middle\" x=\"213.76\" y=\"-145.7\" font-family=\"Times,serif\" font-size=\"14.00\">Connect to</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"orange\" cx=\"361.13\" cy=\"-18\" rx=\"36.51\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"361.13\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Output</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;5 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>6&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M361.13,-88.41C361.13,-76.76 361.13,-61.05 361.13,-47.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"364.63,-47.86 361.13,-37.86 357.63,-47.86 364.63,-47.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"390.76\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">Connect to</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x11122fc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diagram = output_explanation[\"diagram\"]\n",
    "\n",
    "adept.visualize_knowledge_graph(diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial neural networks are like a team of interconnected neurons in the brain working together to solve a complex puzzle.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_explanation[\"analogy\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Image recognition software that can accurately identify objects in photographs using a trained neural network.\\n2. Speech recognition technology that converts spoken words into text by processing audio signals through a neural network.\\n3. Autonomous vehicles that use neural networks to interpret sensor data and make decisions on steering, braking, and acceleration.\\n4. Virtual assistants like Siri or Alexa that use neural networks to understand and respond to natural language queries.\\n5. Predictive text algorithms on smartphones that suggest words or phrases based on user input and context, powered by neural networks.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_explanation[\"example\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial neural networks are computer algorithms designed to mimic the way the human brain processes information. They are used in machine learning and artificial intelligence to recognize patterns and make decisions based on data.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_explanation[\"plain_english\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial neural networks are computational models inspired by the structure and function of the human brain, composed of interconnected nodes (neurons) that process and transmit information through weighted connections.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_explanation[\"technical_def\"].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-langchain",
   "language": "python",
   "name": "oreilly-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
