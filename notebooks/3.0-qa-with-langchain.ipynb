{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2023-07-24-10-52-10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Simple QA System for Chatting with a PDF\n",
    "\n",
    "This part of the training will be mostly hands on with the code for building the qa PDF system with langchain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install openai\n",
    "# !pip install pypdf\n",
    "# !pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"]=\"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\"\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import ChatVectorDBChain\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500, chunk_overlap = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = './persist_directory/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = \"./assets-resources/llm_paper_know_dont_know.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(pdf_path)\n",
    "pdf_doc = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits = text_splitter.split_documents(pdf_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the vector store\n",
    "vectordb = Chroma.from_documents(all_splits, embedding=embedding,\\\n",
    "        persist_directory=persist_directory)\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages/langchain/chains/conversational_retrieval/base.py:405: UserWarning: `ChatVectorDBChain` is deprecated - please use `from langchain.chains import ConversationalRetrievalChain`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pdf_qa = ChatVectorDBChain.from_llm(ChatOpenAI(temperature=0,\\\n",
    "    model_name=\"gpt-3.5-turbo\"), vectordb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are the main contributions of this paper with regards to self-knowledge in LLMs?',\n",
       " 'chat_history': [],\n",
       " 'answer': \"The main contributions of this paper with regards to self-knowledge in LLMs are:\\n\\n1. Development of a new dataset called SelfAware: The paper introduces a diverse range of commonly posed unanswerable questions in this dataset. It comprises 1,032 unanswerable questions distributed across five distinct categories, along with an additional 2,337 answerable questions.\\n\\n2. Proposal of an innovative evaluation technique: The paper proposes an evaluation technique based on text similarity to quantify the degree of uncertainty inherent in model outputs. This technique helps determine whether the model's responses reflect uncertainty.\\n\\n3. Identification of a significant disparity between LLMs and humans: Through a detailed analysis of 20 LLMs benchmarked against human self-knowledge, the paper identifies a notable disparity between the self-knowledge exhibited by the most advanced LLMs (such as GPT-4) and human self-knowledge. The self-knowledge of GPT-4 measures at 75.47%, while human self-knowledge is rated at 84.93%.\\n\\nOverall, the paper contributes to the understanding of self-knowledge in LLMs by providing a new dataset, proposing an evaluation technique, and highlighting the disparity between LLMs and human self-knowledge.\"}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are the main contributions of this paper with regards to self-knowledge in LLMs?\"\n",
    "pdf_qa({\"question\": query, \"chat_history\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Long context issue in LLMs](https://arxiv.org/pdf/2303.18223.pdf)\n",
    "\n",
    "Long Context. One of the main drawbacks of Transformerbased language models is the context length is limited due to the involved quadratic computational costs in both time\n",
    "and memory. Meanwhile, there is an increasing demand\n",
    "for LLM applications with long context windows, such as\n",
    "in PDF processing and story writing [217]. ChatGPT has\n",
    "recently released an updated variant with a context window\n",
    "size of up to 16K tokens, which is much longer than the\n",
    "initial one, i.e., 4K tokens. Additionally, GPT-4 was launched\n",
    "with variants with context window of 32K tokens [46]. Next,\n",
    "we discuss two important factors that support long context\n",
    "modeling for LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb \n",
    "Below are notebook from openai cookbook on these topics of search and embeddings:\n",
    "- https://github.com/openai/openai-cookbook/blob/main/examples/Get_embeddings.ipynb\n",
    "- https://github.com/openai/openai-cookbook/blob/main/examples/Code_search.ipynb\n",
    "- https://github.com/openai/openai-cookbook/blob/main/examples/Customizing_embeddings.ipynb\n",
    "- https://github.com/openai/openai-cookbook/blob/main/examples/Embedding_Wikipedia_articles_for_search.ipynb\n",
    "- https://platform.openai.com/docs/guides/embeddings/what-are-embeddings\n",
    "- [In-context learning abilities of ChatGPT models](https://arxiv.org/pdf/2303.18223.pdf)\n",
    "- [Issue with long context](https://arxiv.org/pdf/2303.18223.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-langchain",
   "language": "python",
   "name": "oreilly-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
