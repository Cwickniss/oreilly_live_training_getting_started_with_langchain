{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Call Without Pydantic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installs for the below cells.\n",
    "\n",
    "%pip install openai\n",
    "%pip install langchain\n",
    "%pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# # Set OPENAI API Key\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"your openai key\"\n",
    "\n",
    "# OR (load from .env file)\n",
    "# make sure you have python-dotenv installed\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(\"./.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': 25, 'Gender': 'F'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tool\n",
    "def find_name_info_from_database(name):\n",
    "    \"\"\"REturns information about a name from a database.\"\"\"\n",
    "    names_info = {\n",
    "        'Alice': {'Age': 25, 'Gender': 'F'},\n",
    "        'Bob': {'Age': 30, 'Gender': 'M'},\n",
    "        'Charlie': {'Age': 35, 'Gender': 'M'}\n",
    "    }\n",
    "    \n",
    "    return names_info[name]\n",
    "\n",
    "find_name_info_from_database.invoke(\"Alice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [find_name_info_from_database]\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Cxxg6M49lBGNJc2D3oubRI0D', 'function': {'arguments': '{\"name\":\"Alice\"}', 'name': 'find_name_info_from_database'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 71, 'total_tokens': 88}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_319be4768e', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-43fd4d71-b6b2-4c55-8d57-8b4e107c60d8-0', tool_calls=[{'name': 'find_name_info_from_database', 'args': {'name': 'Alice'}, 'id': 'call_Cxxg6M49lBGNJc2D3oubRI0D'}], usage_metadata={'input_tokens': 71, 'output_tokens': 17, 'total_tokens': 88})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Output(BaseModel):\n",
    "    info : dict = Field(..., description=\"Information about the person\")\n",
    "    \n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"You take in a request about a person and call a function to return information about that person: {name}\")\n",
    "\n",
    "chain = prompt | llm_with_tools\n",
    "\n",
    "tool_calls = chain.invoke({\"name\": \"Alice\"})\n",
    "\n",
    "tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'find_name_info_from_database',\n",
       " 'args': {'name': 'Alice'},\n",
       " 'id': 'call_Cxxg6M49lBGNJc2D3oubRI0D'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tool_calls.tool_calls[0]\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='find_name_info_from_database', description='REturns information about a name from a database.', args_schema=<class 'pydantic.v1.main.find_name_info_from_databaseSchema'>, func=<function find_name_info_from_database at 0x10bb11d00>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_tool = {\"find_name_info_from_database\": find_name_info_from_database}[output[\"name\"].lower()]\n",
    "selected_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.tools.StructuredTool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(selected_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Age': 25, 'Gender': 'F'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_output = selected_tool.invoke(output[\"args\"])\n",
    "tool_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tool Call With Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x10bd56c90>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x10bd3f2d0>, model_name='gpt-4o', openai_api_key=SecretStr('**********'), openai_api_base='https://api.openai.com/v1', openai_proxy=''), kwargs={'tools': [{'type': 'function', 'function': {'name': 'NameInfo', 'description': '', 'parameters': {'type': 'object', 'properties': {'age': {'description': 'Age of the person', 'type': 'integer'}, 'status': {'description': 'Gender of the person', 'type': 'string'}}, 'required': ['age', 'status']}}}]})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers.openai_tools import PydanticToolsParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class NameInfo(BaseModel):\n",
    "    age: int = Field(..., description=\"Age of the person\")\n",
    "    status: str = Field(..., description=\"Gender of the person\")\n",
    "                      \n",
    "prompt = ChatPromptTemplate.from_template(\"You take in a request and return info about these people: \\\n",
    "                                           Bob: [34, married], Mary: [25, single], Alice: [30, single],\\\n",
    "                                          Request: {name}.\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm_with_tools = llm.bind_tools([NameInfo])\n",
    "\n",
    "llm_with_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm_with_tools | PydanticToolsParser(tools=[NameInfo])\n",
    "\n",
    "output_info = chain.invoke({\"name\": \"Alice\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_info[0].age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'single'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_info[0].status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model = OllamaFunctions(\n",
    "    model=\"llama3\", \n",
    "    format=\"json\"\n",
    "    )\n",
    "\n",
    "model = model.bind_tools(\n",
    "    tools=[\n",
    "        {\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, \" \"e.g. San Francisco, CA\",\n",
    "                    },\n",
    "                    \"unit\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"enum\": [\"celsius\", \"fahrenheit\"],\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    function_call={\"name\": \"get_current_weather\"},\n",
    ")\n",
    "\n",
    "response = model.invoke(\"what is the weather in Singapore?\")\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-langchain",
   "language": "python",
   "name": "oreilly-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
