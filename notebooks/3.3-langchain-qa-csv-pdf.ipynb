{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Q&A Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install docarray\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Superhero Name</th>\n",
       "      <th>Superpower</th>\n",
       "      <th>Power Level</th>\n",
       "      <th>Catchphrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Captain Thunder</td>\n",
       "      <td>Bolt Manipulation</td>\n",
       "      <td>90</td>\n",
       "      <td>Feel the power of the storm!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Silver Falcon</td>\n",
       "      <td>Flight and Agility</td>\n",
       "      <td>85</td>\n",
       "      <td>Soar high, fearlessly!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mystic Shadow</td>\n",
       "      <td>Invisibility and Illusions</td>\n",
       "      <td>78</td>\n",
       "      <td>Disappear into the darkness!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Blaze Runner</td>\n",
       "      <td>Pyrokinesis</td>\n",
       "      <td>88</td>\n",
       "      <td>Burn bright and fierce!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Electra-Wave</td>\n",
       "      <td>Electric Manipulation</td>\n",
       "      <td>82</td>\n",
       "      <td>Unleash the electric waves!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Superhero Name                  Superpower  Power Level  \\\n",
       "0  Captain Thunder           Bolt Manipulation           90   \n",
       "1    Silver Falcon          Flight and Agility           85   \n",
       "2    Mystic Shadow  Invisibility and Illusions           78   \n",
       "3     Blaze Runner                 Pyrokinesis           88   \n",
       "4     Electra-Wave       Electric Manipulation           82   \n",
       "\n",
       "                    Catchphrase  \n",
       "0  Feel the power of the storm!  \n",
       "1        Soar high, fearlessly!  \n",
       "2  Disappear into the darkness!  \n",
       "3       Burn bright and fierce!  \n",
       "4   Unleash the electric waves!  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./superheroes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = 'superheroes.csv'\n",
    "loader = CSVLoader(file_path=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's set up our Vector store (we'll talk about what that is in a second):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.indexes import VectorstoreIndexCreator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorstoreIndexCreator(vectorstore_cls=DocArrayInMemorySearch).from_loaders([loader])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Tell me the catch phrase for Captain Thunder\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = index.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Captain Thunder's catchphrase is \"Feel the power of the storm!\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, cool! So, now let's backtrack a little bit and discuss what is going on.\n",
    "\n",
    "If we want LLMs to get access to our data in order to help us get insights, we have one major problem: LLMs have a limited context window, meaning they can only process a few thousand words at a time which constraints their ability to answer questions (for example) of really big documents. \n",
    "\n",
    "That's where things like embeddings and vector stores come into play, these are way of representing the data in such a way to facilitate the access by an LLM. Let's break it down, starting with embeddings:\n",
    "\n",
    "Embeddings are numerical representations of data, meaning, their a way to represent data such that the semantic information of that data is properly reflected in the distances between the data points in the embedding.\n",
    "\n",
    "That means that text with similar content will have similar vectors (which is a way of saying that they'll be closer together in the embedding)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](2023-07-30-19-29-27.png)\n",
    "\n",
    "[LangChain for LLM Application Development by Deeplearning.ai](https://learn.deeplearning.ai/langchain/lesson/1/introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's talk about vector databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vector database is a way to store these embeddings, these numerical representations that we just discussed.\n",
    "\n",
    "The pipeline is:\n",
    "- In coming document\n",
    "- Create chunks of text from that document\n",
    "- Embed each chunk\n",
    "- Store these embeddings\n",
    "\n",
    "![](2023-07-30-19-32-13.png)\n",
    "\n",
    "[LangChain for LLM Application Development by Deeplearning.ai](https://learn.deeplearning.ai/langchain/lesson/1/introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can query those embeddings stored in the vector database to get the most relevant responses!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So when we create a query, that query is first embedded and then we compare its embedding with the embeddings we have stored in the vector database. We then select the N-most similar embeddings, and pass those to the LLM.\n",
    "\n",
    "![](images/2023-07-30-19-34-48.png)\n",
    "\n",
    "[LangChain for LLM Application Development by Deeplearning.ai](https://learn.deeplearning.ai/langchain/lesson/1/introduction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Embedding__: the useful data representation that will be used as the thing (or things) we can query\n",
    "- __Vector Database__: the vectorization of the embedding chunks (the database for the embeddings where we can do the query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "\n",
    "\n",
    "![](./images/embeddings.png)\n",
    "\n",
    "![](./images/embeddings2.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Database\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![](./images/2023-07-17-12-48-28.png)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
