{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Trying Out Different Learning Acronyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ADEPT\n",
    "\n",
    "- A:= analogy\n",
    "- D:= diagram\n",
    "- E:= example\n",
    "- P:= plain english\n",
    "- T:= technical definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This still needs a bridge into what the person cares about. So teachiing some formalization technique or trick to bring that person's interests into the problem/concept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "\n",
    "# # Set OPENAI API Key\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"your openai key\"\n",
    "\n",
    "# OR (load from .env file)\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(\"./.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analogy': AIMessage(content='A joint probability mass function is like a recipe that shows how two ingredients (events) come together to create a delicious dish (probability).'),\n",
       " 'diagram': AIMessage(content='A joint probability mass function is a function that describes the probability of multiple random variables taking on specific values simultaneously. It is commonly denoted as P(X=x, Y=y) where X and Y are random variables and x and y are specific values they can take on. The joint probability mass function is used to describe the likelihood of events occurring together.\\n\\nConcepts and elements:\\n1. Joint probability mass function\\n   - Describes the probability of multiple random variables taking on specific values simultaneously\\n   - Denoted as P(X=x, Y=y)\\n\\n2. Random variables\\n   - Variables that can take on different values in a random experiment\\n   - Denoted as X and Y in the context of the joint probability mass function\\n\\n3. Probability\\n   - Likelihood of an event occurring\\n   - Expressed as a number between 0 and 1\\n\\n4. Events\\n   - Outcomes of a random experiment\\n   - Can be single events or multiple events occurring together\\n\\n5. Values\\n   - Specific outcomes that random variables can take on\\n   - Denoted as x and y in the context of the joint probability mass function\\n\\n6. Simultaneously\\n   - Events occurring at the same time or in conjunction with each other\\n   - Describes the relationship between multiple random variables in the joint probability mass function\\n\\nBy understanding the concepts and elements in this knowledge graph, one can grasp the concept of a joint probability mass function and how it relates to random variables, probability, events, values, and the idea of events occurring simultaneously.'),\n",
       " 'example': AIMessage(content='1. Rolling a fair six-sided die and flipping a fair coin at the same time, where the joint probability mass function would represent the probability of each possible outcome (e.g. getting a 3 on the die and a heads on the coin).\\n2. Drawing two cards from a standard deck without replacement, where the joint probability mass function would show the likelihood of drawing specific combinations of cards (e.g. drawing a red queen followed by a black king).\\n3. Selecting a random student from a class and recording both their gender and grade level, where the joint probability mass function would indicate the probability of each possible combination of gender and grade level.\\n4. Observing the number of cars passing through an intersection during different times of the day, where the joint probability mass function would show the likelihood of specific numbers of cars passing through at specific times.\\n5. Conducting a survey to determine both the favorite color and favorite food of participants, where the joint probability mass function would illustrate the probability of each possible combination of favorite color and favorite food.'),\n",
       " 'plain_english': AIMessage(content='A joint probability mass function is a function that assigns probabilities to different combinations of outcomes from multiple random variables in a discrete probability distribution.'),\n",
       " 'technical_def': AIMessage(content='A joint probability mass function is a function that assigns probabilities to each possible combination of values for multiple random variables in a discrete probability distribution.')}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "def chain_analogy(llm): \n",
    "    return ChatPromptTemplate.from_template(\"Write a simple analogy for this concept: '''{concept}''', which should perfectly encapsulate\\\n",
    "        what it is.\") | llm\n",
    "\n",
    "def chain_diagram(llm):\n",
    "    return ChatPromptTemplate.from_template(\"Write a knowledge graph with the necessary concepts and elements to understand the following concept: '''{concept}''', this diagram should perfectly encapsulate\\\n",
    "        what it is and what it relates to.\") | llm\n",
    "\n",
    "\n",
    "def chain_example(llm):\n",
    "    return ChatPromptTemplate.from_template(\"Write down five examples that perfectly demonstrate this concept: '''{concept}'''. \") | llm\n",
    "\n",
    "\n",
    "def chain_plain_english(llm):\n",
    "    return ChatPromptTemplate.from_template(\"Write a plain english definition for this concept: '''{concept}'''\") | llm\n",
    "\n",
    "\n",
    "def chain_technical_definition(llm):\n",
    "    return ChatPromptTemplate.from_template(\"Write a short and precise technical definition for this concept: '''{concept}'''\") | llm\n",
    "\n",
    "\n",
    "llm_chat = ChatOpenAI()\n",
    "\n",
    "analogy_chain = chain_analogy(llm_chat)\n",
    "diagram_chain = chain_diagram(llm_chat)\n",
    "example_chain = chain_example(llm_chat)\n",
    "plain_english_chain = chain_plain_english(llm_chat)\n",
    "technical_definition_chain = chain_technical_definition(llm_chat)\n",
    "\n",
    "\n",
    "concept = \"joint probability mass function\"\n",
    "map_chain = RunnableParallel(analogy=analogy_chain, diagram=diagram_chain, example=example_chain, \n",
    "                             plain_english=plain_english_chain, technical_def=technical_definition_chain)\n",
    "output_explanation = map_chain.invoke({\"concept\": concept})\n",
    "output_explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**analogy**\n",
       "\n",
       "A joint probability mass function is like a recipe book that tells you the probability of different combinations of ingredients resulting in a specific outcome. Just as a recipe book provides instructions for combining ingredients to create a delicious dish, a joint probability mass function provides probabilities for combining different events to create a particular outcome.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**diagram**\n",
       "\n",
       "Here is a knowledge graph explaining the concept of a \"joint probability mass function\":\n",
       "\n",
       "```\n",
       "        Joint Probability Mass Function (PMF)\n",
       "        \n",
       "                     Probability\n",
       "                       Theory\n",
       "                          |\n",
       "                          |\n",
       "                Random Variables\n",
       "                          |\n",
       "                          |\n",
       "               Joint PMF (P(X, Y))\n",
       "                          |\n",
       "                          |\n",
       "          Probability Distribution\n",
       "             (Joint Probability)\n",
       "                          |\n",
       "                          |\n",
       "       Marginal PMFs (P(X) and P(Y))\n",
       "                          |\n",
       "                          |\n",
       "     Probability Distribution\n",
       "            (Marginal Probability)\n",
       "                          |\n",
       "                          |\n",
       "  Conditional PMFs (P(X|Y) and P(Y|X))\n",
       "                          |\n",
       "                          |\n",
       "      Conditional Probability\n",
       "```\n",
       "\n",
       "Explanation of the knowledge graph:\n",
       "\n",
       "1. Probability Theory: The branch of mathematics that deals with the analysis of random phenomena and measures the likelihood of events.\n",
       "\n",
       "2. Random Variables: Variables whose values depend on the outcomes of a random event or experiment.\n",
       "\n",
       "3. Joint Probability Mass Function (PMF): A function that assigns probabilities to each possible combination of values of multiple random variables. It represents the joint distribution of these variables.\n",
       "\n",
       "4. Probability Distribution (Joint Probability): The set of probabilities assigned to all possible combinations of values of multiple random variables. It describes the likelihood of each combination occurring.\n",
       "\n",
       "5. Marginal PMFs: Probability mass functions that represent the probabilities of individual random variables, ignoring the values of other variables. Marginal PMFs are derived from the joint PMF.\n",
       "\n",
       "6. Probability Distribution (Marginal Probability): The set of probabilities assigned to each individual random variable, ignoring the values of other variables. It describes the likelihood of each variable's values occurring.\n",
       "\n",
       "7. Conditional PMFs: Probability mass functions that represent the probabilities of one random variable given the value of another variable. Conditional PMFs are derived from the joint PMF.\n",
       "\n",
       "8. Conditional Probability: The probability of one event occurring given that another event has already occurred. It is calculated using the joint PMF and the marginal PMFs.\n",
       "\n",
       "This knowledge graph illustrates the relationships and connections between the key concepts necessary to understand the \"joint probability mass function.\" It demonstrates how the joint PMF relates to probability theory, random variables, probability distributions, marginal PMFs, and conditional PMFs.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**example**\n",
       "\n",
       "1. Consider a two-player game where each player rolls a fair six-sided die. The joint probability mass function would give the probability of each possible outcome (i, j), where i represents the number rolled by player 1 and j represents the number rolled by player 2.\n",
       "\n",
       "2. In a survey, respondents are asked two questions: \"Do you own a car?\" and \"Do you own a house?\". The joint probability mass function would provide the probabilities of each possible combination of responses, such as (yes, yes), (yes, no), (no, yes), and (no, no).\n",
       "\n",
       "3. In a genetics study, researchers are interested in the probability of a couple having a child with a specific genetic trait. The joint probability mass function would describe the probabilities of each possible combination of the parents' genetic makeups and the resulting trait in the child.\n",
       "\n",
       "4. In a manufacturing process, there are two machines that can produce defective products. The joint probability mass function would provide the probabilities of each possible combination of defects produced by the machines, helping identify potential areas for improvement.\n",
       "\n",
       "5. A medical researcher is investigating the relationship between two symptoms in a patient. The joint probability mass function would give the probabilities of each possible combination of the presence or absence of the symptoms, aiding in diagnosis and treatment decisions.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**plain_english**\n",
       "\n",
       "A joint probability mass function refers to the likelihood of two or more random variables occurring together in a discrete probability distribution. It calculates the probability of specific outcomes happening simultaneously, helping to understand the relationship between different events or variables.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**technical_def**\n",
       "\n",
       "A joint probability mass function is a statistical function that assigns probabilities to each possible combination of values in two or more discrete random variables. It provides a way to calculate the probability of specific outcomes occurring simultaneously in a given probability distribution.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "for key in output_explanation.keys():\n",
    "    display(Markdown(f\"**{key}**\\n\\n{output_explanation[key].content}\\n\\n\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, this is nice but can we make it better? Like the knowledge graph is not visual, how can we improve upon that? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydantic import BaseModel, Field\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from typing import List\n",
    "from graphviz import Digraph\n",
    "import argparse\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "import graphviz\n",
    "from IPython.display import display\n",
    "\n",
    "class Node(BaseModel):\n",
    "    id: int\n",
    "    label: str\n",
    "    color: str\n",
    "\n",
    "class Edge(BaseModel):\n",
    "    source: int\n",
    "    target: int\n",
    "    label: str\n",
    "    color: str = \"black\"\n",
    "\n",
    "class KnowledgeGraph(BaseModel):\n",
    "    \"\"\"A knowledge graph is a graph that represents knowledge as a set of entities and relations between them.\"\"\"\n",
    "    nodes: List[Node] = Field(..., description=\"A list of nodes in the knowledge graph\")\n",
    "    edges: List[Edge] = Field(..., description=\"A list of edges in the knowledge graph\")\n",
    "\n",
    "\n",
    "def visualize_knowledge_graph(kg: KnowledgeGraph):\n",
    "    dot = Digraph(comment=\"Knowledge Graph\")\n",
    "\n",
    "    # Add nodes\n",
    "    for node in kg.nodes:\n",
    "        dot.node(str(node.id), node.label, color=node.color)\n",
    "\n",
    "    # Add edges\n",
    "    for edge in kg.edges:\n",
    "        dot.edge(str(edge.source), str(edge.target), label=edge.label, color=edge.color)\n",
    "\n",
    "    # Render the graph\n",
    "    display(graphviz.Source(dot.source))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's modify the `chain_diagram()` function to output a schema that's appropriate for generating a knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\\n  \"nodes\": [\\n    {\\n      \"id\": 1,\\n      \"label\": \"Probability\",\\n      \"color\": \"#bdbdbd\"\\n    },\\n    {\\n      \"id\": 2,\\n      \"label\": \"Joint Probability Mass Function\",\\n      \"color\": \"#4caf50\"\\n    },\\n    {\\n      \"id\": 3,\\n      \"label\": \"Probability Mass Function\",\\n      \"color\": \"#4caf50\"\\n    },\\n    {\\n      \"id\": 4,\\n      \"label\": \"Random Variables\",\\n      \"color\": \"#2196f3\"\\n    }\\n  ],\\n  \"edges\": [\\n    {\\n      \"source\": 1,\\n      \"target\": 2,\\n      \"label\": \"defines\"\\n    },\\n    {\\n      \"source\": 2,\\n      \"target\": 3,\\n      \"label\": \"is a type of\"\\n    },\\n    {\\n      \"source\": 4,\\n      \"target\": 2,\\n      \"label\": \"uses\"\\n    }\\n  ]\\n}', 'name': 'KnowledgeGraph'}})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "openai_function_knowledge_graph = convert_pydantic_to_openai_function(KnowledgeGraph)\n",
    "\n",
    "llm_chat = ChatOpenAI()    \n",
    "llm_with_tools = llm_chat.bind(functions=[openai_function_knowledge_graph])\n",
    "\n",
    "chain = chain_diagram(llm_with_tools)\n",
    "concept = \"joint probability mass function\"\n",
    "\n",
    "output_graph = chain.invoke({\"concept\": concept})\n",
    "output_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we are getting the right output, which we can access like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"nodes\": [\\n    {\\n      \"id\": 1,\\n      \"label\": \"Probability\",\\n      \"color\": \"#bdbdbd\"\\n    },\\n    {\\n      \"id\": 2,\\n      \"label\": \"Joint Probability Mass Function\",\\n      \"color\": \"#4caf50\"\\n    },\\n    {\\n      \"id\": 3,\\n      \"label\": \"Probability Mass Function\",\\n      \"color\": \"#4caf50\"\\n    },\\n    {\\n      \"id\": 4,\\n      \"label\": \"Random Variables\",\\n      \"color\": \"#2196f3\"\\n    }\\n  ],\\n  \"edges\": [\\n    {\\n      \"source\": 1,\\n      \"target\": 2,\\n      \"label\": \"defines\"\\n    },\\n    {\\n      \"source\": 2,\\n      \"target\": 3,\\n      \"label\": \"is a type of\"\\n    },\\n    {\\n      \"source\": 4,\\n      \"target\": 2,\\n      \"label\": \"uses\"\\n    }\\n  ]\\n}'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_graph.additional_kwargs[\"function_call\"][\"arguments\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we want this output to be perfectly tailored for a function that visualizes the graph, so let's do that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"nodes\": [\\n    {\\n      \"id\": 1,\\n      \"label\": \"Probability\",\\n      \"color\": \"#bdbdbd\"\\n    },\\n    {\\n      \"id\": 2,\\n      \"label\": \"Joint Probability Mass Function\",\\n      \"color\": \"#4caf50\"\\n    },\\n    {\\n      \"id\": 3,\\n      \"label\": \"Probability Mass Function\",\\n      \"color\": \"#4caf50\"\\n    },\\n    {\\n      \"id\": 4,\\n      \"label\": \"Random Variables\",\\n      \"color\": \"#2196f3\"\\n    }\\n  ],\\n  \"edges\": [\\n    {\\n      \"source\": 1,\\n      \"target\": 2,\\n      \"label\": \"defines\"\\n    },\\n    {\\n      \"source\": 2,\\n      \"target\": 3,\\n      \"label\": \"is a type of\"\\n    },\\n    {\\n      \"source\": 4,\\n      \"target\": 2,\\n      \"label\": \"uses\"\\n    }\\n  ]\\n}'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "pydantic_output_parser = PydanticOutputParser(pydantic_object=KnowledgeGraph)\n",
    "\n",
    "output_graph_json_dict = output_graph.additional_kwargs[\"function_call\"][\"arguments\"]\n",
    "output_graph_json_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KnowledgeGraph(nodes=[Node(id=1, label='Probability', color='#bdbdbd'), Node(id=2, label='Joint Probability Mass Function', color='#4caf50'), Node(id=3, label='Probability Mass Function', color='#4caf50'), Node(id=4, label='Random Variables', color='#2196f3')], edges=[Edge(source=1, target=2, label='defines', color='black'), Edge(source=2, target=3, label='is a type of', color='black'), Edge(source=4, target=2, label='uses', color='black')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pydantic_output_parser.parse(output_graph_json_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! As you can see above, the output of parsing with the pydantic_output_parser is the `KnowledgeGraph` object, which we can feed into the \n",
    "`visualize_graph` function to get the final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"292pt\" height=\"221pt\"\n",
       " viewBox=\"0.00 0.00 292.16 221.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 217)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-217 288.16,-217 288.16,4 -4,4\"/>\n",
       "<!-- 1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#bdbdbd\" cx=\"56.17\" cy=\"-195\" rx=\"51.86\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"56.17\" y=\"-189.95\" font-family=\"Times,serif\" font-size=\"14.00\">Probability</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#4caf50\" cx=\"130.17\" cy=\"-106.5\" rx=\"130.17\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.17\" y=\"-101.45\" font-family=\"Times,serif\" font-size=\"14.00\">Joint Probability Mass Function</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M70.44,-177.32C81.15,-164.8 96.01,-147.43 108.23,-133.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"110.61,-135.74 114.46,-125.87 105.3,-131.19 110.61,-135.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"119.67\" y=\"-145.7\" font-family=\"Times,serif\" font-size=\"14.00\">defines</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"#4caf50\" cx=\"130.17\" cy=\"-18\" rx=\"109.7\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"130.17\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Probability Mass Function</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M130.17,-88.41C130.17,-76.76 130.17,-61.05 130.17,-47.52\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"133.67,-47.86 130.17,-37.86 126.67,-47.86 133.67,-47.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"160.54\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">is a type of</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"#2196f3\" cx=\"205.17\" cy=\"-195\" rx=\"78.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"205.17\" y=\"-189.95\" font-family=\"Times,serif\" font-size=\"14.00\">Random Variables</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>4&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M190.35,-176.91C179.53,-164.43 164.68,-147.3 152.44,-133.18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"155.4,-131.26 146.2,-125.99 150.11,-135.84 155.4,-131.26\"/>\n",
       "<text text-anchor=\"middle\" x=\"185.79\" y=\"-145.7\" font-family=\"Times,serif\" font-size=\"14.00\">uses</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x12abd7590>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kg = pydantic_output_parser.parse(output_graph_json_dict)\n",
    "\n",
    "visualize_knowledge_graph(kg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yaaay victory!!! Now, let's wrap this into a modified version of the original chain by using the RunnableLambda Object to do the \n",
    "intermediary step we were doing before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"629pt\" height=\"221pt\"\n",
       " viewBox=\"0.00 0.00 629.08 221.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 217)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-217 625.08,-217 625.08,4 -4,4\"/>\n",
       "<!-- 1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#0099ff\" cx=\"319.76\" cy=\"-195\" rx=\"102.02\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"319.76\" y=\"-189.95\" font-family=\"Times,serif\" font-size=\"14.00\">Large Language Models</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#ffcc00\" cx=\"90.76\" cy=\"-106.5\" rx=\"90.76\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"90.76\" y=\"-101.45\" font-family=\"Times,serif\" font-size=\"14.00\">Artificial Intelligence</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#707070\" d=\"M277.76,-178.13C239.59,-163.72 183.17,-142.41 142.29,-126.96\"/>\n",
       "<polygon fill=\"#707070\" stroke=\"#707070\" points=\"143.73,-123.77 133.14,-123.51 141.26,-130.32 143.73,-123.77\"/>\n",
       "<text text-anchor=\"middle\" x=\"256.01\" y=\"-145.7\" font-family=\"Times,serif\" font-size=\"14.00\">is a part of</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"#ffcc00\" cx=\"319.76\" cy=\"-106.5\" rx=\"119.93\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"319.76\" y=\"-101.45\" font-family=\"Times,serif\" font-size=\"14.00\">Natural Language Processing</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#707070\" d=\"M319.76,-176.91C319.76,-165.26 319.76,-149.55 319.76,-136.02\"/>\n",
       "<polygon fill=\"#707070\" stroke=\"#707070\" points=\"323.26,-136.36 319.76,-126.36 316.26,-136.36 323.26,-136.36\"/>\n",
       "<text text-anchor=\"middle\" x=\"331.39\" y=\"-145.7\" font-family=\"Times,serif\" font-size=\"14.00\">uses</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"#ffcc00\" cx=\"536.76\" cy=\"-106.5\" rx=\"79.5\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"536.76\" y=\"-101.45\" font-family=\"Times,serif\" font-size=\"14.00\">Machine Learning</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;4 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#707070\" d=\"M359.81,-178.03C396.08,-163.58 449.6,-142.25 488.27,-126.83\"/>\n",
       "<polygon fill=\"#707070\" stroke=\"#707070\" points=\"489.36,-130.16 497.35,-123.21 486.77,-123.66 489.36,-130.16\"/>\n",
       "<text text-anchor=\"middle\" x=\"459.39\" y=\"-145.7\" font-family=\"Times,serif\" font-size=\"14.00\">uses</text>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"#ffcc00\" cx=\"479.76\" cy=\"-18\" rx=\"66.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"479.76\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Deep Learning</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"#707070\" d=\"M502.77,-89.81C495.22,-84.72 488.1,-78.32 483.51,-70.5 479.53,-63.72 477.84,-55.55 477.33,-47.73\"/>\n",
       "<polygon fill=\"#707070\" stroke=\"#707070\" points=\"480.83,-47.87 477.33,-37.87 473.83,-47.88 480.83,-47.87\"/>\n",
       "<text text-anchor=\"middle\" x=\"519.39\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">is a subset of</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"#ffcc00\" cx=\"592.76\" cy=\"-18\" rx=\"28.32\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"592.76\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Data</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;6 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>4&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"#707070\" d=\"M547.82,-88.41C555.88,-75.97 566.93,-58.9 576.05,-44.81\"/>\n",
       "<polygon fill=\"#707070\" stroke=\"#707070\" points=\"578.97,-46.74 581.47,-36.45 573.09,-42.94 578.97,-46.74\"/>\n",
       "<text text-anchor=\"middle\" x=\"591.51\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">requires</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x12af29550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "\n",
    "\n",
    "def chain_diagram_viz():\n",
    "    \"\"\"Full chain to generate the formatted knowledge graph\"\"\"\n",
    "    openai_function_knowledge_graph = convert_pydantic_to_openai_function(KnowledgeGraph)\n",
    "    llm_chat = ChatOpenAI()    \n",
    "    llm_with_tools = llm_chat.bind(functions=[openai_function_knowledge_graph])\n",
    "    pydantic_output_parser = PydanticOutputParser(pydantic_object=KnowledgeGraph)\n",
    "    return ChatPromptTemplate.from_template(\"Write a knowledge graph with the necessary concepts and elements to understand the following concept: '''{concept}''', this diagram should perfectly encapsulate\\\n",
    "        what it is and what it relates to.\") | llm_with_tools | RunnableLambda(lambda x: x.additional_kwargs[\"function_call\"][\"arguments\"]) | pydantic_output_parser\n",
    "    # Here instead of using the RunnableLambda we could have used the JsonOutputFunctionsParser, however langchain and pydantic had some compatibility issues\n",
    "    # so we're extracting the json dict manually and then parsing it with the PydanticOutputParser \n",
    "concept = \"large language models\" \n",
    "\n",
    "output_graph = chain_diagram_viz().invoke({\"concept\": concept})\n",
    "visualize_knowledge_graph(output_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! How about we put everything together under a class that represents this LangChain implementation of the ADEPT method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Any\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableParallel\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "@dataclass\n",
    "class ADEPT:\n",
    "    concept: str\n",
    "    llm_chat = ChatOpenAI()\n",
    "    \n",
    "    def chain_analogy(self):\n",
    "        return ChatPromptTemplate.from_template(\"Write a simple analogy for this concept: '''{concept}''', which should perfectly encapsulate\\\n",
    "            what it is.\") | llm_chat\n",
    "\n",
    "    \n",
    "    def chain_diagram_viz(self):\n",
    "        \"\"\"Full chain to generate the formatted knowledge graph\"\"\"\n",
    "        openai_function_knowledge_graph = convert_pydantic_to_openai_function(KnowledgeGraph) \n",
    "        llm_with_tools = llm_chat.bind(functions=[openai_function_knowledge_graph])\n",
    "        pydantic_output_parser = PydanticOutputParser(pydantic_object=KnowledgeGraph)\n",
    "        return ChatPromptTemplate.from_template(\"Write a knowledge graph with the necessary concepts and elements to understand the following concept: '''{concept}''', this diagram should perfectly encapsulate\\\n",
    "            what it is and what it relates to.\") | llm_with_tools | RunnableLambda(lambda x: x.additional_kwargs[\"function_call\"][\"arguments\"]) | pydantic_output_parser\n",
    "        \n",
    "\n",
    "    def chain_example(self):\n",
    "        return ChatPromptTemplate.from_template(\"Write down five examples that perfectly demonstrate this concept: '''{concept}'''. \") | llm_chat\n",
    "\n",
    "\n",
    "    def chain_plain_english(self):\n",
    "        return ChatPromptTemplate.from_template(\"Write a plain english definition for this concept: '''{concept}'''\") | llm_chat\n",
    "\n",
    "\n",
    "    def chain_technical_definition(self):\n",
    "        return ChatPromptTemplate.from_template(\"Write a short and precise technical definition for this concept: '''{concept}'''\") | llm_chat\n",
    "    \n",
    "    def visualize_knowledge_graph(self, kg: KnowledgeGraph):\n",
    "        dot = Digraph(comment=\"Knowledge Graph\")\n",
    "\n",
    "        # Add nodes\n",
    "        for node in kg.nodes:\n",
    "            dot.node(str(node.id), node.label, color=node.color)\n",
    "\n",
    "        # Add edges\n",
    "        for edge in kg.edges:\n",
    "            dot.edge(str(edge.source), str(edge.target), label=edge.label, color=edge.color)\n",
    "\n",
    "        # Render the graph\n",
    "        display(graphviz.Source(dot.source))\n",
    "        \n",
    "    # now let's write a __call__ method that runs all of the chains and generates a nice output just from the concept input.\n",
    "    def __call__(self):\n",
    "        analogy_chain = self.chain_analogy()\n",
    "        diagram_chain = self.chain_diagram_viz()\n",
    "        example_chain = self.chain_example()\n",
    "        plain_english_chain = self.chain_plain_english()\n",
    "        technical_definition_chain = self.chain_technical_definition()\n",
    "        map_chain = RunnableParallel(analogy=analogy_chain, diagram=diagram_chain, example=example_chain, \n",
    "                             plain_english=plain_english_chain, technical_def=technical_definition_chain)\n",
    "        output_explanation = map_chain.invoke({\"concept\": self.concept})\n",
    "        return output_explanation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADEPT(concept='langchain python library')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concept = \"langchain python library\"\n",
    "\n",
    "adept = ADEPT(concept)\n",
    "adept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_explanation = adept()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 9.0.0 (20230911.1827)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"416pt\" height=\"133pt\"\n",
       " viewBox=\"0.00 0.00 416.24 132.50\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 128.5)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-128.5 412.24,-128.5 412.24,4 -4,4\"/>\n",
       "<!-- 1 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"#ffcc00\" cx=\"174.02\" cy=\"-106.5\" rx=\"102.02\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"174.02\" y=\"-101.45\" font-family=\"Times,serif\" font-size=\"14.00\">langchain python library</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"#3776ab\" cx=\"37.02\" cy=\"-18\" rx=\"37.02\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"37.02\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Python</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"#ffcc00\" d=\"M122.78,-90.64C109.2,-85.44 95,-78.77 83.02,-70.5 72.66,-63.35 63.06,-53.4 55.34,-44.15\"/>\n",
       "<polygon fill=\"#ffcc00\" stroke=\"#ffcc00\" points=\"58.19,-42.11 49.23,-36.45 52.71,-46.46 58.19,-42.11\"/>\n",
       "<text text-anchor=\"middle\" x=\"126.52\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">Implemented in</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"#00b894\" cx=\"174.02\" cy=\"-18\" rx=\"81.55\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"174.02\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Language Analysis</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"#ffcc00\" d=\"M174.02,-88.41C174.02,-76.76 174.02,-61.05 174.02,-47.52\"/>\n",
       "<polygon fill=\"#ffcc00\" stroke=\"#ffcc00\" points=\"177.52,-47.86 174.02,-37.86 170.52,-47.86 177.52,-47.86\"/>\n",
       "<text text-anchor=\"middle\" x=\"187.15\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">Uses</text>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"#6c5ce7\" cx=\"341.02\" cy=\"-18\" rx=\"67.22\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"341.02\" y=\"-12.95\" font-family=\"Times,serif\" font-size=\"14.00\">Chain Analysis</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;4 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"#ffcc00\" d=\"M205.83,-89.03C232.91,-75 271.97,-54.76 301.15,-39.65\"/>\n",
       "<polygon fill=\"#ffcc00\" stroke=\"#ffcc00\" points=\"302.41,-42.94 309.68,-35.24 299.19,-36.73 302.41,-42.94\"/>\n",
       "<text text-anchor=\"middle\" x=\"286.15\" y=\"-57.2\" font-family=\"Times,serif\" font-size=\"14.00\">Uses</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x107ff11d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "diagram = output_explanation[\"diagram\"]\n",
    "\n",
    "adept.visualize_knowledge_graph(diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The \"langchain python library\" is like a versatile toolbox for language enthusiasts. Just as a library offers a wide range of books on various subjects, this python library provides a vast collection of tools and resources for working with different languages. It allows you to easily analyze, manipulate, and understand languages, just like browsing through books in a library helps you explore and gain knowledge in different areas.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_explanation[\"analogy\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. A user can import the langchain python library into their Python project and use its functions to analyze the sentiment of a given text. The library provides pre-trained sentiment analysis models, making it easy for the user to determine whether a text has a positive, negative, or neutral sentiment.\\n\\n2. The langchain python library offers a feature for language detection. By utilizing this library, a user can input a piece of text, and the library will automatically detect the language in which the text is written. This can be useful in various applications such as multilingual chatbots or language-specific data analysis.\\n\\n3. The library provides a translation function that allows users to translate text from one language to another. For instance, a user can input an English sentence and specify the target language as Spanish, and the library will return the translated version of that sentence. This can be beneficial for applications that require multilingual support.\\n\\n4. With the langchain python library, users can perform named entity recognition (NER) on text data. NER involves identifying and classifying named entities such as names of people, organizations, locations, etc. The library simplifies this task by providing pre-trained models that can accurately detect and classify these entities within a given text.\\n\\n5. The langchain python library includes a function for text summarization. Users can input a long piece of text, and the library will generate a concise summary of the main points or key ideas present in that text. This can be particularly helpful for tasks such as news article summarization or document summarization, where extracting important information efficiently is crucial.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_explanation[\"example\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The langchain python library is a software tool that helps developers work with programming languages and understand how they are related or connected to each other.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_explanation[\"plain_english\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The langchain python library refers to a software package written in the Python programming language that provides a set of functions and tools for working with the Langchain programming language.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_explanation[\"technical_def\"].content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-langchain",
   "language": "python",
   "name": "oreilly-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
