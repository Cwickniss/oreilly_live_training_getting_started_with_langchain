{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain\n",
    "# !pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to LangChain \n",
    "\n",
    "Working with LLMs involves in one way or another working with a specific type of abstraction: \"Prompts\".\n",
    "\n",
    "However, in the practical context of day-to-day tasks we expect LLMs to perform, these prompts won't be some static and dead type of abstraction. Instead we'll work with dynamic prompts re-usable prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lanchain\n",
    "\n",
    "[LangChain](https://python.langchain.com/docs/get_started/introduction.html) is a framework that allows you to connect LLMs together by allowing you to work with modular components like prompt templates and chains giving you immense flexibility in creating tailored solutions powered by the capabilities of large language models.\n",
    "\n",
    "\n",
    "Its main features are:\n",
    "- **Components**: abstractions for working with LMs\n",
    "- **Off-the-shelf chains**: assembly of components for accomplishing certain higher-level tasks\n",
    "\n",
    "LangChain facilitates the creation of complex pipelines that leverage the connection of components like chains, prompt templates, output parsers and others to compose intricate pipelines that give you everything you need to solve a wide variety of tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the core of LangChain, we have the following elements:\n",
    "\n",
    "- Models\n",
    "- Prompts\n",
    "- Output parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models**\n",
    "\n",
    "Models are nothing more than abstractions over the LLM APIs like the ChatGPT API.â€‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and add your api key!!!\n",
    "\n",
    "\n",
    "# import os\n",
    "\n",
    "\n",
    "# os.environ[\"OPENAI_API_KEY\"] = \"<your OPENAI API KEY>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can predict outputs from both LLMs and ChatModels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's great! LLMs, or Master of Laws degrees, are advanced law degrees that allow students to specialize in a specific area of law. What topics will you be covering in your training session?\")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(\"I am teaching a live-training about LLMs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic components are:\n",
    "\n",
    "- Models\n",
    "- Prompt templates\n",
    "- Output parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"Show me 5 examples of this concept: {concept}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Show me 5 examples of this concept: animal'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(concept=\"animal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. Dogs are a common example of an animal that is often kept as a pet by humans.\\n2. Lions are known for their strength and are often referred to as the \"king of the jungle.\"\\n3. Dolphins are highly intelligent animals that are known for their playful behavior.\\n4. Elephants are one of the largest land animals and are known for their long tusks and trunks.\\n5. Birds are a diverse group of animals that are known for their ability to fly.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | chat_model\n",
    "\n",
    "output = chain.invoke({\"concept\": \"animal\"})\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Dogs are a common example of an animal that is often kept as a pet by humans.\n",
       "2. Lions are known for their strength and are often referred to as the \"king of the jungle.\"\n",
       "3. Dolphins are highly intelligent animals that are known for their playful behavior.\n",
       "4. Elephants are one of the largest land animals and are known for their long tusks and trunks.\n",
       "5. Birds are a diverse group of animals that are known for their ability to fly."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "Markdown(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the predict method over a string input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Snooze')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"What would be a good name for a dog that loves to nap??\"\n",
    "chat_model.invoke(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompts**\n",
    "\n",
    "The same works for prompts. Now, prompts are pieces of text we feed to LLMs, and LangChain allows you to work with prompt templates.\n",
    "\n",
    "Prompt Templates are useful abstractions for reusing prompts and they are used to provide context for the specific task that the language model needs to complete. \n",
    "\n",
    "A simple example is a `PromptTemplate` that formats a string into a prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What is a good dog name for a dog that loves to sleeping?'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts  import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"What is a good dog name for a dog that loves to {activity}?\")\n",
    "prompt.format(activity=\"sleeping\")\n",
    "# Output: \"What is a good dog name for a dog that loves to nap?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Parsers**\n",
    "\n",
    "OutputParsers convert the raw output from an LLM into a format that can be used downstream. Here is an example of an OutputParser that converts a comma-separated list into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "prompt = ChatPromptTemplate.from_template(\"Write 5 concepts that are fundamental to learn about {topic}.\")\n",
    "chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Transformers Architecture: Understanding the basic structure and components of the transformer neural network architecture, including the self-attention mechanism, feed-forward neural network, and layer normalization.\\n\\n2. Self-Attention Mechanism: Exploring how the self-attention mechanism allows the model to weigh the importance of different input elements when making predictions, enabling the transformer to capture long-range dependencies in the data.\\n\\n3. Multi-Head Attention: Learning about the concept of multi-head attention, where the model can attend to different parts of the input data simultaneously, allowing for more complex relationships to be captured.\\n\\n4. Positional Encoding: Understanding how positional encoding is used in transformers to provide information about the position of tokens in the input sequence, helping the model to understand the sequential nature of the data.\\n\\n5. Training and Inference: Exploring the training process of transformers, including techniques such as backpropagation and gradient descent, as well as how the model is used for inference and making predictions on new data.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"Transformers neural network architecture\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chain will take input variables, pass those to a prompt template to create a prompt, pass the prompt to an LLM, and then pass the output through an output parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so these are the basics of langchain. But how can we leverage these abstraction capabilities inside our LLM app application?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to put everything together LangChain allows you to build something called \"chains\", which are components that connect prompts, llms and output parsers into a building block that allows you to create more interesting and complex functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activity': 'sleep', 'text': 'Snooze'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"What is a good dog name for a dog that loves to {activity}?\")\n",
    "\n",
    "chain = LLMChain(\n",
    "    llm=ChatOpenAI(),\n",
    "    prompt=prompt,\n",
    ")\n",
    "chain.invoke(\"sleep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what the chain is doing is connecting these basic components (the LLM and the prompt template) into\n",
    "a block that can be run separately. The chain allows you to turn workflows using LLLMs into this modular process of composing components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the newer versions of LangChain have a new representation language to create these chains (and more) known as LCEL or LangChain expression language, which is a declarative way to easily compose chains together. The same example as above expressed in this LCEL format would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Snooze')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | ChatOpenAI()\n",
    "\n",
    "chain.invoke({\"activity\": \"sleep\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that now the output is an `AIMessage()` object, which represents LangChain's way to abstract the output from an LLM model like ChatGPT or others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These building blocks and abstractions that LangChain provides are what makes this library so unique, because it gives you the tools you didn't know you need it to build awesome stuff powered by LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Lab Exercises\n",
    "\n",
    "Let's take a look at a few examples using some of the capabilities of the LangChain library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a prompt to summarize any piece of text into some desirable format. \n",
    "\n",
    "Let's make use of the `PromptTemplate` to abstract away the following pieces of the prompt: \n",
    "- `content` - the text content to be summarized  \n",
    "- `summary_format` - the format in which we want the summary to be presented (like bullet points and so on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Summarize this: This is a test.. The output should be in the following format: One word summary.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Summarize this: {content}. The output should be in the following format: {summary_format}.\")\n",
    "\n",
    "# We can look at a simple example to illustrate what that prompt is doing\n",
    "prompt.format(content=\"This is a test.\", summary_format=\"One word summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we have our prompt template done, let's load the llm and create a nice chain to put everything together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "\n",
    "llm_chat =  ChatOpenAI()\n",
    "chain = prompt | llm_chat # This is the Pipe symbol! from LCEL that connect model to prompt!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we have our chain we can run some tests. The cool thing about working with LLMs is that you can use them to create examples for simple tests like this (avoiding the annoynace of searching online for some piece of text, copying and pasting etc...). So, let's generate a few examples of tests below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"The concept of human-machine interaction has become increasingly prevalent in today's society, with the rise of artificial intelligence and automation technologies. From virtual assistants like Siri and Alexa to self-driving cars, humans are now interacting with machines in ways that were once only seen in science fiction. This shift has raised questions about the impact of these technologies on human behavior and relationships.\\n\\nSome experts argue that human-machine interaction can lead to a loss of empathy and social skills, as people become more reliant on machines for communication and decision-making. However, others believe that these technologies have the potential to enhance human capabilities and improve overall quality of life. By working in tandem with machines, humans can access vast amounts of information and resources that were previously unavailable, leading to increased efficiency and productivity. Ultimately, the future of human-machine interaction will likely depend on how we navigate the balance between technological advancement and maintaining our humanity.\",\n",
       " \"With the rise of artificial intelligence and automation, the interaction between humans and machines has become more prevalent than ever before. From smart home devices like Amazon's Alexa to self-driving cars, technology is reshaping the way we live and work. This shift towards a more interconnected world has both exciting possibilities and potential challenges.\\n\\nOne of the key issues in human-machine interaction is the ethical considerations surrounding the use of AI. As machines become more sophisticated and capable of making decisions on their own, questions arise about who is ultimately responsible for their actions. Additionally, concerns about privacy and data security have become more pressing as we entrust more and more of our personal information to machines. As we continue to navigate this new era of technology, it will be crucial to establish clear guidelines and regulations to ensure that human-machine interaction is safe and beneficial for all.\",\n",
       " 'Human-machine interaction, also known as HMI, has become an integral part of our daily lives. From smartphones and laptops to smart home devices and self-driving cars, we rely on machines to assist us in almost every aspect of our lives. The design of these interactions plays a crucial role in how we perceive and interact with technology. User-friendly interfaces and intuitive interactions can make our lives easier, while confusing or poorly designed interfaces can lead to frustration and inefficiency.\\n\\nAs technology continues to advance, the line between human and machine is becoming increasingly blurred. With the rise of artificial intelligence and machine learning, machines are becoming more capable of understanding and responding to human emotions and behaviors. This has led to new opportunities for collaboration between humans and machines, as well as new challenges in ensuring that these interactions are ethical and beneficial for all parties involved. As we navigate the ever-evolving landscape of human-machine interaction, it is important to consider the implications of our design choices and strive to create interactions that are not only efficient and effective, but also respectful of the human experience.',\n",
       " 'Human-machine interaction has become an integral part of everyday life, with technology playing a crucial role in how we communicate, work, and live. From virtual assistants like Siri and Alexa to self-driving cars and smart home devices, the lines between humans and machines continue to blur. As our reliance on technology grows, it is essential to consider the ethical implications of this relationship and how it impacts our privacy, autonomy, and overall well-being.\\n\\nOne of the key challenges in human-machine interaction is ensuring that machines can understand and respond to human emotions and intentions accurately. This requires advances in artificial intelligence and machine learning to create more intuitive and empathetic interfaces. Additionally, as machines become more sophisticated, questions arise about the potential loss of jobs and the impact on society as a whole. Finding a balance between human and machine capabilities is essential to ensure a harmonious and productive future for both parties.',\n",
       " \"Human-machine interaction has become increasingly important in today's technological age. From voice-activated virtual assistants to self-driving cars, machines are playing a larger role in our daily lives than ever before. This interaction between humans and machines has the potential to greatly enhance efficiency and convenience, but it also raises important questions about privacy, security, and ethical considerations.\\n\\nAs machines become more advanced and integrated into society, it is crucial for humans to maintain control and oversight over these technologies. Ensuring that machines are programmed to prioritize human safety and well-being is essential, as is establishing clear guidelines for how data collected by machines is used and protected. Ultimately, the relationship between humans and machines should be one of collaboration and mutual benefit, with both parties working together to achieve common goals and address any potential challenges that may arise.\"]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples = 5\n",
    "examples = []\n",
    "for i in range(num_examples):\n",
    "    examples.append(llm_chat.predict(\"Create a piece of text with 2 paragraphs about a random topic regarding human-machine interaction.\"))\n",
    "\n",
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Now that we have our examples, let's run our chain on them and check out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"- Human-machine interaction is increasingly prevalent in today's society due to the rise of artificial intelligence and automation technologies.\\n- Virtual assistants like Siri and Alexa, as well as self-driving cars, are examples of how humans are now interacting with machines in ways previously only seen in science fiction.\\n- This shift has raised questions about the impact of these technologies on human behavior and relationships.\\n- Some experts believe that human-machine interaction can lead to a loss of empathy and social skills, as people become more reliant on machines for communication and decision-making.\\n- Others argue that these technologies have the potential to enhance human capabilities and improve overall quality of life.\\n- By working in tandem with machines, humans can access vast amounts of information and resources, leading to increased efficiency and productivity.\\n- The future of human-machine interaction will likely depend on how we navigate the balance between technological advancement and maintaining our humanity.\")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_format = \"bullet points\"\n",
    "\n",
    "outputs = []\n",
    "for ex in examples:\n",
    "    outputs.append(chain.invoke({\"content\": ex, \"summary_format\": summary_format}))\n",
    "\n",
    "# Let's display one example output\n",
    "outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So it seems our chain worked and we generated some summaries! Let's visualize all the summaries generated in a neat way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Output 0 \n",
       " - Human-machine interaction is increasingly prevalent in today's society due to the rise of artificial intelligence and automation technologies.\n",
       "- Virtual assistants like Siri and Alexa, as well as self-driving cars, are examples of how humans are now interacting with machines in ways previously only seen in science fiction.\n",
       "- This shift has raised questions about the impact of these technologies on human behavior and relationships.\n",
       "- Some experts believe that human-machine interaction can lead to a loss of empathy and social skills, as people become more reliant on machines for communication and decision-making.\n",
       "- Others argue that these technologies have the potential to enhance human capabilities and improve overall quality of life.\n",
       "- By working in tandem with machines, humans can access vast amounts of information and resources, leading to increased efficiency and productivity.\n",
       "- The future of human-machine interaction will likely depend on how we navigate the balance between technological advancement and maintaining our humanity."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Output 1 \n",
       " - AI and automation have increased interaction between humans and machines\n",
       "- Technology like smart home devices and self-driving cars are reshaping daily life\n",
       "- Possibilities and challenges exist in this more interconnected world\n",
       "- Ethical considerations arise with the use of AI, including responsibility for machine actions\n",
       "- Privacy and data security concerns are heightened as personal information is entrusted to machines\n",
       "- Clear guidelines and regulations will be crucial to ensure safe and beneficial human-machine interaction."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Output 2 \n",
       " - Human-machine interaction (HMI) is a vital part of our daily lives, seen in smartphones, laptops, smart home devices, and self-driving cars.\n",
       "- Well-designed interactions can make our lives easier, while poorly designed ones can lead to frustration and inefficiency.\n",
       "- The line between human and machine is becoming increasingly blurred with advancements in artificial intelligence and machine learning.\n",
       "- New opportunities for collaboration and challenges in ensuring ethical and beneficial interactions arise with the integration of AI.\n",
       "- It is crucial to consider the implications of design choices and strive for interactions that are efficient, effective, and respectful of the human experience."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Output 3 \n",
       " - Human-machine interaction is a crucial part of daily life, impacting how we communicate, work, and live\n",
       "- Technology such as virtual assistants, self-driving cars, and smart home devices are blurring the lines between humans and machines\n",
       "- Ethical considerations must be made regarding privacy, autonomy, and overall well-being in this relationship\n",
       "- Machines need to accurately understand and respond to human emotions and intentions\n",
       "- Advances in artificial intelligence and machine learning are necessary to create more intuitive interfaces\n",
       "- Questions arise about potential job loss and societal impact as machines become more sophisticated\n",
       "- Finding a balance between human and machine capabilities is crucial for a harmonious and productive future."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Output 4 \n",
       " - Human-machine interaction is increasingly important in today's technological age\n",
       "- Machines like virtual assistants and self-driving cars are playing a larger role in daily life\n",
       "- This interaction has the potential to enhance efficiency and convenience\n",
       "- Raises questions about privacy, security, and ethical considerations\n",
       "- Humans must maintain control and oversight over advanced technologies\n",
       "- Machines should prioritize human safety and well-being\n",
       "- Clear guidelines needed for data collection and protection\n",
       "- Relationship between humans and machines should be one of collaboration and mutual benefit."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "for i in range(num_examples):\n",
    "    display(Markdown(f\"Output {i} \\n {outputs[i].content}\"))\n",
    "# Markdown(f\"**Input**: {examples[0]}\\n\\n**Output**: {outputs[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Our summaries worked, and we were able to apply a given summary format to all of them.\n",
    "\n",
    "LangChain is an extremely powerful library to work with abstractions like these and throughout this course we hope to give you a gliimpse of the cool stuff you can build with it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-langchain",
   "language": "python",
   "name": "oreilly-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
