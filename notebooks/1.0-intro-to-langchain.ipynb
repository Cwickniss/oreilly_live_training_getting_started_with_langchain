{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (0.2.14)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.32 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (0.2.34)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (0.2.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (0.1.77)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (2.7.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (3.0.0)\n",
      "Requirement already satisfied: langchain-openai in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (0.1.8)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-openai) (0.2.34)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.26.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-openai) (1.34.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (0.1.77)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (2.7.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (8.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.66.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain-openai) (3.10.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.1)\n",
      "Requirement already satisfied: langsmith in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (0.1.77)\n",
      "Collecting langsmith\n",
      "  Downloading langsmith-0.1.104-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langsmith) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langsmith) (3.10.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langsmith) (2.7.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langsmith) (2.31.0)\n",
      "Requirement already satisfied: anyio in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (4.4.0)\n",
      "Requirement already satisfied: certifi in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (3.7)\n",
      "Requirement already satisfied: sniffio in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langsmith) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langsmith) (2.2.1)\n",
      "Downloading langsmith-0.1.104-py3-none-any.whl (149 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.1/149.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langsmith\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.77\n",
      "    Uninstalling langsmith-0.1.77:\n",
      "      Successfully uninstalled langsmith-0.1.77\n",
      "Successfully installed langsmith-0.1.104\n"
     ]
    }
   ],
   "source": [
    "# uncomment and run below:\n",
    "%pip install -qU langchain\n",
    "%pip install -qU langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to LangChain \n",
    "\n",
    "Working with LLMs involves in one way or another working with a specific type of abstraction: \"Prompts\".\n",
    "\n",
    "However, in the practical context of day-to-day tasks we expect LLMs to perform, these prompts won't be some static and dead type of abstraction. Instead we'll work with dynamic prompts re-usable prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lanchain\n",
    "\n",
    "[LangChain](https://python.langchain.com/docs/get_started/introduction.html) is a framework that allows you to connect LLMs together by allowing you to work with modular components like prompt templates and chains giving you immense flexibility in creating tailored solutions powered by the capabilities of large language models.\n",
    "\n",
    "\n",
    "Its main features are:\n",
    "- **Components**: abstractions for working with LMs\n",
    "- **Off-the-shelf chains**: assembly of components for accomplishing certain higher-level tasks\n",
    "\n",
    "LangChain facilitates the creation of complex pipelines that leverage the connection of components like chains, prompt templates, output parsers and others to compose intricate pipelines that give you everything you need to solve a wide variety of tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the core of LangChain, we have the following elements:\n",
    "\n",
    "- Models\n",
    "- Prompts\n",
    "- Output parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models**\n",
    "\n",
    "Models are nothing more than abstractions over the LLM APIs like the ChatGPT API.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# # Set OPENAI API Key\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "# OR (load from .env file)\n",
    "# make sure you have python-dotenv installed\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(\"./.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL='gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(model=MODEL, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='That sounds exciting! Large Language Models (LLMs) are a fascinating topic with a lot of depth. What specific aspects are you planning to cover in your training? Here are some ideas you might consider including:\\n\\n1. **Introduction to LLMs**: Explain what LLMs are, how they work, and their significance in the field of AI.\\n\\n2. **Architecture**: Discuss the architecture of popular LLMs like GPT, BERT, and others. You could cover concepts like transformers, attention mechanisms, and tokenization.\\n\\n3. **Training Process**: Explain how LLMs are trained, including the data used, the training process, and the challenges involved.\\n\\n4. **Applications**: Highlight various applications of LLMs, such as chatbots, content generation, translation, and more.\\n\\n5. **Ethical Considerations**: Discuss the ethical implications of using LLMs, including bias, misinformation, and the environmental impact of training large models.\\n\\n6. **Hands-On Demonstration**: If possible, include a live demo where participants can interact with an LLM, such as generating text or answering questions.\\n\\n7. **Future Trends**: Talk about the future of LLMs, including advancements in technology and potential new applications.\\n\\n8. **Q&A Session**: Allow time for participants to ask questions and engage in discussion.\\n\\nIf you have specific questions or need resources for any of these topics, feel free to ask!', response_metadata={'token_usage': {'completion_tokens': 295, 'prompt_tokens': 18, 'total_tokens': 313}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_f3db212e1c', 'finish_reason': 'stop', 'logprobs': None}, id='run-26dd4e92-65b3-4bfb-ae45-da4ea6ddbba7-0', usage_metadata={'input_tokens': 18, 'output_tokens': 295, 'total_tokens': 313})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = chat_model.invoke(\"I am teaching a live-training about LLMs!\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That sounds exciting! Large Language Models (LLMs) are a fascinating topic with a lot of depth. What specific aspects are you planning to cover in your training? Here are some ideas you might consider including:\n",
      "\n",
      "1. **Introduction to LLMs**: Explain what LLMs are, how they work, and their significance in the field of AI.\n",
      "\n",
      "2. **Architecture**: Discuss the architecture of popular LLMs like GPT, BERT, and others. You could cover concepts like transformers, attention mechanisms, and tokenization.\n",
      "\n",
      "3. **Training Process**: Explain how LLMs are trained, including the data used, the training process, and the challenges involved.\n",
      "\n",
      "4. **Applications**: Highlight various applications of LLMs, such as chatbots, content generation, translation, and more.\n",
      "\n",
      "5. **Ethical Considerations**: Discuss the ethical implications of using LLMs, including bias, misinformation, and the environmental impact of training large models.\n",
      "\n",
      "6. **Hands-On Demonstration**: If possible, include a live demo where participants can interact with an LLM, such as generating text or answering questions.\n",
      "\n",
      "7. **Future Trends**: Talk about the future of LLMs, including advancements in technology and potential new applications.\n",
      "\n",
      "8. **Q&A Session**: Allow time for participants to ask questions and engage in discussion.\n",
      "\n",
      "If you have specific questions or need resources for any of these topics, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can predict outputs from both LLMs and ChatModels:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic components are:\n",
    "\n",
    "- Models\n",
    "- Prompt templates\n",
    "- Output parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Show me 5 examples of this concept: animal'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"Show me 5 examples of this concept: {concept}\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "prompt.format(concept=\"animal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.runnables.base.RunnableSequence"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke({\"concept\": \"animal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! Here are five examples of different types of animals:\\n\\n1. **Mammal**: **Elephant** - The largest land animal, known for its intelligence, social behavior, and strong familial bonds.\\n\\n2. **Bird**: **Bald Eagle** - A bird of prey known for its white head and tail, symbolizing strength and freedom, and is the national bird of the United States.\\n\\n3. **Reptile**: **Green Iguana** - A large lizard native to Central and South America, known for its vibrant green color and ability to adapt to various environments.\\n\\n4. **Amphibian**: **Poison Dart Frog** - A small, brightly colored frog found in Central and South America, known for its toxic skin that can be lethal to predators.\\n\\n5. **Fish**: **Clownfish** - A small, colorful fish that lives in sea anemones, known for its symbiotic relationship with the anemone and popularized by the movie \"Finding Nemo.\"\\n\\nThese examples illustrate the diversity of the animal kingdom across different classes.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! Here are five examples of different types of animals:\n",
       "\n",
       "1. **Mammal**: **Elephant** - The largest land animal, known for its intelligence, social behavior, and strong familial bonds.\n",
       "\n",
       "2. **Bird**: **Bald Eagle** - A bird of prey known for its white head and tail, symbolizing strength and freedom, and is the national bird of the United States.\n",
       "\n",
       "3. **Reptile**: **Green Iguana** - A large lizard native to Central and South America, known for its vibrant green color and ability to adapt to various environments.\n",
       "\n",
       "4. **Amphibian**: **Poison Dart Frog** - A small, brightly colored frog found in Central and South America, known for its toxic skin that can be lethal to predators.\n",
       "\n",
       "5. **Fish**: **Clownfish** - A small, colorful fish that lives in sea anemones, known for its symbiotic relationship with the anemone and popularized by the movie \"Finding Nemo.\"\n",
       "\n",
       "These examples illustrate the diversity of the animal kingdom across different classes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "Markdown(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the predict method over a string input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here are some cute name ideas for a dog that loves to nap:\\n\\n1. Snoozer\\n2. Naptime\\n3. Dreamer\\n4. Dozer\\n5. Snuggles\\n6. Siesta\\n7. Zzz\\n8. Pillow\\n9. Napster\\n10. Drowse\\n\\nChoose one that fits your dog's personality!\", response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 21, 'total_tokens': 95}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-e7347bfd-1c7f-4c07-b88c-547be07ce054-0', usage_metadata={'input_tokens': 21, 'output_tokens': 74, 'total_tokens': 95})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"What would be a good name for a dog that loves to nap??\"\n",
    "chat_model.invoke(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompts**\n",
    "\n",
    "The same works for prompts. Now, prompts are pieces of text we feed to LLMs, and LangChain allows you to work with prompt templates.\n",
    "\n",
    "Prompt Templates are useful abstractions for reusing prompts and they are used to provide context for the specific task that the language model needs to complete. \n",
    "\n",
    "A simple example is a `PromptTemplate` that formats a string into a prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What is a good dog name for a dog that loves to sleeping?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts  import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"What is a good dog name for a dog that loves to {activity}?\")\n",
    "prompt.format(activity=\"sleeping\")\n",
    "# Output: \"What is a good dog name for a dog that loves to nap?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here are some cute and fitting names for a dog that loves to sleep:\\n\\n1. **Snoozer**\\n2. **Napster**\\n3. **Dozer**\\n4. **Slumber**\\n5. **Dreamer**\\n6. **Pillow**\\n7. **Cuddles**\\n8. **Resty**\\n9. **Zzz**\\n10. **Naptime**\\n\\nChoose one that resonates with your dog's personality!\", response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 21, 'total_tokens': 109}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-8ef93ae2-9ec7-497d-a55f-ece436cf658e-0', usage_metadata={'input_tokens': 21, 'output_tokens': 88, 'total_tokens': 109})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | chat_model\n",
    "\n",
    "chain.invoke({'activity': 'sleeping'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Parsers**\n",
    "\n",
    "OutputParsers convert the raw output from an LLM into a format that can be used downstream. Here is an example of an OutputParser that converts a comma-separated list into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! Here are five examples of different types of landscapes:\\n\\n1. **Mountain Landscape**: A breathtaking view of the Rocky Mountains, featuring towering peaks, lush green valleys, and a clear blue sky. This landscape often includes elements like alpine lakes, dense forests, and wildlife such as deer and eagles.\\n\\n2. **Desert Landscape**: A vast expanse of the Sahara Desert, characterized by rolling sand dunes, sparse vegetation, and a dramatic sunset that casts warm hues across the horizon. This landscape may also include unique rock formations and occasional oases.\\n\\n3. **Coastal Landscape**: A picturesque scene of the Amalfi Coast in Italy, showcasing steep cliffs adorned with colorful villages, crystal-clear waters, and lush Mediterranean vegetation. The landscape is often dotted with boats and features stunning views of the coastline.\\n\\n4. **Forest Landscape**: A serene view of a temperate rainforest, such as the Pacific Northwest, filled with towering trees, ferns, and a rich undergrowth. Mist often hangs in the air, creating a mystical atmosphere, and the sounds of birds and flowing streams enhance the tranquility.\\n\\n5. **Urban Landscape**: A vibrant cityscape of New York City, featuring iconic skyscrapers, bustling streets, and a mix of historic and modern architecture. This landscape captures the energy of urban life, with people, vehicles, and bright lights creating a dynamic environment.\\n\\nThese examples illustrate the diversity of landscapes found in nature and urban settings.', response_metadata={'token_usage': {'completion_tokens': 293, 'prompt_tokens': 18, 'total_tokens': 311}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-797a2e01-f6be-4262-98d2-87ae231e9d34-0', usage_metadata={'input_tokens': 18, 'output_tokens': 293, 'total_tokens': 311})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"concept\": \"Landscapes\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Certainly! Here are five fundamental concepts that are essential to understand when learning about Artificial Neural Networks (ANNs):\\n\\n1. **Neurons and Activation Functions**:\\n   - At the core of ANNs are artificial neurons, which are inspired by biological neurons. Each neuron receives inputs, processes them, and produces an output. The output is typically passed through an activation function, which introduces non-linearity into the model. Common activation functions include Sigmoid, ReLU (Rectified Linear Unit), and Tanh. Understanding how these functions work and their impact on the network's performance is crucial.\\n\\n2. **Network Architecture**:\\n   - The architecture of an ANN refers to the arrangement of neurons in layers, including the input layer, hidden layers, and output layer. The number of layers and the number of neurons in each layer can significantly affect the network's ability to learn and generalize. Concepts such as feedforward networks, convolutional neural networks (CNNs), and recurrent neural networks (RNNs) are important to explore.\\n\\n3. **Forward Propagation and Backpropagation**:\\n   - Forward propagation is the process of passing input data through the network to obtain an output. Backpropagation is the algorithm used to update the weights of the network based on the error of the output compared to the expected result. This involves calculating gradients using the chain rule and applying optimization techniques like gradient descent. Understanding these processes is key to training ANNs effectively.\\n\\n4. **Loss Functions and Optimization**:\\n   - A loss function quantifies how well the ANN's predictions match the actual target values. Common loss functions include Mean Squared Error (MSE) for regression tasks and Cross-Entropy Loss for classification tasks. Optimization algorithms, such as Stochastic Gradient Descent (SGD) and Adam, are used to minimize the loss function during training. Knowing how to choose and implement these functions is vital for model performance.\\n\\n5. **Overfitting and Regularization**:\\n   - Overfitting occurs when a model learns the training data too well, capturing noise and outliers, which leads to poor generalization on unseen data. Regularization techniques, such as L1/L2 regularization, dropout, and early stopping, help mitigate overfitting by adding constraints or modifying the training process. Understanding these concepts is essential for building robust and generalizable models.\\n\\nThese concepts form the foundation for understanding and working with artificial neural networks, enabling learners to build, train, and optimize their own models effectively.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=MODEL, temperature=0.0)\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Write 5 concepts that are fundamental to learn about {topic}.\n",
    "                                          \"\"\")\n",
    "chain = prompt | llm | output_parser\n",
    "chain.invoke({\"topic\": \"Artificial Neural Networks\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chain will take input variables, pass those to a prompt template to create a prompt, pass the prompt to an LLM, and then pass the output through an output parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so these are the basics of langchain. But how can we leverage these abstraction capabilities inside our LLM app application?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to put everything together LangChain allows you to build something called \"chains\", which are components that connect prompts, llms and output parsers into a building block that allows you to create more interesting and complex functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the example below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what the chain is doing is connecting these basic components (the LLM and the prompt template) into\n",
    "a block that can be run separately. The chain allows you to turn workflows using LLLMs into this modular process of composing components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the newer versions of LangChain have a new representation language to create these chains (and more) known as LCEL or LangChain expression language, which is a declarative way to easily compose chains together. The same example as above expressed in this LCEL format would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here are five fundamental concepts to learn about sleep:\\n\\n1. **Sleep Stages and Cycles**: Sleep is divided into several stages, including Non-REM (Rapid Eye Movement) and REM sleep. Non-REM sleep further consists of three stages (N1, N2, and N3), with N3 being deep sleep. Understanding these stages helps elucidate the restorative processes that occur during sleep, such as physical repair, memory consolidation, and emotional regulation.\\n\\n2. **Circadian Rhythms**: Circadian rhythms are the body’s internal clock, regulating the sleep-wake cycle roughly every 24 hours. Factors such as light exposure, hormone levels (like melatonin), and lifestyle choices influence these rhythms. Disruptions to circadian rhythms can lead to sleep disorders and negatively impact overall health.\\n\\n3. **Sleep Hygiene**: Sleep hygiene refers to a set of practices and habits that promote good quality sleep. This includes maintaining a consistent sleep schedule, creating a conducive sleep environment (e.g., dark, quiet, and cool), limiting screen time before bed, and avoiding stimulants like caffeine and nicotine close to bedtime.\\n\\n4. **Sleep Disorders**: There are various sleep disorders, such as insomnia, sleep apnea, narcolepsy, and restless legs syndrome. Understanding these disorders, their symptoms, and potential treatments is essential for recognizing when professional help may be needed to improve sleep quality.\\n\\n5. **Impact of Sleep on Health**: Sleep plays a crucial role in physical and mental health. Adequate sleep is linked to improved cognitive function, emotional well-being, and physical health, including immune function and metabolic regulation. Chronic sleep deprivation can lead to serious health issues, including cardiovascular diseases, obesity, diabetes, and mental health disorders.', response_metadata={'token_usage': {'completion_tokens': 353, 'prompt_tokens': 21, 'total_tokens': 374}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_507c9469a1', 'finish_reason': 'stop', 'logprobs': None}, id='run-44701901-b783-44d1-ae35-77daf3b243d2-0', usage_metadata={'input_tokens': 21, 'output_tokens': 353, 'total_tokens': 374})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\"topic\": \"sleep\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama pull llama3 in the terminal\n",
    "llm = ChatOllama(model=\"llama3.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_ollama.chat_models.ChatOllama"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here are five key concepts that are fundamental to learning about the neuroscience of sleep:\\n\\n1. **Sleep-Wake Cycle Regulation**: The suprachiasmatic nucleus (SCN) is the master biological clock that regulates the body's 24-hour sleep-wake cycle, also known as the circadian rhythm. This cycle involves a complex interplay between light exposure, hormones, and neural activity to maintain our natural sleep-wake patterns.\\n\\n2. **Sleep Stage Architecture**: Sleep is not just one continuous process but rather a series of different stages that occur in a cyclical pattern throughout the night. These stages include:\\n\\t* NREM (non-rapid eye movement) sleep: divided into three sub-stages (N1, N2, and N3), characterized by decreasing cortical activity and increasing parasympathetic dominance.\\n\\t* REM (rapid eye movement) sleep: marked by rapid eye movements, low muscle tone, increased brain activity, and vivid dreams.\\n\\n3. **Neurotransmitters and Sleep**: Various neurotransmitters play a crucial role in regulating sleep and wakefulness. Key players include:\\n\\t* GABA (gamma-aminobutyric acid): an inhibitory neurotransmitter that helps induce relaxation and reduce cortical activity.\\n\\t* Glutamate: an excitatory neurotransmitter that promotes neural activity, particularly during REM sleep.\\n\\t* Norepinephrine, serotonin, and acetylcholine: all of which are involved in regulating arousal and wakefulness.\\n\\n4. **Sleep Spindles and Slow Waves**: During non-REM sleep, especially stage 2 (N2), the brain exhibits characteristic patterns known as:\\n\\t* Sleep spindles: brief bursts of neural activity that help consolidate memories.\\n\\t* Slow waves (delta waves): large-amplitude oscillations in the theta frequency band that reflect decreased cortical activity and increased parasympathetic dominance.\\n\\n5. **The Role of Brain Regions**: Different brain regions contribute to various aspects of sleep regulation, including:\\n\\t* The prefrontal cortex: involved in regulating executive function and decision-making during wakefulness.\\n\\t* The amygdala: processes emotions and helps regulate the body's stress response during both wakefulness and sleep.\\n\\t* The hypothalamus: regulates basic bodily functions like temperature, hunger, and thirst.\\n\\nThese fundamental concepts form the basis of understanding the neuroscience of sleep.\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "\n",
    "chain.invoke({\"topic\": \"neuroscience of sleep\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that now the output is an `AIMessage()` object, which represents LangChain's way to abstract the output from an LLM model like ChatGPT or others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These building blocks and abstractions that LangChain provides are what makes this library so unique, because it gives you the tools you didn't know you need it to build awesome stuff powered by LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple chain for summarization of content. \n",
    "\n",
    "Your chain should:\n",
    "\n",
    "- A prompt template with one or more variables\n",
    "- A model like ChatGPT or other (you can use local models if you'd like, I recommend `ChatOllama` for that!)\n",
    "- Optional: use output parsing or just fetch the string output at the end!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Answer\n",
    "\n",
    "Let's make use of the `ChatPromptTemplate` to abstract away the following pieces of the prompt: \n",
    "- `content` - the text content to be summarized  \n",
    "- `summary_format` - the format in which we want the summary to be presented (like bullet points and so on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Summarize this: This is a test.. The output should be in the following format: One word summary.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Summarize this: {content}. The output should be in the following format: {summary_format}.\")\n",
    "\n",
    "# We can look at a simple example to illustrate what that prompt is doing\n",
    "prompt.format(content=\"This is a test.\", summary_format=\"One word summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we have our prompt template done, let's load the llm and create a nice chain to put everything together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_chat =  ChatOpenAI()\n",
    "chain = prompt | llm_chat # This is the Pipe symbol! from LCEL that connect model to prompt!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we have our chain we can run some tests. The cool thing about working with LLMs is that you can use them to create examples for simple tests like this (avoiding the annoynace of searching online for some piece of text, copying and pasting etc...). So, let's generate a few examples of tests below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='As technology continues to advance, the interaction between humans and machines becomes more integrated into everyday life. From virtual assistants like Siri and Alexa to self-driving cars, the reliance on machines to assist in our daily tasks is only growing. This shift in human-machine interaction raises questions about the future of work and the role of automation in society.\\n\\nWhile machines can greatly improve efficiency and productivity, there are concerns about the potential impact on employment. As more tasks become automated, there is a fear that jobs will be displaced and workers will be left without opportunities. However, proponents of automation argue that it can create new job opportunities and allow humans to focus on more creative and strategic tasks. Finding a balance between human labor and machine automation will be crucial in navigating the future of work and ensuring that both humans and machines can coexist harmoniously.', response_metadata={'token_usage': {'completion_tokens': 164, 'prompt_tokens': 25, 'total_tokens': 189}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0fde7da3-af91-4200-bc46-478e16b1a0a0-0', usage_metadata={'input_tokens': 25, 'output_tokens': 164, 'total_tokens': 189}),\n",
       " AIMessage(content='As technology continues to advance, the relationship between humans and machines becomes increasingly intertwined. From smartphones to smart homes, we rely on machines to assist us in our daily lives. This interaction has led to new ways of communication and problem-solving, as well as concerns about privacy and security.\\n\\nOne area of human-machine interaction that is rapidly growing is artificial intelligence. AI systems are becoming more sophisticated in understanding and responding to human language, leading to advancements in virtual assistants and chatbots. However, the ethical implications of AI have sparked debates about the potential impact on jobs, decision-making processes, and societal values. As we continue to navigate this complex relationship, it is crucial to consider the implications of our reliance on machines in shaping our future interactions.', response_metadata={'token_usage': {'completion_tokens': 146, 'prompt_tokens': 25, 'total_tokens': 171}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7e63aef2-a744-4ea0-b0cd-a88dfc2d7e79-0', usage_metadata={'input_tokens': 25, 'output_tokens': 146, 'total_tokens': 171}),\n",
       " AIMessage(content='As technology continues to advance, the interaction between humans and machines becomes increasingly seamless. From voice-activated virtual assistants to self-driving cars, the ways in which we interact with machines are constantly evolving. This raises questions about the impact of these interactions on our daily lives and the potential for machines to take over tasks traditionally performed by humans.\\n\\nOne area of concern is the potential for job displacement as machines become more capable of performing tasks that were once reserved for humans. However, proponents of human-machine interaction argue that this shift can lead to greater efficiency and productivity, allowing humans to focus on more creative and strategic work. Ultimately, the key to successful human-machine interaction lies in finding a balance between harnessing the capabilities of machines while also preserving the unique skills and abilities of humans.', response_metadata={'token_usage': {'completion_tokens': 153, 'prompt_tokens': 25, 'total_tokens': 178}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-66410f00-e4ca-4833-b6cc-fa34f070525d-0', usage_metadata={'input_tokens': 25, 'output_tokens': 153, 'total_tokens': 178})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples = 3\n",
    "examples = []\n",
    "for i in range(num_examples):\n",
    "    examples.append(llm_chat.invoke(\"Create a piece of text with 2 paragraphs about a random topic regarding human-machine interaction.\"))\n",
    "\n",
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Now that we have our examples, let's run our chain on them and check out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='- Technology advances lead to increased integration of humans and machines in daily life\\n- From virtual assistants to self-driving cars, reliance on machines for daily tasks is growing\\n- Shift raises questions about the future of work and role of automation in society\\n- Concerns about potential impact on employment as tasks become automated\\n- Debate between job displacement and creation of new opportunities through automation\\n- Finding a balance between human labor and machine automation is crucial for harmonious coexistence.', response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 310, 'total_tokens': 403}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-67ec51b2-de36-4ead-ba88-af5d76418cf1-0', usage_metadata={'input_tokens': 310, 'output_tokens': 93, 'total_tokens': 403})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_format = \"bullet points\"\n",
    "\n",
    "outputs = []\n",
    "for ex in examples:\n",
    "    outputs.append(chain.invoke({\"content\": ex, \"summary_format\": summary_format}))\n",
    "\n",
    "# Let's display one example output\n",
    "outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So it seems our chain worked and we generated some summaries! Let's visualize all the summaries generated in a neat way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Output 0 \n",
       " - Technology advances lead to increased integration of humans and machines in daily life\n",
       "- From virtual assistants to self-driving cars, reliance on machines for daily tasks is growing\n",
       "- Shift raises questions about the future of work and role of automation in society\n",
       "- Concerns about potential impact on employment as tasks become automated\n",
       "- Debate between job displacement and creation of new opportunities through automation\n",
       "- Finding a balance between human labor and machine automation is crucial for harmonious coexistence."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Output 1 \n",
       " - As technology advances, humans and machines are becoming more intertwined in various aspects of daily life.\n",
       "- The reliance on machines for communication and problem-solving has raised concerns about privacy and security.\n",
       "- Artificial intelligence is rapidly growing, with AI systems becoming more sophisticated in understanding and responding to human language.\n",
       "- Ethical debates surrounding AI focus on its potential impact on jobs, decision-making processes, and societal values.\n",
       "- It is important to consider the implications of our reliance on machines in shaping future interactions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Output 2 \n",
       " - Technology is advancing, making interactions between humans and machines more seamless\n",
       "- Voice-activated virtual assistants and self-driving cars are examples of evolving interactions with machines\n",
       "- Concerns arise about the impact on daily lives and the potential for machines to replace human tasks\n",
       "- Job displacement is a key concern as machines become more capable\n",
       "- Proponents argue that human-machine interaction can lead to greater efficiency and productivity\n",
       "- Finding a balance between harnessing machine capabilities and preserving human skills is crucial for successful interaction."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "for i in range(num_examples):\n",
    "    display(Markdown(f\"Output {i} \\n {outputs[i].content}\"))\n",
    "# Markdown(f\"**Input**: {examples[0]}\\n\\n**Output**: {outputs[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Our summaries worked, and we were able to apply a given summary format to all of them.\n",
    "\n",
    "LangChain is an extremely powerful library to work with abstractions like these and throughout this course we hope to give you a gliimpse of the cool stuff you can build with it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-langchain",
   "language": "python",
   "name": "oreilly-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
