{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (0.2.14)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (2.0.30)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.32 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (0.2.34)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (0.2.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (0.1.77)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (2.7.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (3.0.0)\n",
      "Requirement already satisfied: langchain-openai in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (0.1.8)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-openai) (0.2.34)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.26.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-openai) (1.34.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (0.1.77)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (2.7.4)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (8.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.66.4)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain-openai) (3.7)\n",
      "Requirement already satisfied: certifi in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain-openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.2->langchain-openai) (3.10.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.1)\n",
      "Requirement already satisfied: langsmith in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (0.1.77)\n",
      "Collecting langsmith\n",
      "  Downloading langsmith-0.1.104-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langsmith) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langsmith) (3.10.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langsmith) (2.7.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langsmith) (2.31.0)\n",
      "Requirement already satisfied: anyio in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (4.4.0)\n",
      "Requirement already satisfied: certifi in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (3.7)\n",
      "Requirement already satisfied: sniffio in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (2.18.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langsmith) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langsmith) (2.2.1)\n",
      "Downloading langsmith-0.1.104-py3-none-any.whl (149 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.1/149.1 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langsmith\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.77\n",
      "    Uninstalling langsmith-0.1.77:\n",
      "      Successfully uninstalled langsmith-0.1.77\n",
      "Successfully installed langsmith-0.1.104\n"
     ]
    }
   ],
   "source": [
    "# uncomment and run below:\n",
    "!pip install langchain==0.2.14\n",
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to LangChain \n",
    "\n",
    "Working with LLMs involves in one way or another working with a specific type of abstraction: \"Prompts\".\n",
    "\n",
    "However, in the practical context of day-to-day tasks we expect LLMs to perform, these prompts won't be some static and dead type of abstraction. Instead we'll work with dynamic prompts re-usable prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lanchain\n",
    "\n",
    "[LangChain](https://python.langchain.com/docs/get_started/introduction.html) is a framework that allows you to connect LLMs together by allowing you to work with modular components like prompt templates and chains giving you immense flexibility in creating tailored solutions powered by the capabilities of large language models.\n",
    "\n",
    "\n",
    "Its main features are:\n",
    "- **Components**: abstractions for working with LMs\n",
    "- **Off-the-shelf chains**: assembly of components for accomplishing certain higher-level tasks\n",
    "\n",
    "LangChain facilitates the creation of complex pipelines that leverage the connection of components like chains, prompt templates, output parsers and others to compose intricate pipelines that give you everything you need to solve a wide variety of tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the core of LangChain, we have the following elements:\n",
    "\n",
    "- Models\n",
    "- Prompts\n",
    "- Output parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models**\n",
    "\n",
    "Models are nothing more than abstractions over the LLM APIs like the ChatGPT API.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# # Set OPENAI API Key\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "# OR (load from .env file)\n",
    "# make sure you have python-dotenv installed\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(\"./.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL='gpt-4o-mini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(model=MODEL, temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That sounds exciting! Teaching about Large Language Models (LLMs) can be a rewarding experience, as they are a fascinating and rapidly evolving area of AI. Here are some key topics and tips you might consider including in your live training:\\n\\n### Key Topics to Cover\\n\\n1. **Introduction to LLMs**:\\n   - What are LLMs?\\n   - Brief history and evolution of language models (from n-grams to transformers).\\n\\n2. **How LLMs Work**:\\n   - Overview of the transformer architecture.\\n   - Explanation of attention mechanisms.\\n   - Training processes (pre-training and fine-tuning).\\n\\n3. **Applications of LLMs**:\\n   - Text generation (e.g., chatbots, content creation).\\n   - Text summarization.\\n   - Translation and language understanding.\\n   - Code generation and assistance.\\n\\n4. **Ethical Considerations**:\\n   - Bias in language models.\\n   - Misinformation and the potential for misuse.\\n   - Importance of responsible AI usage.\\n\\n5. **Hands-On Demonstration**:\\n   - Show how to use an LLM (e.g., OpenAI's GPT, Hugging Face Transformers).\\n   - Live coding session or interactive examples.\\n\\n6. **Future Trends**:\\n   - Ongoing research and advancements in LLMs.\\n   - Potential future applications and challenges.\\n\\n### Tips for Effective Training\\n\\n- **Engage Your Audience**: Encourage questions and discussions throughout the session. Use polls or quizzes to keep participants engaged.\\n  \\n- **Use Visuals**: Incorporate diagrams, flowcharts, and videos to illustrate complex concepts.\\n\\n- **Provide Resources**: Share links to papers, articles, and tools for further learning.\\n\\n- **Real-World Examples**: Use case studies or examples of how companies are leveraging LLMs.\\n\\n- **Interactive Activities**: Consider including breakout sessions or group activities where participants can brainstorm applications or ethical considerations.\\n\\n- **Feedback Loop**: At the end of the session, gather feedback to improve future trainings.\\n\\nIf you have specific areas you want to focus on or any questions, feel free to ask!\", response_metadata={'token_usage': {'completion_tokens': 427, 'prompt_tokens': 19, 'total_tokens': 446}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-fb6f54d5-285e-431b-8c77-0533d9a87b14-0', usage_metadata={'input_tokens': 19, 'output_tokens': 427, 'total_tokens': 446})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = chat_model.invoke(\"I am teaching a live-training\\\n",
    "    about LLMs!\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That sounds exciting! Teaching about Large Language Models (LLMs) can be a rewarding experience, as they are a fascinating and rapidly evolving area of AI. Here are some key topics and tips you might consider including in your live training:\n",
      "\n",
      "### Key Topics to Cover\n",
      "\n",
      "1. **Introduction to LLMs**:\n",
      "   - What are LLMs?\n",
      "   - Brief history and evolution of language models (from n-grams to transformers).\n",
      "\n",
      "2. **How LLMs Work**:\n",
      "   - Overview of the transformer architecture.\n",
      "   - Explanation of attention mechanisms.\n",
      "   - Training processes (pre-training and fine-tuning).\n",
      "\n",
      "3. **Applications of LLMs**:\n",
      "   - Text generation (e.g., chatbots, content creation).\n",
      "   - Text summarization.\n",
      "   - Translation and language understanding.\n",
      "   - Code generation and assistance.\n",
      "\n",
      "4. **Ethical Considerations**:\n",
      "   - Bias in language models.\n",
      "   - Misinformation and the potential for misuse.\n",
      "   - Importance of responsible AI usage.\n",
      "\n",
      "5. **Hands-On Demonstration**:\n",
      "   - Show how to use an LLM (e.g., OpenAI's GPT, Hugging Face Transformers).\n",
      "   - Live coding session or interactive examples.\n",
      "\n",
      "6. **Future Trends**:\n",
      "   - Ongoing research and advancements in LLMs.\n",
      "   - Potential future applications and challenges.\n",
      "\n",
      "### Tips for Effective Training\n",
      "\n",
      "- **Engage Your Audience**: Encourage questions and discussions throughout the session. Use polls or quizzes to keep participants engaged.\n",
      "  \n",
      "- **Use Visuals**: Incorporate diagrams, flowcharts, and videos to illustrate complex concepts.\n",
      "\n",
      "- **Provide Resources**: Share links to papers, articles, and tools for further learning.\n",
      "\n",
      "- **Real-World Examples**: Use case studies or examples of how companies are leveraging LLMs.\n",
      "\n",
      "- **Interactive Activities**: Consider including breakout sessions or group activities where participants can brainstorm applications or ethical considerations.\n",
      "\n",
      "- **Feedback Loop**: At the end of the session, gather feedback to improve future trainings.\n",
      "\n",
      "If you have specific areas you want to focus on or any questions, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can predict outputs from both LLMs and ChatModels:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic components are:\n",
    "\n",
    "- Models\n",
    "- Prompt templates\n",
    "- Output parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Show me 5 examples of this concept: animal'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"Show me 5 examples of this concept: {concept}\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "prompt.format(concept=\"animal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.runnables.base.RunnableSequence"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke({\"concept\": \"animal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! Here are five examples of different types of animals:\\n\\n1. **Mammal**: **Elephant** - The largest land animal, known for its intelligence, social behavior, and strong familial bonds.\\n\\n2. **Bird**: **Bald Eagle** - A bird of prey found in North America, recognized for its white head and tail, and a symbol of strength and freedom.\\n\\n3. **Reptile**: **Green Iguana** - A large lizard native to Central and South America, known for its vibrant green color and ability to adapt to various environments.\\n\\n4. **Amphibian**: **Poison Dart Frog** - A small, brightly colored frog found in Central and South America, known for its toxic skin and vibrant colors that serve as a warning to predators.\\n\\n5. **Fish**: **Clownfish** - A small, colorful fish that lives in sea anemones, known for its symbiotic relationship with the anemone and popularized by the movie \"Finding Nemo.\"\\n\\nThese examples illustrate the diversity of the animal kingdom across different classes.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure! Here are five examples of different types of animals:\n",
       "\n",
       "1. **Mammal**: **Elephant** - The largest land animal, known for its intelligence, social behavior, and strong familial bonds.\n",
       "\n",
       "2. **Bird**: **Bald Eagle** - A bird of prey found in North America, recognized for its white head and tail, and a symbol of strength and freedom.\n",
       "\n",
       "3. **Reptile**: **Green Iguana** - A large lizard native to Central and South America, known for its vibrant green color and ability to adapt to various environments.\n",
       "\n",
       "4. **Amphibian**: **Poison Dart Frog** - A small, brightly colored frog found in Central and South America, known for its toxic skin and vibrant colors that serve as a warning to predators.\n",
       "\n",
       "5. **Fish**: **Clownfish** - A small, colorful fish that lives in sea anemones, known for its symbiotic relationship with the anemone and popularized by the movie \"Finding Nemo.\"\n",
       "\n",
       "These examples illustrate the diversity of the animal kingdom across different classes."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "Markdown(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the predict method over a string input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here are some cute name ideas for a dog that loves to nap:\\n\\n1. Snoozer\\n2. Naptime\\n3. Dreamer\\n4. Dozer\\n5. Snuggles\\n6. Siesta\\n7. Zzz\\n8. Pillow\\n9. Napster\\n10. Drowse\\n\\nChoose one that fits your dog's personality!\", response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 21, 'total_tokens': 95}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-e7347bfd-1c7f-4c07-b88c-547be07ce054-0', usage_metadata={'input_tokens': 21, 'output_tokens': 74, 'total_tokens': 95})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"What would be a good name for a dog that loves to nap??\"\n",
    "chat_model.invoke(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompts**\n",
    "\n",
    "The same works for prompts. Now, prompts are pieces of text we feed to LLMs, and LangChain allows you to work with prompt templates.\n",
    "\n",
    "Prompt Templates are useful abstractions for reusing prompts and they are used to provide context for the specific task that the language model needs to complete. \n",
    "\n",
    "A simple example is a `PromptTemplate` that formats a string into a prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What is a good dog name for a dog that loves to sleeping?'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts  import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"What is a good dog name for a dog that loves to {activity}?\")\n",
    "prompt.format(activity=\"sleeping\")\n",
    "# Output: \"What is a good dog name for a dog that loves to nap?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Parsers**\n",
    "\n",
    "OutputParsers convert the raw output from an LLM into a format that can be used downstream. Here is an example of an OutputParser that converts a comma-separated list into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! Here are five examples of different types of landscapes:\\n\\n1. **Mountain Landscape**: A breathtaking view of the Rocky Mountains, featuring towering peaks, lush green valleys, and a clear blue sky. This landscape often includes elements like alpine lakes, dense forests, and wildlife such as deer and eagles.\\n\\n2. **Desert Landscape**: A vast expanse of the Sahara Desert, characterized by rolling sand dunes, sparse vegetation, and a dramatic sunset that casts warm hues across the horizon. This landscape may also include unique rock formations and occasional oases.\\n\\n3. **Coastal Landscape**: A picturesque scene of the Amalfi Coast in Italy, showcasing steep cliffs adorned with colorful villages, crystal-clear waters, and lush Mediterranean vegetation. The landscape is often dotted with boats and features stunning views of the coastline.\\n\\n4. **Forest Landscape**: A serene view of a temperate rainforest, such as the Pacific Northwest, filled with towering trees, ferns, and a rich undergrowth. Mist often hangs in the air, creating a mystical atmosphere, and the sounds of birds and flowing streams enhance the tranquility.\\n\\n5. **Urban Landscape**: A vibrant cityscape of New York City, featuring iconic skyscrapers, bustling streets, and a mix of historic and modern architecture. This landscape captures the energy of urban life, with people, vehicles, and bright lights creating a dynamic environment.\\n\\nThese examples illustrate the diversity of landscapes found in nature and urban settings.', response_metadata={'token_usage': {'completion_tokens': 293, 'prompt_tokens': 18, 'total_tokens': 311}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-797a2e01-f6be-4262-98d2-87ae231e9d34-0', usage_metadata={'input_tokens': 18, 'output_tokens': 293, 'total_tokens': 311})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"concept\": \"Landscapes\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure! Here are five examples of different types of landscapes:\\n\\n1. **Mountain Landscape**: A breathtaking view of the Rocky Mountains, featuring towering peaks, rugged terrain, and lush valleys. The scene might include a clear blue sky, patches of snow on the summits, and a winding river flowing through the valley below.\\n\\n2. **Desert Landscape**: A vast expanse of the Sahara Desert, characterized by rolling sand dunes, sparse vegetation, and a striking sunset that casts warm hues of orange and red across the sky. The landscape may also include unique rock formations and the occasional oasis.\\n\\n3. **Coastal Landscape**: A picturesque view of the Amalfi Coast in Italy, showcasing steep cliffs adorned with colorful villages, lush greenery, and the sparkling blue Mediterranean Sea. The scene might feature boats bobbing in the water and vibrant flowers cascading down the cliffs.\\n\\n4. **Forest Landscape**: A serene scene in a temperate rainforest, with towering trees, a thick canopy, and a carpet of ferns and moss on the forest floor. Sunlight filters through the leaves, creating dappled patterns of light and shadow, while a gentle stream meanders through the underbrush.\\n\\n5. **Urban Landscape**: A dynamic cityscape of New York City, featuring iconic skyscrapers, bustling streets, and a vibrant mix of cultures. The scene might include the bright lights of Times Square, the green expanse of Central Park, and the historic architecture of Brooklyn Bridge.\\n\\nThese examples illustrate the diversity of landscapes found in nature and urban environments.', response_metadata={'token_usage': {'completion_tokens': 312, 'prompt_tokens': 18, 'total_tokens': 330}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_48196bc67a', 'finish_reason': 'stop', 'logprobs': None}, id='run-f5c7e1ba-0e08-4488-be29-493413f7af30-0', usage_metadata={'input_tokens': 18, 'output_tokens': 312, 'total_tokens': 330})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"concept\": \"Landscapes\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Certainly! Here are five fundamental concepts that are essential to understand when learning about Artificial Neural Networks (ANNs):\\n\\n1. **Neurons and Activation Functions**:\\n   - **Neurons** are the basic building blocks of ANNs, similar to biological neurons. Each neuron receives input, processes it, and produces an output.\\n   - **Activation Functions** determine whether a neuron should be activated based on the weighted sum of its inputs. Common activation functions include Sigmoid, ReLU (Rectified Linear Unit), and Tanh. They introduce non-linearity into the model, allowing it to learn complex patterns.\\n\\n2. **Layers and Architecture**:\\n   - ANNs are organized into layers: input layer, hidden layers, and output layer. The **input layer** receives the initial data, **hidden layers** perform computations and learn features, and the **output layer** produces the final predictions.\\n   - The architecture of a neural network (number of layers, number of neurons per layer) significantly impacts its ability to learn and generalize from data.\\n\\n3. **Forward Propagation and Backpropagation**:\\n   - **Forward Propagation** is the process of passing inputs through the network to obtain an output. During this process, inputs are transformed through the weights and activation functions.\\n   - **Backpropagation** is the algorithm used for training the network. It calculates the gradient of the loss function with respect to each weight by applying the chain rule, allowing the model to update its weights to minimize prediction error.\\n\\n4. **Loss Functions and Optimization**:\\n   - **Loss Functions** quantify how well the neural network's predictions match the actual target values. Common loss functions include Mean Squared Error for regression tasks and Cross-Entropy Loss for classification tasks.\\n   - **Optimization Algorithms** (like Stochastic Gradient Descent, Adam, etc.) are used to minimize the loss function by adjusting the weights of the network. The choice of optimizer and learning rate can greatly influence the training process.\\n\\n5. **Overfitting, Regularization, and Generalization**:\\n   - **Overfitting** occurs when a model learns the training data too well, including noise and outliers, resulting in poor performance on unseen data.\\n   - **Regularization techniques** (like L1 and L2 regularization, dropout, and early stopping) are employed to prevent overfitting by penalizing overly complex models or randomly dropping neurons during training.\\n   - Understanding **generalization**—the model's ability to perform well on new, unseen data—is crucial for developing robust neural networks.\\n\\nThese concepts form the foundation for understanding how artificial neural networks function, how they are trained, and how to apply them effectively in various machine learning tasks.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=MODEL)\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Write 5 concepts that are fundamental to learn about {topic}.\n",
    "                                          \"\"\")\n",
    "chain = prompt | llm | output_parser\n",
    "chain.invoke({\"topic\": \"Artificial Neural Networks\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chain will take input variables, pass those to a prompt template to create a prompt, pass the prompt to an LLM, and then pass the output through an output parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so these are the basics of langchain. But how can we leverage these abstraction capabilities inside our LLM app application?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to put everything together LangChain allows you to build something called \"chains\", which are components that connect prompts, llms and output parsers into a building block that allows you to create more interesting and complex functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the example below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what the chain is doing is connecting these basic components (the LLM and the prompt template) into\n",
    "a block that can be run separately. The chain allows you to turn workflows using LLLMs into this modular process of composing components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the newer versions of LangChain have a new representation language to create these chains (and more) known as LCEL or LangChain expression language, which is a declarative way to easily compose chains together. The same example as above expressed in this LCEL format would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here are five fundamental concepts to learn about sleep:\\n\\n1. **Sleep Stages and Cycles**: Sleep is divided into several stages, including Non-REM (Rapid Eye Movement) and REM sleep. Non-REM sleep further consists of three stages (N1, N2, and N3), with N3 being deep sleep. Understanding these stages helps elucidate the restorative processes that occur during sleep, such as physical repair, memory consolidation, and emotional regulation.\\n\\n2. **Circadian Rhythms**: Circadian rhythms are the body’s internal clock, regulating the sleep-wake cycle roughly every 24 hours. Factors such as light exposure, hormone levels (like melatonin), and lifestyle choices influence these rhythms. Disruptions to circadian rhythms can lead to sleep disorders and negatively impact overall health.\\n\\n3. **Sleep Hygiene**: Sleep hygiene refers to a set of practices and habits that promote good quality sleep. This includes maintaining a consistent sleep schedule, creating a conducive sleep environment (e.g., dark, quiet, and cool), limiting screen time before bed, and avoiding stimulants like caffeine and nicotine close to bedtime.\\n\\n4. **Sleep Disorders**: There are various sleep disorders, such as insomnia, sleep apnea, narcolepsy, and restless legs syndrome. Understanding these disorders, their symptoms, and potential treatments is essential for recognizing when professional help may be needed to improve sleep quality.\\n\\n5. **Impact of Sleep on Health**: Sleep plays a crucial role in physical and mental health. Adequate sleep is linked to improved cognitive function, emotional well-being, and physical health, including immune function and metabolic regulation. Chronic sleep deprivation can lead to serious health issues, including cardiovascular diseases, obesity, diabetes, and mental health disorders.', response_metadata={'token_usage': {'completion_tokens': 353, 'prompt_tokens': 21, 'total_tokens': 374}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_507c9469a1', 'finish_reason': 'stop', 'logprobs': None}, id='run-44701901-b783-44d1-ae35-77daf3b243d2-0', usage_metadata={'input_tokens': 21, 'output_tokens': 353, 'total_tokens': 374})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\"topic\": \"sleep\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama pull llama3 in the terminal\n",
    "llm = ChatOllama(model=\"llama3.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are five key concepts fundamental to understanding the neuroscience of sleep:\\n\\n1. **Sleep-Wake Cycle (Circadian Rhythm)**: The internal biological clock that regulates the sleep-wake cycle, also known as the circadian rhythm. This cycle is controlled by a group of cells in the suprachiasmatic nucleus (SCN) of the hypothalamus and responds to light and darkness signals from the environment.\\n\\n2. **Sleep Stages**: Sleep can be divided into two main stages: non-rapid eye movement (NREM) sleep and rapid eye movement (REM) sleep. NREM sleep is further subdivided into three stages, each characterized by distinct brain wave patterns, such as slow-wave sleep (SWS), stage 2 NREM, and stage 3 NREM. REM sleep is marked by high brain activity, similar to that of being awake.\\n\\n3. **Sleep-Wake Homeostasis**: The process by which the drive for sleep and wakefulness is regulated and adjusted based on previous sleep and wake periods. This homeostatic mechanism ensures that we get enough sleep and stay alert during the day.\\n\\n4. **Neurotransmitters and Modulators of Sleep**: Various neurotransmitters and modulators, such as norepinephrine, serotonin, dopamine, acetylcholine, and GABA, play crucial roles in regulating sleep-wake transitions and maintaining different stages of sleep. These chemicals can either promote or inhibit sleep, depending on their levels and activity.\\n\\n5. **REM Sleep and Memory Consolidation**: REM sleep is essential for memory consolidation, the process by which memories are transferred from short-term to long-term storage. Research suggests that REM sleep helps strengthen neural connections and improves learning and memory recall by reactivating and replaying previously experienced events.\\n\\nThese five concepts form a foundation for understanding the complex neuroscience of sleep and its importance in maintaining our physical and mental well-being.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | output_parser\n",
    "\n",
    "chain.invoke({\"topic\": \"neuroscience of sleep\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that now the output is an `AIMessage()` object, which represents LangChain's way to abstract the output from an LLM model like ChatGPT or others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These building blocks and abstractions that LangChain provides are what makes this library so unique, because it gives you the tools you didn't know you need it to build awesome stuff powered by LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple chain for summarization of content. \n",
    "\n",
    "Your chain should:\n",
    "\n",
    "- A prompt template with one or more variables\n",
    "- A model like ChatGPT or other (you can use local models if you'd like, I recommend `ChatOllama` for that!)\n",
    "- Optional: use output parsing or just fetch the string output at the end!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Answer\n",
    "\n",
    "Let's make use of the `ChatPromptTemplate` to abstract away the following pieces of the prompt: \n",
    "- `content` - the text content to be summarized  \n",
    "- `summary_format` - the format in which we want the summary to be presented (like bullet points and so on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Summarize this: This is a test.. The output should be in the following format: One word summary.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Summarize this: {content}. The output should be in the following format: {summary_format}.\")\n",
    "\n",
    "# We can look at a simple example to illustrate what that prompt is doing\n",
    "prompt.format(content=\"This is a test.\", summary_format=\"One word summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we have our prompt template done, let's load the llm and create a nice chain to put everything together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_chat =  ChatOpenAI()\n",
    "chain = prompt | llm_chat # This is the Pipe symbol! from LCEL that connect model to prompt!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we have our chain we can run some tests. The cool thing about working with LLMs is that you can use them to create examples for simple tests like this (avoiding the annoynace of searching online for some piece of text, copying and pasting etc...). So, let's generate a few examples of tests below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='As technology continues to advance, the interaction between humans and machines becomes more integrated into everyday life. From virtual assistants like Siri and Alexa to self-driving cars, the reliance on machines to assist in our daily tasks is only growing. This shift in human-machine interaction raises questions about the future of work and the role of automation in society.\\n\\nWhile machines can greatly improve efficiency and productivity, there are concerns about the potential impact on employment. As more tasks become automated, there is a fear that jobs will be displaced and workers will be left without opportunities. However, proponents of automation argue that it can create new job opportunities and allow humans to focus on more creative and strategic tasks. Finding a balance between human labor and machine automation will be crucial in navigating the future of work and ensuring that both humans and machines can coexist harmoniously.', response_metadata={'token_usage': {'completion_tokens': 164, 'prompt_tokens': 25, 'total_tokens': 189}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0fde7da3-af91-4200-bc46-478e16b1a0a0-0', usage_metadata={'input_tokens': 25, 'output_tokens': 164, 'total_tokens': 189}),\n",
       " AIMessage(content='As technology continues to advance, the relationship between humans and machines becomes increasingly intertwined. From smartphones to smart homes, we rely on machines to assist us in our daily lives. This interaction has led to new ways of communication and problem-solving, as well as concerns about privacy and security.\\n\\nOne area of human-machine interaction that is rapidly growing is artificial intelligence. AI systems are becoming more sophisticated in understanding and responding to human language, leading to advancements in virtual assistants and chatbots. However, the ethical implications of AI have sparked debates about the potential impact on jobs, decision-making processes, and societal values. As we continue to navigate this complex relationship, it is crucial to consider the implications of our reliance on machines in shaping our future interactions.', response_metadata={'token_usage': {'completion_tokens': 146, 'prompt_tokens': 25, 'total_tokens': 171}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-7e63aef2-a744-4ea0-b0cd-a88dfc2d7e79-0', usage_metadata={'input_tokens': 25, 'output_tokens': 146, 'total_tokens': 171}),\n",
       " AIMessage(content='As technology continues to advance, the interaction between humans and machines becomes increasingly seamless. From voice-activated virtual assistants to self-driving cars, the ways in which we interact with machines are constantly evolving. This raises questions about the impact of these interactions on our daily lives and the potential for machines to take over tasks traditionally performed by humans.\\n\\nOne area of concern is the potential for job displacement as machines become more capable of performing tasks that were once reserved for humans. However, proponents of human-machine interaction argue that this shift can lead to greater efficiency and productivity, allowing humans to focus on more creative and strategic work. Ultimately, the key to successful human-machine interaction lies in finding a balance between harnessing the capabilities of machines while also preserving the unique skills and abilities of humans.', response_metadata={'token_usage': {'completion_tokens': 153, 'prompt_tokens': 25, 'total_tokens': 178}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-66410f00-e4ca-4833-b6cc-fa34f070525d-0', usage_metadata={'input_tokens': 25, 'output_tokens': 153, 'total_tokens': 178})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples = 3\n",
    "examples = []\n",
    "for i in range(num_examples):\n",
    "    examples.append(llm_chat.invoke(\"Create a piece of text with 2 paragraphs about a random topic regarding human-machine interaction.\"))\n",
    "\n",
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Now that we have our examples, let's run our chain on them and check out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='- Technology advances lead to increased integration of humans and machines in daily life\\n- From virtual assistants to self-driving cars, reliance on machines for daily tasks is growing\\n- Shift raises questions about the future of work and role of automation in society\\n- Concerns about potential impact on employment as tasks become automated\\n- Debate between job displacement and creation of new opportunities through automation\\n- Finding a balance between human labor and machine automation is crucial for harmonious coexistence.', response_metadata={'token_usage': {'completion_tokens': 93, 'prompt_tokens': 310, 'total_tokens': 403}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-67ec51b2-de36-4ead-ba88-af5d76418cf1-0', usage_metadata={'input_tokens': 310, 'output_tokens': 93, 'total_tokens': 403})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_format = \"bullet points\"\n",
    "\n",
    "outputs = []\n",
    "for ex in examples:\n",
    "    outputs.append(chain.invoke({\"content\": ex, \"summary_format\": summary_format}))\n",
    "\n",
    "# Let's display one example output\n",
    "outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So it seems our chain worked and we generated some summaries! Let's visualize all the summaries generated in a neat way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Output 0 \n",
       " - Technology advances lead to increased integration of humans and machines in daily life\n",
       "- From virtual assistants to self-driving cars, reliance on machines for daily tasks is growing\n",
       "- Shift raises questions about the future of work and role of automation in society\n",
       "- Concerns about potential impact on employment as tasks become automated\n",
       "- Debate between job displacement and creation of new opportunities through automation\n",
       "- Finding a balance between human labor and machine automation is crucial for harmonious coexistence."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Output 1 \n",
       " - As technology advances, humans and machines are becoming more intertwined in various aspects of daily life.\n",
       "- The reliance on machines for communication and problem-solving has raised concerns about privacy and security.\n",
       "- Artificial intelligence is rapidly growing, with AI systems becoming more sophisticated in understanding and responding to human language.\n",
       "- Ethical debates surrounding AI focus on its potential impact on jobs, decision-making processes, and societal values.\n",
       "- It is important to consider the implications of our reliance on machines in shaping future interactions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Output 2 \n",
       " - Technology is advancing, making interactions between humans and machines more seamless\n",
       "- Voice-activated virtual assistants and self-driving cars are examples of evolving interactions with machines\n",
       "- Concerns arise about the impact on daily lives and the potential for machines to replace human tasks\n",
       "- Job displacement is a key concern as machines become more capable\n",
       "- Proponents argue that human-machine interaction can lead to greater efficiency and productivity\n",
       "- Finding a balance between harnessing machine capabilities and preserving human skills is crucial for successful interaction."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "for i in range(num_examples):\n",
    "    display(Markdown(f\"Output {i} \\n {outputs[i].content}\"))\n",
    "# Markdown(f\"**Input**: {examples[0]}\\n\\n**Output**: {outputs[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Our summaries worked, and we were able to apply a given summary format to all of them.\n",
    "\n",
    "LangChain is an extremely powerful library to work with abstractions like these and throughout this course we hope to give you a gliimpse of the cool stuff you can build with it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-langchain",
   "language": "python",
   "name": "oreilly-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
