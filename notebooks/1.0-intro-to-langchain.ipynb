{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (0.1.8)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.21 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (0.0.21)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.24 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (0.1.45)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (0.1.3)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.2,>=0.1.24->langchain) (23.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: langchain-openai in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (0.1.3)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.42 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-openai) (0.1.45)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-openai) (1.12.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (0.1.3)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (2.6.1)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.42->langchain-openai) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.3.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.26.0)\n",
      "Requirement already satisfied: sniffio in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2024.4.16)\n",
      "Requirement already satisfied: requests>=2.26.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai) (3.6)\n",
      "Requirement already satisfied: certifi in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.3)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.42->langchain-openai) (2.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.42->langchain-openai) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain-openai) (2.2.1)\n",
      "Requirement already satisfied: langsmith in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (0.1.3)\n",
      "Collecting langsmith\n",
      "  Using cached langsmith-0.1.49-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langsmith) (3.10.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langsmith) (2.6.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from langsmith) (2.31.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (2.16.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from pydantic<3,>=1->langsmith) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langsmith) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langsmith) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langsmith) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/greatmaster/miniconda3/envs/oreilly-langchain/lib/python3.11/site-packages (from requests<3,>=2->langsmith) (2024.2.2)\n",
      "Using cached langsmith-0.1.49-py3-none-any.whl (115 kB)\n",
      "Installing collected packages: langsmith\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.3\n",
      "    Uninstalling langsmith-0.1.3:\n",
      "      Successfully uninstalled langsmith-0.1.3\n",
      "Successfully installed langsmith-0.1.49\n"
     ]
    }
   ],
   "source": [
    "# uncomment and run below:\n",
    "!pip install langchain\n",
    "!pip install langchain-openai\n",
    "!pip install -U langsmith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to LangChain \n",
    "\n",
    "Working with LLMs involves in one way or another working with a specific type of abstraction: \"Prompts\".\n",
    "\n",
    "However, in the practical context of day-to-day tasks we expect LLMs to perform, these prompts won't be some static and dead type of abstraction. Instead we'll work with dynamic prompts re-usable prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lanchain\n",
    "\n",
    "[LangChain](https://python.langchain.com/docs/get_started/introduction.html) is a framework that allows you to connect LLMs together by allowing you to work with modular components like prompt templates and chains giving you immense flexibility in creating tailored solutions powered by the capabilities of large language models.\n",
    "\n",
    "\n",
    "Its main features are:\n",
    "- **Components**: abstractions for working with LMs\n",
    "- **Off-the-shelf chains**: assembly of components for accomplishing certain higher-level tasks\n",
    "\n",
    "LangChain facilitates the creation of complex pipelines that leverage the connection of components like chains, prompt templates, output parsers and others to compose intricate pipelines that give you everything you need to solve a wide variety of tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the core of LangChain, we have the following elements:\n",
    "\n",
    "- Models\n",
    "- Prompts\n",
    "- Output parsers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Models**\n",
    "\n",
    "Models are nothing more than abstractions over the LLM APIs like the ChatGPT API.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and add your api key!!!\n",
    "\n",
    "import os\n",
    "\n",
    "# Set OPENAI API Key\n",
    "\n",
    "# colab\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"<put your openai api key here\"\n",
    "\n",
    "# OR (load from .env file)\n",
    "# make sure you have python-dotenv installed\n",
    "\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv(\"./.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's great! LLMs, or Master of Laws degrees, are advanced legal degrees that are typically pursued by individuals who already have a law degree and want to specialize in a particular area of law or gain expertise in a specific legal field. During your live training, you can cover topics such as the different types of LLM programs available, the admissions process, the curriculum and coursework, career opportunities for LLM graduates, and the benefits of pursuing an LLM degree. You can also provide practical tips and advice for individuals who are considering pursuing an LLM. Good luck with your training!\", response_metadata={'token_usage': {'completion_tokens': 119, 'prompt_tokens': 19, 'total_tokens': 138}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-c09cea1a-983e-49d8-b7e1-a6adc12e6cb3-0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = chat_model.invoke(\"I am teaching a live-training\\\n",
    "    about LLMs!\")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.messages.ai.AIMessage"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's great! LLMs, or Master of Laws degrees, are advanced legal degrees that are typically pursued by individuals who already have a law degree and want to specialize in a particular area of law or gain expertise in a specific legal field. During your live training, you can cover topics such as the different types of LLM programs available, the admissions process, the curriculum and coursework, career opportunities for LLM graduates, and the benefits of pursuing an LLM degree. You can also provide practical tips and advice for individuals who are considering pursuing an LLM. Good luck with your training!\n"
     ]
    }
   ],
   "source": [
    "print(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can predict outputs from both LLMs and ChatModels:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic components are:\n",
    "\n",
    "- Models\n",
    "- Prompt templates\n",
    "- Output parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Show me 5 examples of this concept: animal'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "template = \"Show me 5 examples of this concept: {concept}\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "prompt.format(concept=\"animal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke({\"concept\": \"animal\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Dogs are a common household pet that are known for their loyalty and companionship.\\n2. Elephants are large, intelligent animals that are known for their impressive memory and social behavior.\\n3. Dolphins are highly intelligent marine mammals known for their playful behavior and advanced communication skills.\\n4. Cheetahs are the fastest land animals, capable of reaching speeds up to 70 miles per hour in short bursts.\\n5. Penguins are flightless birds that are highly adapted to living in cold climates, with specialized flippers for swimming and sliding on ice.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "1. Dogs are a common household pet that are known for their loyalty and companionship.\n",
       "2. Elephants are large, intelligent animals that are known for their impressive memory and social behavior.\n",
       "3. Dolphins are highly intelligent marine mammals known for their playful behavior and advanced communication skills.\n",
       "4. Cheetahs are the fastest land animals, capable of reaching speeds up to 70 miles per hour in short bursts.\n",
       "5. Penguins are flightless birds that are highly adapted to living in cold climates, with specialized flippers for swimming and sliding on ice."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "\n",
    "Markdown(output.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the predict method over a string input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Snooze', response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 21, 'total_tokens': 24}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-d72d1f2d-4257-46b2-a724-0e3f0955248e-0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"What would be a good name for a dog that loves to nap??\"\n",
    "chat_model.invoke(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prompts**\n",
    "\n",
    "The same works for prompts. Now, prompts are pieces of text we feed to LLMs, and LangChain allows you to work with prompt templates.\n",
    "\n",
    "Prompt Templates are useful abstractions for reusing prompts and they are used to provide context for the specific task that the language model needs to complete. \n",
    "\n",
    "A simple example is a `PromptTemplate` that formats a string into a prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What is a good dog name for a dog that loves to sleeping?'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts  import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"What is a good dog name for a dog that loves to {activity}?\")\n",
    "prompt.format(activity=\"sleeping\")\n",
    "# Output: \"What is a good dog name for a dog that loves to nap?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Parsers**\n",
    "\n",
    "OutputParsers convert the raw output from an LLM into a format that can be used downstream. Here is an example of an OutputParser that converts a comma-separated list into a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='1. A lush green forest with towering trees, glistening streams, and a variety of wildlife.\\n2. A vast desert landscape with towering sand dunes, sparse vegetation, and a clear blue sky.\\n3. A mountainous landscape with snow-capped peaks, winding rivers, and rocky cliffs.\\n4. A coastal landscape with sandy beaches, crashing waves, and a colorful sunset.\\n5. An urban landscape with towering skyscrapers, bustling streets, and city lights illuminating the night sky.', response_metadata={'token_usage': {'completion_tokens': 100, 'prompt_tokens': 19, 'total_tokens': 119}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-02b08823-4427-41d0-b18f-d009ea8d036a-0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"concept\": \"Landscapes\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Neurons: The basic building blocks of artificial neural networks, neurons are mathematical functions that take input data, apply weights to them, and produce an output. Understanding how neurons work is crucial to understanding how neural networks learn and make predictions.\\n\\n2. Activation functions: Activation functions are used to introduce non-linearity into neural networks, allowing them to model complex relationships in data. Common activation functions include sigmoid, tanh, ReLU, and softmax. Knowing how activation functions work and when to use them is essential for building effective neural networks.\\n\\n3. Backpropagation: Backpropagation is the algorithm used to train neural networks by adjusting the weights of connections between neurons to minimize the difference between predicted and actual outputs. Understanding how backpropagation works is critical for optimizing the performance of neural networks.\\n\\n4. Layers: Neural networks are typically organized into layers, with each layer consisting of a group of neurons that process input data. Common types of layers include input layers, hidden layers, and output layers. Knowing how to design and structure layers in a neural network is essential for achieving desired outcomes.\\n\\n5. Loss functions: Loss functions are used to quantify the error between predicted and actual outputs in neural networks. Common loss functions include mean squared error, cross-entropy, and hinge loss. Understanding how loss functions work and selecting the appropriate loss function for a specific task is crucial for training neural networks effectively.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Write 5 concepts that are fundamental to learn about {topic}.\n",
    "                                          \"\"\")\n",
    "chain = prompt | llm | output_parser\n",
    "chain.invoke({\"topic\": \"Artificial Neural Networks\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This chain will take input variables, pass those to a prompt template to create a prompt, pass the prompt to an LLM, and then pass the output through an output parser."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so these are the basics of langchain. But how can we leverage these abstraction capabilities inside our LLM app application?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to put everything together LangChain allows you to build something called \"chains\", which are components that connect prompts, llms and output parsers into a building block that allows you to create more interesting and complex functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the example below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what the chain is doing is connecting these basic components (the LLM and the prompt template) into\n",
    "a block that can be run separately. The chain allows you to turn workflows using LLLMs into this modular process of composing components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the newer versions of LangChain have a new representation language to create these chains (and more) known as LCEL or LangChain expression language, which is a declarative way to easily compose chains together. The same example as above expressed in this LCEL format would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"1. Circadian rhythm: The body's internal clock that regulates the sleep-wake cycle and other biological processes.\\n\\n2. Sleep stages: The different stages of sleep, including REM (rapid eye movement) and non-REM sleep, each serving different functions for physical and mental health.\\n\\n3. Sleep hygiene: Healthy sleep habits and practices that promote quality sleep, such as maintaining a consistent sleep schedule and creating a relaxing bedtime routine.\\n\\n4. Sleep disorders: Conditions that disrupt normal sleep patterns, such as insomnia, sleep apnea, and narcolepsy, which can have negative impacts on overall health and well-being.\\n\\n5. Importance of sleep: The crucial role that sleep plays in overall health, cognitive function, mood regulation, and physical performance, emphasizing the need for adequate and restorative sleep.\", response_metadata={'token_usage': {'completion_tokens': 159, 'prompt_tokens': 21, 'total_tokens': 180}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-a7e75df5-b5b1-4c14-8c20-570cbe8b2b87-0')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | ChatOpenAI()\n",
    "\n",
    "chain.invoke({\"topic\": \"sleep\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that now the output is an `AIMessage()` object, which represents LangChain's way to abstract the output from an LLM model like ChatGPT or others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These building blocks and abstractions that LangChain provides are what makes this library so unique, because it gives you the tools you didn't know you need it to build awesome stuff powered by LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a simple chain for summarization of content. \n",
    "\n",
    "Your chain should:\n",
    "\n",
    "- A prompt template with one or more variables\n",
    "- A model like ChatGPT or other (you can use local models if you'd like, I recommend `ChatOllama` for that!)\n",
    "- Optional: use output parsing or just fetch the string output at the end!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Answer\n",
    "\n",
    "Let's make use of the `ChatPromptTemplate` to abstract away the following pieces of the prompt: \n",
    "- `content` - the text content to be summarized  \n",
    "- `summary_format` - the format in which we want the summary to be presented (like bullet points and so on)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: Summarize this: This is a test.. The output should be in the following format: One word summary.'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"Summarize this: {content}. The output should be in the following format: {summary_format}.\")\n",
    "\n",
    "# We can look at a simple example to illustrate what that prompt is doing\n",
    "prompt.format(content=\"This is a test.\", summary_format=\"One word summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we have our prompt template done, let's load the llm and create a nice chain to put everything together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm_chat =  ChatOpenAI()\n",
    "chain = prompt | llm_chat # This is the Pipe symbol! from LCEL that connect model to prompt!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we have our chain we can run some tests. The cool thing about working with LLMs is that you can use them to create examples for simple tests like this (avoiding the annoynace of searching online for some piece of text, copying and pasting etc...). So, let's generate a few examples of tests below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='With the rise of artificial intelligence and machine learning technologies, the interaction between humans and machines has become increasingly common in everyday life. From voice-activated virtual assistants like Siri and Alexa to self-driving cars and smart home devices, humans are now relying on machines to assist with a wide range of tasks. This shift in human-machine interaction has not only made our lives more convenient and efficient, but it has also raised questions about the impact of technology on society.\\n\\nOne of the key concerns surrounding human-machine interaction is the potential for job displacement as automation continues to replace manual labor tasks. While machines can perform certain tasks faster and more accurately than humans, there is a fear that this could lead to widespread unemployment and economic instability. Additionally, there are ethical considerations to be made in terms of privacy and data security, as machines collect and analyze vast amounts of personal information. As we navigate this new era of human-machine interaction, it is crucial to consider the implications and work towards creating a balance that benefits both humans and machines.', response_metadata={'token_usage': {'completion_tokens': 201, 'prompt_tokens': 25, 'total_tokens': 226}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-f05a6ca9-34b1-4a13-b597-df75a7d15404-0'),\n",
       " AIMessage(content='One fascinating aspect of human-machine interaction is the concept of artificial intelligence and its ability to mimic human behavior. As AI technology continues to advance, machines are becoming increasingly capable of learning, adapting, and even displaying emotions in a way that is eerily similar to human beings. This has raised interesting ethical questions about the potential implications of creating machines that are so closely aligned with human cognition.\\n\\nOn the other hand, human-machine interaction has also revolutionized the way we live and work. From voice assistants like Siri and Alexa to self-driving cars and automated customer service bots, machines are now an integral part of our daily lives. This seamless integration of technology has made tasks more efficient, convenient, and accessible than ever before. As we continue to develop and refine our interactions with machines, it will be interesting to see how this dynamic evolves and shapes the future of human society.', response_metadata={'token_usage': {'completion_tokens': 172, 'prompt_tokens': 25, 'total_tokens': 197}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-cfd2e68b-9edc-4fa6-8f72-e5b40dfcca01-0'),\n",
       " AIMessage(content='One of the most fascinating aspects of human-machine interaction is the concept of artificial intelligence. AI has become increasingly integrated into our daily lives, from virtual assistants like Siri and Alexa to self-driving cars and recommendation algorithms on streaming platforms. The ability of machines to learn, adapt, and make decisions on their own raises important questions about the future of work, privacy, and ethics. As AI continues to advance, it is crucial for society to consider the implications of this technology and how we can ensure that it is used responsibly and ethically.\\n\\nAnother interesting aspect of human-machine interaction is the way in which technology has changed the way we communicate with one another. Social media platforms, messaging apps, and video conferencing tools have made it easier than ever to connect with others, regardless of physical distance. However, this increased connectivity also raises concerns about the impact of technology on mental health, relationships, and social skills. Finding a balance between the benefits and drawbacks of technology in our interactions with others is an ongoing challenge that requires thoughtful consideration and reflection.', response_metadata={'token_usage': {'completion_tokens': 206, 'prompt_tokens': 25, 'total_tokens': 231}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-0758f454-db8a-4fa7-83d4-3a75695a2d0c-0')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_examples = 3\n",
    "examples = []\n",
    "for i in range(num_examples):\n",
    "    examples.append(llm_chat.invoke(\"Create a piece of text with 2 paragraphs about a random topic regarding human-machine interaction.\"))\n",
    "\n",
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! Now that we have our examples, let's run our chain on them and check out the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='- With the rise of artificial intelligence and machine learning, human-machine interaction is becoming more common in everyday life\\n- Examples include virtual assistants like Siri and Alexa, self-driving cars, and smart home devices\\n- This shift has made our lives more convenient and efficient, but also raises concerns about job displacement, privacy, and data security\\n- Automation replacing manual labor tasks may lead to widespread unemployment and economic instability\\n- There are ethical considerations surrounding the collection and analysis of personal information by machines\\n- It is important to navigate this new era of human-machine interaction carefully and strive for a balance that benefits both humans and machines', response_metadata={'token_usage': {'completion_tokens': 123, 'prompt_tokens': 329, 'total_tokens': 452}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-ae9d9d30-2206-495c-8eb5-5a9a368d0216-0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_format = \"bullet points\"\n",
    "\n",
    "outputs = []\n",
    "for ex in examples:\n",
    "    outputs.append(chain.invoke({\"content\": ex, \"summary_format\": summary_format}))\n",
    "\n",
    "# Let's display one example output\n",
    "outputs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! So it seems our chain worked and we generated some summaries! Let's visualize all the summaries generated in a neat way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Output 0 \n",
       " - With the rise of artificial intelligence and machine learning, human-machine interaction is becoming more common in everyday life\n",
       "- Examples include virtual assistants like Siri and Alexa, self-driving cars, and smart home devices\n",
       "- This shift has made our lives more convenient and efficient, but also raises concerns about job displacement, privacy, and data security\n",
       "- Automation replacing manual labor tasks may lead to widespread unemployment and economic instability\n",
       "- There are ethical considerations surrounding the collection and analysis of personal information by machines\n",
       "- It is important to navigate this new era of human-machine interaction carefully and strive for a balance that benefits both humans and machines"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Output 1 \n",
       " - Artificial intelligence in human-machine interaction is advancing rapidly, allowing machines to mimic human behavior, learn, adapt, and display emotions.\n",
       "- This raises ethical questions about the implications of creating machines so closely aligned with human cognition.\n",
       "- Human-machine interaction has revolutionized daily life, with technologies like voice assistants, self-driving cars, and customer service bots becoming integral.\n",
       "- Technology integration has made tasks more efficient, convenient, and accessible.\n",
       "- The evolution of interactions with machines will shape the future of human society."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Output 2 \n",
       " - Artificial intelligence (AI) is a fascinating aspect of human-machine interaction that is increasingly integrated into daily life\n",
       "- AI is seen in virtual assistants, self-driving cars, and recommendation algorithms on streaming platforms\n",
       "- The ability of machines to learn, adapt, and make decisions raises questions about the future of work, privacy, and ethics\n",
       "- Society must consider the implications of AI and ensure it is used responsibly and ethically\n",
       "- Technology has changed the way we communicate with social media, messaging apps, and video conferencing tools\n",
       "- Increased connectivity through technology raises concerns about mental health, relationships, and social skills\n",
       "- Finding a balance between the benefits and drawbacks of technology in interactions with others is an ongoing challenge that requires thoughtful consideration and reflection."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "for i in range(num_examples):\n",
    "    display(Markdown(f\"Output {i} \\n {outputs[i].content}\"))\n",
    "# Markdown(f\"**Input**: {examples[0]}\\n\\n**Output**: {outputs[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Our summaries worked, and we were able to apply a given summary format to all of them.\n",
    "\n",
    "LangChain is an extremely powerful library to work with abstractions like these and throughout this course we hope to give you a gliimpse of the cool stuff you can build with it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oreilly-langchain",
   "language": "python",
   "name": "oreilly-langchain"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
